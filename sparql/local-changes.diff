diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/build.xml work-copy/build.xml
--- upstream/build.xml	2006-08-20 20:01:02.000000000 -0400
+++ work-copy/build.xml	2006-12-02 11:01:18.000000000 -0500
@@ -8,7 +8,7 @@
      Ryan Levering
      ====================================================================== -->
 <project name="SPARQL Parser" default="dist_from_grammar">
-	
+
 	<!-- STRUCTURE PROPERTIES -->
 	<property name="srcdir" value="src/main" />
 	<property name="testdir" value="src/tests" />
@@ -76,12 +76,12 @@
 		<jar basedir="${temp_dir}" destfile="${libdir}/${library}" />
 		<delete dir="${temp_dir}" />
 		<mkdir dir="${temp_dir}" />
-		<javac srcdir="${testdir}" destdir="${temp_dir}">
+		<!--<javac srcdir="${testdir}" destdir="${temp_dir}">
 			<classpath>
 				<path refid="test.classpath" />
 				<pathelement path="${libdir}/${library}" />
 			</classpath>
-		</javac>
+		</javac>-->
 		<copy todir="${temp_dir}" includeemptydirs="false">
 			<fileset dir="test_files">
 				<include name="**/*" />
@@ -92,6 +92,7 @@
 	</target>
 	
 	<!-- THIS WILL BUILD THE SOURCE AND TEST IT AGAINST THE GENERIC TEST CASES -->
+	<!--
 	<target name="test" depends="jar">
 		<junit printsummary="yes" fork="yes" haltonfailure="yes">
 			<classpath>
@@ -103,6 +104,7 @@
 			<formatter type="plain" usefile="false" />
 		</junit>
 	</target>
+	-->
 		
 	<!-- THIS WILL CREATE THE JAVADOCS IN THE DOCS FOLDER -->
 	<!-- THIS ISN'T USED FOR DISTRIBUTION, BUT CAN BE USED BY END USER -->
@@ -174,4 +176,4 @@
 	<!-- THIS WILL BUILD THE WHOLE DISTRIBUTION FROM GRAMMAR -->
 	<target name="dist_from_grammar" depends="grammar,dist" />
 
-</project>
\ No newline at end of file
+</project>
Binary files upstream/lib/sparql-core.jar and work-copy/lib/sparql-core.jar differ
Binary files upstream/lib/sparql-tests.jar and work-copy/lib/sparql-tests.jar differ
Binary files upstream/sparql-0.8.zip and work-copy/sparql-0.8.zip differ
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/common/AdvancedRdfSource.java work-copy/src/main/name/levering/ryan/sparql/common/AdvancedRdfSource.java
--- upstream/src/main/name/levering/ryan/sparql/common/AdvancedRdfSource.java	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/common/AdvancedRdfSource.java	2006-12-02 11:00:47.000000000 -0500
@@ -0,0 +1,26 @@
+/*
+ * SPARQL Engine
+ * Copyright (C) 2005 Ryan Levering, All rights reserved.
+ * See LICENSE for full license information
+ */
+package name.levering.ryan.sparql.common;
+
+import java.util.Iterator;
+import java.util.List;
+
+import org.openrdf.model.URI;
+import org.openrdf.model.Value;
+import org.openrdf.model.ValueFactory;
+
+/**
+ * Description...
+ * 
+ * @author Joshua Tauberer
+ * @version 1.0
+ */
+public interface AdvancedRdfSource extends RdfSource {
+    public Iterator getStatements(Value[] subj, Value[] pred, Value[] obj, URI[] graph, Object[] litFilters);
+    public Iterator getDefaultStatements(Value[] subj, Value[] pred, Value[] obj, Object[] litFilters);
+    public Iterator getStatements(Value[] subj, Value[] pred, Value[] obj, Object[] litFilters);
+}
+
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/common/impl/RdfBindingSetImpl.java work-copy/src/main/name/levering/ryan/sparql/common/impl/RdfBindingSetImpl.java
--- upstream/src/main/name/levering/ryan/sparql/common/impl/RdfBindingSetImpl.java	2006-08-20 20:00:59.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/common/impl/RdfBindingSetImpl.java	2007-02-17 11:09:33.000000000 -0500
@@ -98,6 +98,8 @@
 		for (Iterator oldRows = oldSet.iterator(); oldRows.hasNext();) {
 			this.addRow((RdfBindingRow) oldRows.next());
 		}
+		setDistinct(oldSet.isDistinct());
+		setOrdered(oldSet.isOrdered());
 	}
 
 	/**
@@ -141,11 +143,10 @@
 		if (row == null) {
 			throw new NullPointerException("RdfBindingRow 'row' cannot be null");
 		}
-		List newValues = new ArrayList();
-		for (int i = 0; i < this.variables.length; i++) {
-			newValues.add(row.getValue(this.variables[i]));
-		}
-		this.values.add(newValues.toArray(new Value[0]));
+		Value[] newValues = new Value[this.variables.length];
+		for (int i = 0; i < this.variables.length; i++)
+			newValues[i] = row.getValue(this.variables[i]);
+		this.values.add(newValues);
 	}
 
 	/**
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/extensions/fpredicates/FunctionalPredicateLogic.java work-copy/src/main/name/levering/ryan/sparql/extensions/fpredicates/FunctionalPredicateLogic.java
--- upstream/src/main/name/levering/ryan/sparql/extensions/fpredicates/FunctionalPredicateLogic.java	2006-08-20 20:00:59.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/extensions/fpredicates/FunctionalPredicateLogic.java	2007-02-21 07:08:18.000000000 -0500
@@ -1,6 +1,7 @@
 package name.levering.ryan.sparql.extensions.fpredicates;
 
 import java.util.Collection;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -41,10 +42,9 @@
 	 * @param namedDatasets the named graphs, ignored
 	 * @return a binding set according to the function
 	 */
-	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
 		
-		return this.function.getBindingSet(this.data.getSubjectExpression(), this.data.getObjectExpression(), source);
+		return this.function.getBindingSet(this.data.getSubjectExpression(), this.data.getObjectExpression(), p.source);
 	}
 
 }
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/extensions/fpredicates/FunctionalPredicateLogic.java~ work-copy/src/main/name/levering/ryan/sparql/extensions/fpredicates/FunctionalPredicateLogic.java~
--- upstream/src/main/name/levering/ryan/sparql/extensions/fpredicates/FunctionalPredicateLogic.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/extensions/fpredicates/FunctionalPredicateLogic.java~	2007-02-21 07:05:12.000000000 -0500
@@ -0,0 +1,50 @@
+package name.levering.ryan.sparql.extensions.fpredicates;
+
+import java.util.Collection;
+import java.util.Map;
+
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.model.data.TripleConstraintData;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
+
+/**
+ * The logic to handle the functional predicate delegation.
+ * 
+ * @author Ryan Levering
+ * @version 1.0
+ */
+public class FunctionalPredicateLogic implements ConstraintLogic {
+
+	private final TripleConstraintData data;
+
+	private final FunctionalPredicate function;
+
+	/**
+	 * Creates a new logic delegator that merely passes off the binding set
+	 * creation to a functional predicate class.
+	 * 
+	 * @param function the function to handle the set creation
+	 * @param data the triple data to pull the subject and object from
+	 */
+	public FunctionalPredicateLogic(FunctionalPredicate function, TripleConstraintData data) {
+		this.function = function;
+		this.data = data;
+	}
+
+	/**
+	 * Delegates to the function to return a binding set based on the source and
+	 * the subject and object of the functional predicate statement.
+	 * 
+	 * @param bindings the current bindings, ignored
+	 * @param source the RDF source to pass to the function
+	 * @param defaultDatasets the default named graphs, ignored
+	 * @param namedDatasets the named graphs, ignored
+	 * @return a binding set according to the function
+	 */
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+		
+		return this.function.getBindingSet(this.data.getSubjectExpression(), this.data.getObjectExpression(), source);
+	}
+
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/IsMaxFunction.java work-copy/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/IsMaxFunction.java
--- upstream/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/IsMaxFunction.java	2006-08-20 20:00:59.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/IsMaxFunction.java	2006-12-02 11:00:47.000000000 -0500
@@ -128,7 +128,7 @@
 		return new ExternalFunctionFactory() {
 
 			public ExternalFunction create(LogicFactory logicFactory, SPARQLValueFactory valueFactory) {
-				return new IsMaxFunction(logicFactory.getValueOrderingLogic());
+				return new IsMaxFunction(logicFactory.getValueOrderingLogic(valueFactory));
 			}
 
 		};
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/IsMinFunction.java work-copy/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/IsMinFunction.java
--- upstream/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/IsMinFunction.java	2006-08-20 20:00:59.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/IsMinFunction.java	2006-12-02 11:00:47.000000000 -0500
@@ -126,7 +126,7 @@
 		return new ExternalFunctionFactory() {
 
 			public ExternalFunction create(LogicFactory logicFactory, SPARQLValueFactory valueFactory) {
-				return new IsMinFunction(logicFactory.getValueOrderingLogic());
+				return new IsMinFunction(logicFactory.getValueOrderingLogic(valueFactory));
 			}
 
 		};
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/MaxFunction.java work-copy/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/MaxFunction.java
--- upstream/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/MaxFunction.java	2006-08-20 20:00:59.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/MaxFunction.java	2006-12-02 11:00:47.000000000 -0500
@@ -121,7 +121,7 @@
 		return new ExternalFunctionFactory() {
 
 			public ExternalFunction create(LogicFactory logicFactory, SPARQLValueFactory valueFactory) {
-				return new MaxFunction(logicFactory.getValueOrderingLogic());
+				return new MaxFunction(logicFactory.getValueOrderingLogic(valueFactory));
 			}
 
 		};
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/MinFunction.java work-copy/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/MinFunction.java
--- upstream/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/MinFunction.java	2006-08-20 20:00:59.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/MinFunction.java	2006-12-02 11:00:47.000000000 -0500
@@ -121,7 +121,7 @@
 		return new ExternalFunctionFactory() {
 
 			public ExternalFunction create(LogicFactory logicFactory, SPARQLValueFactory valueFactory) {
-				return new MinFunction(logicFactory.getValueOrderingLogic());
+				return new MinFunction(logicFactory.getValueOrderingLogic(valueFactory));
 			}
 
 		};
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/extensions/with/DefaultWithConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/extensions/with/DefaultWithConstraintLogic.java
--- upstream/src/main/name/levering/ryan/sparql/extensions/with/DefaultWithConstraintLogic.java	2006-08-20 20:00:59.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/extensions/with/DefaultWithConstraintLogic.java	2007-02-21 07:07:42.000000000 -0500
@@ -1,6 +1,7 @@
 package name.levering.ryan.sparql.extensions.with;
 
 import java.util.Collection;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -43,10 +44,9 @@
 	 * @param namedDatasets the named data sets to query against, ignored
 	 * @return the binding set created by the extension
 	 */
-	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
 		return this.extension.getBindingSet((ExpressionLogic[]) this.data.getArguments().toArray(
-				new ExpressionLogic[] {}), source);
+				new ExpressionLogic[] {}), p.source);
 	}
 
 }
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/extensions/with/DefaultWithConstraintLogic.java~ work-copy/src/main/name/levering/ryan/sparql/extensions/with/DefaultWithConstraintLogic.java~
--- upstream/src/main/name/levering/ryan/sparql/extensions/with/DefaultWithConstraintLogic.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/extensions/with/DefaultWithConstraintLogic.java~	2007-02-21 07:05:10.000000000 -0500
@@ -0,0 +1,52 @@
+package name.levering.ryan.sparql.extensions.with;
+
+import java.util.Collection;
+import java.util.Map;
+
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.model.data.WithConstraintData;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
+import name.levering.ryan.sparql.model.logic.ExpressionLogic;
+
+/**
+ * This logic delegates the fetching of an RdfBindingSet to the underlying WITH
+ * extension.
+ * 
+ * @author Ryan Levering
+ * @version 1.0
+ */
+public class DefaultWithConstraintLogic implements ConstraintLogic {
+
+	private final WithConstraintData data;
+
+	private final WithExtension extension;
+
+	/**
+	 * Creates a new logic that is responsible for RdfBindingSet delegation to
+	 * an extension.
+	 * 
+	 * @param data the data that includes the extension call
+	 * @param extension the extension to process the call
+	 */
+	public DefaultWithConstraintLogic(WithConstraintData data, WithExtension extension) {
+		this.extension = extension;
+		this.data = data;
+	}
+
+	/**
+	 * Ignores the inputs and just lets the extension return a binding set to be
+	 * intersected with the current running set.
+	 * 
+	 * @param bindings the current bindings, ignored
+	 * @param source the source to query against, passed to the WITH extension
+	 * @param defaultDatasets the default data sets to query against, ignored
+	 * @param namedDatasets the named data sets to query against, ignored
+	 * @return the binding set created by the extension
+	 */
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+		return this.extension.getBindingSet((ExpressionLogic[]) this.data.getArguments().toArray(
+				new ExpressionLogic[] {}), source);
+	}
+
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/BaseLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/BaseLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/BaseLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/BaseLogic.java	2006-12-02 11:01:18.000000000 -0500
@@ -345,8 +345,8 @@
 	 * 
 	 * @return the logic that orders Value objects
 	 */
-	public ValueOrderingLogic getValueOrderingLogic() {
-		return new DefaultValueOrderingLogic();
+	public ValueOrderingLogic getValueOrderingLogic(SPARQLValueFactory valueFactory) {
+		return new DefaultValueOrderingLogic(getNumericPromotionLogic(valueFactory), getValueConversionLogic(valueFactory));
 	}
 
 }
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/BNodeRenamingConstructQueryLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/BNodeRenamingConstructQueryLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/BNodeRenamingConstructQueryLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/BNodeRenamingConstructQueryLogic.java	2007-02-21 07:51:02.000000000 -0500
@@ -22,6 +22,7 @@
 import name.levering.ryan.sparql.model.GroupConstraint;
 import name.levering.ryan.sparql.model.TripleConstraint;
 import name.levering.ryan.sparql.model.data.ConstructQueryData;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
 import name.levering.ryan.sparql.model.logic.ConstructQueryLogic;
 import name.levering.ryan.sparql.model.logic.OrderExpressionLogic;
 import name.levering.ryan.sparql.model.logic.helper.SetRangeLogic;
@@ -85,16 +86,20 @@
 	 * @return an RDF graph containing the formed triples
 	 */
 	public RdfGraph execute(RdfSource source) {
+		ConstraintLogic.CallParams p = new ConstraintLogic.CallParams();
+		p.bindings = new RdfBindingSetImpl();
+		p.source = source;
+		
 		// Grab the necessary fields from the data
 		GroupConstraint constraint = this.data.getConstraint();
-		Collection defaultDatasets = this.data.getDefaultDatasets();
-		Collection namedDatasets = this.data.getNamedDatasets();
+		p.defaultDatasets = this.data.getDefaultDatasets();
+		p.namedDatasets = this.data.getNamedDatasets();
 		List orderExpressions = this.data.getOrderExpressions();
 		int limit = this.data.getLimit();
 		int offset = this.data.getOffset();
 
 		// First bind the result table
-		RdfBindingSet results = constraint.constrain(new RdfBindingSetImpl(), source, defaultDatasets, namedDatasets);
+		RdfBindingSet results = constraint.constrain(p);
 
 		// Now apply ordering in reverse order to give priority to the first
 		// variable
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/BNodeRenamingConstructQueryLogic.java~ work-copy/src/main/name/levering/ryan/sparql/logic/BNodeRenamingConstructQueryLogic.java~
--- upstream/src/main/name/levering/ryan/sparql/logic/BNodeRenamingConstructQueryLogic.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/BNodeRenamingConstructQueryLogic.java~	2007-02-10 09:06:34.000000000 -0500
@@ -0,0 +1,247 @@
+/*
+ * SPARQL Engine
+ * Copyright (C) 2005 Ryan Levering, All rights reserved.
+ * See LICENSE for full license information
+ */
+package name.levering.ryan.sparql.logic;
+
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+
+import name.levering.ryan.sparql.common.RdfBindingRow;
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfGraph;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.common.impl.RdfBindingSetImpl;
+import name.levering.ryan.sparql.common.impl.RdfGraphImpl;
+import name.levering.ryan.sparql.common.impl.SPARQLValueFactory;
+import name.levering.ryan.sparql.common.impl.StatementImpl;
+import name.levering.ryan.sparql.model.GroupConstraint;
+import name.levering.ryan.sparql.model.TripleConstraint;
+import name.levering.ryan.sparql.model.data.ConstructQueryData;
+import name.levering.ryan.sparql.model.logic.ConstructQueryLogic;
+import name.levering.ryan.sparql.model.logic.OrderExpressionLogic;
+import name.levering.ryan.sparql.model.logic.helper.SetRangeLogic;
+
+import org.openrdf.model.BNode;
+import org.openrdf.model.URI;
+import org.openrdf.model.Value;
+
+/**
+ * This query logic constructs an RDF graph by applying an RDF template to a set
+ * of value bindings. It must first bind the variables values, then apply
+ * ordering and cropping, and finally apply the values to the RDF template.
+ * <p>
+ * This differs from the default construct logic in that it renames blank nodes
+ * to have unique scope. This seems to be an underlying idea in the spec and is
+ * definitely specification strict, but in implementation blank node renaming
+ * just causes problems. So this is included in case you want to test your
+ * construct queries against this allowed property of constructs.
+ * 
+ * @author Ryan Levering
+ * @version 1.0
+ */
+public class BNodeRenamingConstructQueryLogic implements ConstructQueryLogic {
+
+	/**
+	 * The data to delegate the data requests to.
+	 */
+	private final ConstructQueryData data;
+
+	/**
+	 * The logic to handle limiting the rows of the binding set results.
+	 */
+	private final SetRangeLogic rangeLogic;
+
+	/**
+	 * Value factory to use when generating new blank nodes for constructed
+	 * graphs.
+	 */
+	private final SPARQLValueFactory valueFactory;
+
+	/**
+	 * Creates a new object that handles the logic of the construct query,
+	 * delegating data calls to the data object.
+	 * 
+	 * @param data the construct query data object delegate
+	 * @param rangeLogic the logic to use to limit or offset the constrained binding set
+	 * @param valueFactory the factory to use to generate value objects
+	 */
+	public BNodeRenamingConstructQueryLogic(ConstructQueryData data, SetRangeLogic rangeLogic,
+			SPARQLValueFactory valueFactory) {
+		this.data = data;
+		this.rangeLogic = rangeLogic;
+		this.valueFactory = valueFactory;
+	}
+
+	/**
+	 * Executes the query against an RdfSource and returns an RDF graph which is
+	 * formed by applying a variable RDF template.
+	 * 
+	 * @param source the data source of RDF triples
+	 * @return an RDF graph containing the formed triples
+	 */
+	public RdfGraph execute(RdfSource source) {
+		// Grab the necessary fields from the data
+		GroupConstraint constraint = this.data.getConstraint();
+		Collection defaultDatasets = this.data.getDefaultDatasets();
+		Collection namedDatasets = this.data.getNamedDatasets();
+		List orderExpressions = this.data.getOrderExpressions();
+		int limit = this.data.getLimit();
+		int offset = this.data.getOffset();
+
+		// First bind the result table
+		RdfBindingSet results = constraint.constrain(new RdfBindingSetImpl(), source, defaultDatasets, namedDatasets, null, null);
+
+		// Now apply ordering in reverse order to give priority to the first
+		// variable
+		for (int i = orderExpressions.size() - 1; i >= 0; i--) {
+			OrderExpressionLogic orderer = (OrderExpressionLogic) orderExpressions.get(i);
+			orderer.order(results);
+		}
+
+		// Now apply limiting and offsetting
+		if (limit >= 0) {
+			results = this.rangeLogic.limit(results, limit);
+		}
+		if (offset >= 0) {
+			results = this.rangeLogic.offset(results, offset);
+		}
+
+		// Now apply the solutions to the template
+		RdfGraphImpl graph = new RdfGraphImpl();
+		for (Iterator solutions = results.iterator(); solutions.hasNext();) {
+			RdfBindingRow row = (RdfBindingRow) solutions.next();
+			Map blankNodeMap = new HashMap();
+			for (Iterator i = this.data.getTriples().iterator(); i.hasNext();) {
+				TripleConstraint triple = (TripleConstraint) i.next();
+
+				// Subject
+				Value subject;
+				if (triple.getSubjectExpression() instanceof BNode) {
+					if (blankNodeMap.containsKey(triple.getSubjectExpression())) {
+						subject = (BNode) blankNodeMap.get(triple.getSubjectExpression());
+					} else {
+						BNode newSubject = this.valueFactory.createBNode();
+						blankNodeMap.put(triple.getSubjectExpression(), newSubject);
+						subject = newSubject;
+					}
+				} else {
+					subject = triple.getSubjectExpression().evaluate(row);
+				}
+				if (subject == null) {
+					continue;
+				}
+
+				// Blank nodes should be renamed to have unique scope
+				if (subject instanceof BNode) {
+					if (blankNodeMap.containsKey(subject)) {
+						subject = (BNode) blankNodeMap.get(subject);
+					} else {
+						BNode newSubject = this.valueFactory.createBNode();
+						blankNodeMap.put(subject, newSubject);
+						subject = newSubject;
+					}
+				}
+
+				// Verb
+				URI verb = (URI) triple.getPredicateExpression().evaluate(row);
+				if (verb == null) {
+					continue;
+				}
+
+				// Object
+				Value object;
+				if (triple.getObjectExpression() instanceof BNode) {
+					if (blankNodeMap.containsKey(triple.getObjectExpression())) {
+						object = (BNode) blankNodeMap.get(triple.getObjectExpression());
+					} else {
+						BNode newobject = this.valueFactory.createBNode();
+						blankNodeMap.put(triple.getObjectExpression(), newobject);
+						object = newobject;
+					}
+				} else {
+					object = triple.getObjectExpression().evaluate(row);
+				}
+				if (object == null) {
+					continue;
+				}
+
+				// Blank nodes should be renamed to have unique scope
+				if (object instanceof BNode) {
+					if (blankNodeMap.containsKey(object)) {
+						object = (BNode) blankNodeMap.get(object);
+					} else {
+						BNode newObject = this.valueFactory.createBNode();
+						blankNodeMap.put(object, newObject);
+						object = newObject;
+					}
+				}
+
+				graph.addTriple(new StatementImpl(subject, verb, object));
+			}
+		}
+
+		// This is a Jena-alike hack to make all constructs at least produce
+		// one statement, take it out later
+		if (results.isEmpty()) {
+			Map blankNodeMap = new HashMap();
+			for (Iterator i = this.data.getTriples().iterator(); i.hasNext();) {
+				TripleConstraint triple = (TripleConstraint) i.next();
+
+				// Subject
+				Value subject;
+				if (triple.getSubjectExpression() instanceof Value) {
+					subject = (Value) triple.getSubjectExpression();
+					if (subject instanceof BNode) {
+						if (blankNodeMap.containsKey(subject)) {
+							subject = (BNode) blankNodeMap.get(subject);
+						} else {
+							BNode newSubject = this.valueFactory.createBNode();
+							blankNodeMap.put(subject, newSubject);
+							subject = newSubject;
+						}
+					}
+				} else {
+					graph = new RdfGraphImpl();
+					break;
+				}
+
+				// Verb
+				URI verb;
+				if (triple.getPredicateExpression() instanceof URI) {
+					verb = (URI) triple.getPredicateExpression();
+				} else {
+					graph = new RdfGraphImpl();
+					break;
+				}
+
+				// Object
+				Value object;
+				if (triple.getObjectExpression() instanceof Value) {
+					object = (Value) triple.getObjectExpression();
+					if (object instanceof BNode) {
+						if (blankNodeMap.containsKey(object)) {
+							object = (BNode) blankNodeMap.get(object);
+						} else {
+							BNode newobject = this.valueFactory.createBNode();
+							blankNodeMap.put(object, newobject);
+							object = newobject;
+						}
+					}
+				} else {
+					graph = new RdfGraphImpl();
+					break;
+				}
+
+				graph.addTriple(new StatementImpl(subject, verb, object));
+			}
+		}
+
+		return graph;
+	}
+
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/debug/DebugLogicWrapper.java work-copy/src/main/name/levering/ryan/sparql/logic/debug/DebugLogicWrapper.java
--- upstream/src/main/name/levering/ryan/sparql/logic/debug/DebugLogicWrapper.java	2006-12-02 11:09:25.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/debug/DebugLogicWrapper.java	2006-12-02 11:11:22.000000000 -0500
@@ -173,8 +173,8 @@
 		return new OptionalConstraintDebug(this.baseFactory.getOptionalConstraintLogic(data, valueFactory), this.out);
 	}
 
-	public OrderExpressionLogic getOrderExpressionLogic(OrderExpressionData data) {
-		return this.baseFactory.getOrderExpressionLogic(data);
+	public OrderExpressionLogic getOrderExpressionLogic(OrderExpressionData data, SPARQLValueFactory valueFactory) {
+		return this.baseFactory.getOrderExpressionLogic(data, valueFactory);
 	}
 
 	public ExpressionLogic getOrLogic(BinaryExpressionData data, SPARQLValueFactory valueFactory) {
@@ -236,8 +236,8 @@
 		return this.baseFactory.getValueConversionLogic(valueFactory);
 	}
 
-	public ValueOrderingLogic getValueOrderingLogic() {
-		return this.baseFactory.getValueOrderingLogic();
+	public ValueOrderingLogic getValueOrderingLogic(SPARQLValueFactory valueFactory) {
+		return this.baseFactory.getValueOrderingLogic(valueFactory);
 	}
 
 	public ConstructQueryLogic getConstructQueryLogic(ExtendedConstructQueryData data, SPARQLValueFactory valueFactory) {
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/debug/FilterConstraintDebug.java work-copy/src/main/name/levering/ryan/sparql/logic/debug/FilterConstraintDebug.java
--- upstream/src/main/name/levering/ryan/sparql/logic/debug/FilterConstraintDebug.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/debug/FilterConstraintDebug.java	2007-02-21 07:09:08.000000000 -0500
@@ -1,6 +1,7 @@
 package name.levering.ryan.sparql.logic.debug;
 
 import java.util.Collection;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -19,11 +20,10 @@
 		this.out = listener;
 	}
 	
-	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
-        this.out.filterConstraintPreExecute(this.data, bindings);
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+        this.out.filterConstraintPreExecute(this.data, p.bindings);
         long start = System.currentTimeMillis();
-        RdfBindingSet returnSet = this.filterLogic.constrain(bindings, source, defaultDatasets, namedDatasets);
+        RdfBindingSet returnSet = this.filterLogic.constrain(p);
         long end = System.currentTimeMillis();
         this.out.filterConstraintPostExecute(end-start, returnSet);
         return returnSet;
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/debug/FilterConstraintDebug.java~ work-copy/src/main/name/levering/ryan/sparql/logic/debug/FilterConstraintDebug.java~
--- upstream/src/main/name/levering/ryan/sparql/logic/debug/FilterConstraintDebug.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/debug/FilterConstraintDebug.java~	2007-02-21 07:05:11.000000000 -0500
@@ -0,0 +1,32 @@
+package name.levering.ryan.sparql.logic.debug;
+
+import java.util.Collection;
+import java.util.Map;
+
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.model.data.FilterConstraintData;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
+
+public class FilterConstraintDebug implements ConstraintLogic {
+
+	private final DebugListener out;
+	private final ConstraintLogic filterLogic;
+	private final FilterConstraintData data;
+
+	public FilterConstraintDebug(ConstraintLogic filterLogic, FilterConstraintData data, DebugListener listener) {
+		this.filterLogic = filterLogic;
+		this.data = data;
+		this.out = listener;
+	}
+	
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+        this.out.filterConstraintPreExecute(this.data, bindings);
+        long start = System.currentTimeMillis();
+        RdfBindingSet returnSet = this.filterLogic.constrain(bindings, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
+        long end = System.currentTimeMillis();
+        this.out.filterConstraintPostExecute(end-start, returnSet);
+        return returnSet;
+	}
+
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/debug/GraphConstraintDebug.java work-copy/src/main/name/levering/ryan/sparql/logic/debug/GraphConstraintDebug.java
--- upstream/src/main/name/levering/ryan/sparql/logic/debug/GraphConstraintDebug.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/debug/GraphConstraintDebug.java	2007-02-21 07:09:15.000000000 -0500
@@ -1,6 +1,7 @@
 package name.levering.ryan.sparql.logic.debug;
 
 import java.util.Collection;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -16,11 +17,10 @@
 		this.out = listener;
 	}
 
-	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
         this.out.graphConstraintPreExecute();
         long start = System.currentTimeMillis();
-        RdfBindingSet returnSet = this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+        RdfBindingSet returnSet = this.logic.constrain(p);
         long end = System.currentTimeMillis();
         this.out.graphConstraintPostExecute(end-start, returnSet);
         return returnSet;
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/debug/GraphConstraintDebug.java~ work-copy/src/main/name/levering/ryan/sparql/logic/debug/GraphConstraintDebug.java~
--- upstream/src/main/name/levering/ryan/sparql/logic/debug/GraphConstraintDebug.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/debug/GraphConstraintDebug.java~	2007-02-21 07:05:12.000000000 -0500
@@ -0,0 +1,29 @@
+package name.levering.ryan.sparql.logic.debug;
+
+import java.util.Collection;
+import java.util.Map;
+
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
+
+public class GraphConstraintDebug implements ConstraintLogic {
+
+	private ConstraintLogic logic;
+	private DebugListener out;
+
+	public GraphConstraintDebug(ConstraintLogic graphConstraintLogic, DebugListener listener) {
+		this.logic = graphConstraintLogic;
+		this.out = listener;
+	}
+
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+        this.out.graphConstraintPreExecute();
+        long start = System.currentTimeMillis();
+        RdfBindingSet returnSet = this.logic.constrain(bindings, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
+        long end = System.currentTimeMillis();
+        this.out.graphConstraintPostExecute(end-start, returnSet);
+        return returnSet;
+	}
+
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/debug/GroupConstraintDebug.java work-copy/src/main/name/levering/ryan/sparql/logic/debug/GroupConstraintDebug.java
--- upstream/src/main/name/levering/ryan/sparql/logic/debug/GroupConstraintDebug.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/debug/GroupConstraintDebug.java	2007-02-21 07:09:19.000000000 -0500
@@ -1,6 +1,7 @@
 package name.levering.ryan.sparql.logic.debug;
 
 import java.util.Collection;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -16,11 +17,10 @@
 		this.out = listener;
 	}
 
-	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
         this.out.groupConstraintPreExecute();
         long start = System.currentTimeMillis();
-        RdfBindingSet returnSet = this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+        RdfBindingSet returnSet = this.logic.constrain(p);
         long end = System.currentTimeMillis();
         this.out.groupConstraintPostExecute(end-start, returnSet);
         return returnSet;
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/debug/GroupConstraintDebug.java~ work-copy/src/main/name/levering/ryan/sparql/logic/debug/GroupConstraintDebug.java~
--- upstream/src/main/name/levering/ryan/sparql/logic/debug/GroupConstraintDebug.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/debug/GroupConstraintDebug.java~	2007-02-21 07:05:13.000000000 -0500
@@ -0,0 +1,29 @@
+package name.levering.ryan.sparql.logic.debug;
+
+import java.util.Collection;
+import java.util.Map;
+
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
+
+public class GroupConstraintDebug implements ConstraintLogic {
+
+	private ConstraintLogic logic;
+	private DebugListener out;
+	
+	public GroupConstraintDebug(ConstraintLogic logic, DebugListener listener) {
+		this.logic = logic;
+		this.out = listener;
+	}
+
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+        this.out.groupConstraintPreExecute();
+        long start = System.currentTimeMillis();
+        RdfBindingSet returnSet = this.logic.constrain(bindings, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
+        long end = System.currentTimeMillis();
+        this.out.groupConstraintPostExecute(end-start, returnSet);
+        return returnSet;
+	}
+
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/debug/OptionalConstraintDebug.java work-copy/src/main/name/levering/ryan/sparql/logic/debug/OptionalConstraintDebug.java
--- upstream/src/main/name/levering/ryan/sparql/logic/debug/OptionalConstraintDebug.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/debug/OptionalConstraintDebug.java	2007-02-21 07:09:24.000000000 -0500
@@ -1,6 +1,7 @@
 package name.levering.ryan.sparql.logic.debug;
 
 import java.util.Collection;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -16,11 +17,10 @@
 		this.out = listener;
 	}
 
-	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
         this.out.optionalConstraintPreExecute();
         long start = System.currentTimeMillis();
-        RdfBindingSet returnSet = this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+        RdfBindingSet returnSet = this.logic.constrain(p);
         long end = System.currentTimeMillis();
         this.out.optionalConstraintPostExecute(end-start, returnSet);
         return returnSet;
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/debug/OptionalConstraintDebug.java~ work-copy/src/main/name/levering/ryan/sparql/logic/debug/OptionalConstraintDebug.java~
--- upstream/src/main/name/levering/ryan/sparql/logic/debug/OptionalConstraintDebug.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/debug/OptionalConstraintDebug.java~	2007-02-21 07:05:14.000000000 -0500
@@ -0,0 +1,29 @@
+package name.levering.ryan.sparql.logic.debug;
+
+import java.util.Collection;
+import java.util.Map;
+
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
+
+public class OptionalConstraintDebug implements ConstraintLogic {
+
+	private ConstraintLogic logic;
+	private DebugListener out;
+
+	public OptionalConstraintDebug(ConstraintLogic logic, DebugListener listener) {
+		this.logic= logic;
+		this.out = listener;
+	}
+
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+        this.out.optionalConstraintPreExecute();
+        long start = System.currentTimeMillis();
+        RdfBindingSet returnSet = this.logic.constrain(bindings, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
+        long end = System.currentTimeMillis();
+        this.out.optionalConstraintPostExecute(end-start, returnSet);
+        return returnSet;
+	}
+
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/debug/TripleConstraintDebug.java work-copy/src/main/name/levering/ryan/sparql/logic/debug/TripleConstraintDebug.java
--- upstream/src/main/name/levering/ryan/sparql/logic/debug/TripleConstraintDebug.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/debug/TripleConstraintDebug.java	2007-02-21 07:09:43.000000000 -0500
@@ -6,6 +6,7 @@
 package name.levering.ryan.sparql.logic.debug;
 
 import java.util.Collection;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -24,11 +25,10 @@
         this.out = listener;
     }
 
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source,
-            Collection defaultDatasets, Collection namedDatasets) {
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
         this.out.tripleFetchPreExecute(this.data);
         long start = System.currentTimeMillis();
-        RdfBindingSet returnSet = this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+        RdfBindingSet returnSet = this.logic.constrain(p);
         long end = System.currentTimeMillis();
         this.out.tripleFetchPostExecute(end-start, returnSet);
         return returnSet;
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/debug/TripleConstraintDebug.java~ work-copy/src/main/name/levering/ryan/sparql/logic/debug/TripleConstraintDebug.java~
--- upstream/src/main/name/levering/ryan/sparql/logic/debug/TripleConstraintDebug.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/debug/TripleConstraintDebug.java~	2007-02-10 09:06:34.000000000 -0500
@@ -0,0 +1,38 @@
+/*
+ * SPARQL Engine
+ * Copyright (C) 2005 Ryan Levering, All rights reserved.
+ * See LICENSE for full license information
+ */
+package name.levering.ryan.sparql.logic.debug;
+
+import java.util.Collection;
+import java.util.Map;
+
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.model.data.TripleConstraintData;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
+
+public class TripleConstraintDebug implements ConstraintLogic {
+
+    private final ConstraintLogic logic;
+    private final TripleConstraintData data;
+	private final DebugListener out;
+
+    public TripleConstraintDebug(TripleConstraintData data, ConstraintLogic logic, DebugListener listener) {
+        this.data = data;
+        this.logic = logic;
+        this.out = listener;
+    }
+
+    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source,
+            Collection defaultDatasets, Collection namedDatasets, Map knownValues, Map knownFilters) {
+        this.out.tripleFetchPreExecute(this.data);
+        long start = System.currentTimeMillis();
+        RdfBindingSet returnSet = this.logic.constrain(bindings, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
+        long end = System.currentTimeMillis();
+        this.out.tripleFetchPostExecute(end-start, returnSet);
+        return returnSet;
+    }
+    
+}
\ No newline at end of file
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/debug/UnionConstraintDebug.java work-copy/src/main/name/levering/ryan/sparql/logic/debug/UnionConstraintDebug.java
--- upstream/src/main/name/levering/ryan/sparql/logic/debug/UnionConstraintDebug.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/debug/UnionConstraintDebug.java	2007-02-21 07:09:49.000000000 -0500
@@ -1,6 +1,7 @@
 package name.levering.ryan.sparql.logic.debug;
 
 import java.util.Collection;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -16,11 +17,10 @@
 		this.out = listener;
 	}
 
-	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
         this.out.unionConstrainPreExecute();
         long start = System.currentTimeMillis();
-        RdfBindingSet returnSet = this.unionLogic.constrain(bindings, source, defaultDatasets, namedDatasets);
+        RdfBindingSet returnSet = this.unionLogic.constrain(p);
         long end = System.currentTimeMillis();
         this.out.unionConstraintPostExecute(end-start, returnSet);
         return returnSet;
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/debug/UnionConstraintDebug.java~ work-copy/src/main/name/levering/ryan/sparql/logic/debug/UnionConstraintDebug.java~
--- upstream/src/main/name/levering/ryan/sparql/logic/debug/UnionConstraintDebug.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/debug/UnionConstraintDebug.java~	2007-02-21 07:05:16.000000000 -0500
@@ -0,0 +1,29 @@
+package name.levering.ryan.sparql.logic.debug;
+
+import java.util.Collection;
+import java.util.Map;
+
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
+
+public class UnionConstraintDebug implements ConstraintLogic {
+
+	private ConstraintLogic unionLogic;
+	private DebugListener out;
+
+	public UnionConstraintDebug(ConstraintLogic unionConstraintLogic, DebugListener listener) {
+		this.unionLogic = unionConstraintLogic;
+		this.out = listener;
+	}
+
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+        this.out.unionConstrainPreExecute();
+        long start = System.currentTimeMillis();
+        RdfBindingSet returnSet = this.unionLogic.constrain(bindings, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
+        long end = System.currentTimeMillis();
+        this.out.unionConstraintPostExecute(end-start, returnSet);
+        return returnSet;
+	}
+
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/DefaultAskQueryLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/DefaultAskQueryLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/DefaultAskQueryLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/DefaultAskQueryLogic.java	2007-02-21 07:51:29.000000000 -0500
@@ -13,6 +13,7 @@
 import name.levering.ryan.sparql.model.GroupConstraint;
 import name.levering.ryan.sparql.model.data.AskQueryData;
 import name.levering.ryan.sparql.model.logic.AskQueryLogic;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
 
 /**
  * This is the simplest query logic in SPARQL, as it doesn't have to deal with
@@ -48,14 +49,17 @@
      * @return true if the delegated query data binds any value rows
      */
     public boolean execute(RdfSource source) {
-        // Grab the necessary fields from the data
+		  ConstraintLogic.CallParams p = new ConstraintLogic.CallParams();
+		  p.bindings = new RdfBindingSetImpl();
+		  p.source = source;
+
+		  // Grab the necessary fields from the data
         GroupConstraint constraint = this.data.getConstraint();
-        Collection defaultDatasets = this.data.getDefaultDatasets();
-        Collection namedDatasets = this.data.getNamedDatasets();
+        p.defaultDatasets = this.data.getDefaultDatasets();
+        p.namedDatasets = this.data.getNamedDatasets();
 
         // First bind the result table
-        RdfBindingSet results = constraint.constrain(new RdfBindingSetImpl(),
-                source, defaultDatasets, namedDatasets);
+        RdfBindingSet results = constraint.constrain(p);
 
         // Return whether or not the iterator returns any rows
         return results.iterator().hasNext();
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/DefaultAskQueryLogic.java~ work-copy/src/main/name/levering/ryan/sparql/logic/DefaultAskQueryLogic.java~
--- upstream/src/main/name/levering/ryan/sparql/logic/DefaultAskQueryLogic.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/DefaultAskQueryLogic.java~	2007-02-21 07:45:53.000000000 -0500
@@ -0,0 +1,67 @@
+/*
+ * SPARQL Engine
+ * Copyright (C) 2005 Ryan Levering, All rights reserved.
+ * See LICENSE for full license information
+ */
+package name.levering.ryan.sparql.logic;
+
+import java.util.Collection;
+
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.common.impl.RdfBindingSetImpl;
+import name.levering.ryan.sparql.model.GroupConstraint;
+import name.levering.ryan.sparql.model.data.AskQueryData;
+import name.levering.ryan.sparql.model.logic.AskQueryLogic;
+
+/**
+ * This is the simplest query logic in SPARQL, as it doesn't have to deal with
+ * any set transformations. Generally speaking, the data in the source is
+ * bound against any constraints in the ask query and if any rows of
+ * values were bound, it returns true.
+ * 
+ * @author Ryan Levering
+ * @version 1.0
+ */
+public class DefaultAskQueryLogic implements AskQueryLogic {
+
+    /**
+     * The data to delegate the data requests to.
+     */
+    private final AskQueryData data;
+
+    /**
+     * Creates a new object that handles the logic of the ask query, delegating
+     * data calls to the data object.
+     * 
+     * @param data the ask query data object delegate
+     */
+    public DefaultAskQueryLogic(AskQueryData data) {
+        this.data = data;
+    }
+
+    /**
+     * Executes the query against an RdfSource and returns true if the query
+     * bound any value rows.
+     * 
+     * @param source the data source of RDF triples
+     * @return true if the delegated query data binds any value rows
+     */
+    public boolean execute(RdfSource source) {
+		  ConstraintLogic.CallParams p = new ConstraintLogic.CallParams();
+		  p.bindings = new RdfBindingSetImpl();
+		  p.source = source;
+
+		  // Grab the necessary fields from the data
+        GroupConstraint constraint = this.data.getConstraint();
+        p.defaultDatasets = this.data.getDefaultDatasets();
+        p.namedDatasets = this.data.getNamedDatasets();
+
+        // First bind the result table
+        RdfBindingSet results = constraint.constrain(p);
+
+        // Return whether or not the iterator returns any rows
+        return results.iterator().hasNext();
+    }
+
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/DefaultConstructQueryLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/DefaultConstructQueryLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/DefaultConstructQueryLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/DefaultConstructQueryLogic.java	2007-02-21 07:51:22.000000000 -0500
@@ -22,6 +22,7 @@
 import name.levering.ryan.sparql.model.GroupConstraint;
 import name.levering.ryan.sparql.model.TripleConstraint;
 import name.levering.ryan.sparql.model.data.ConstructQueryData;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
 import name.levering.ryan.sparql.model.logic.ConstructQueryLogic;
 import name.levering.ryan.sparql.model.logic.OrderExpressionLogic;
 import name.levering.ryan.sparql.model.logic.helper.GraphTranslationLogic;
@@ -30,6 +31,7 @@
 import org.openrdf.model.BNode;
 import org.openrdf.model.URI;
 import org.openrdf.model.Value;
+import org.openrdf.model.BNode;
 
 /**
  * This query logic constructs an RDF graph by applying an RDF template to a set
@@ -79,17 +81,20 @@
      * @return an RDF graph containing the formed triples
      */
     public RdfGraph execute(RdfSource source) {
+		  ConstraintLogic.CallParams p = new ConstraintLogic.CallParams();
+		  p.bindings = new RdfBindingSetImpl();
+		  p.source = source;
+		
         // Grab the necessary fields from the data
         GroupConstraint constraint = this.data.getConstraint();
-        Collection defaultDatasets = this.data.getDefaultDatasets();
-        Collection namedDatasets = this.data.getNamedDatasets();
+        p.defaultDatasets = this.data.getDefaultDatasets();
+        p.namedDatasets = this.data.getNamedDatasets();
         List orderExpressions = this.data.getOrderExpressions();
         int limit = this.data.getLimit();
         int offset = this.data.getOffset();
 
         // First bind the result table
-        RdfBindingSet results = constraint.constrain(new RdfBindingSetImpl(),
-                source, defaultDatasets, namedDatasets);
+        RdfBindingSet results = constraint.constrain(p);
 
         // Now apply ordering in reverse order to give priority to the first
         // variable
@@ -105,7 +110,7 @@
         if (offset >= 0) {
             results = this.rangeLogic.offset(results, offset);
         }
-
+		
         return this.translationLogic.translate(this.data.getTriples(), results);
     }
 
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/DefaultConstructQueryLogic.java~ work-copy/src/main/name/levering/ryan/sparql/logic/DefaultConstructQueryLogic.java~
--- upstream/src/main/name/levering/ryan/sparql/logic/DefaultConstructQueryLogic.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/DefaultConstructQueryLogic.java~	2007-02-21 07:46:14.000000000 -0500
@@ -0,0 +1,116 @@
+/*
+ * SPARQL Engine
+ * Copyright (C) 2005 Ryan Levering, All rights reserved.
+ * See LICENSE for full license information
+ */
+package name.levering.ryan.sparql.logic;
+
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+
+import name.levering.ryan.sparql.common.RdfBindingRow;
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfGraph;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.common.impl.RdfBindingSetImpl;
+import name.levering.ryan.sparql.common.impl.RdfGraphImpl;
+import name.levering.ryan.sparql.common.impl.SPARQLValueFactory;
+import name.levering.ryan.sparql.common.impl.StatementImpl;
+import name.levering.ryan.sparql.model.GroupConstraint;
+import name.levering.ryan.sparql.model.TripleConstraint;
+import name.levering.ryan.sparql.model.data.ConstructQueryData;
+import name.levering.ryan.sparql.model.logic.ConstructQueryLogic;
+import name.levering.ryan.sparql.model.logic.OrderExpressionLogic;
+import name.levering.ryan.sparql.model.logic.helper.GraphTranslationLogic;
+import name.levering.ryan.sparql.model.logic.helper.SetRangeLogic;
+
+import org.openrdf.model.BNode;
+import org.openrdf.model.URI;
+import org.openrdf.model.Value;
+import org.openrdf.model.BNode;
+
+/**
+ * This query logic constructs an RDF graph by applying an RDF template to a set
+ * of value bindings. It must first bind the variables values, then apply
+ * ordering and cropping, and finally apply the values to the RDF template.
+ * 
+ * @author Ryan Levering
+ * @version 1.0
+ */
+public class DefaultConstructQueryLogic implements ConstructQueryLogic {
+
+    /**
+     * The data to delegate the data requests to.
+     */
+    private final ConstructQueryData data;
+
+    /**
+     * The logic to handle limiting the rows of the binding set results.
+     */
+    private final SetRangeLogic rangeLogic;
+    
+    /**
+     * Translation logic to create the construct graph.
+     */
+    private final GraphTranslationLogic translationLogic;
+
+    /**
+     * Creates a new object that handles the logic of the construct query,
+     * delegating data calls to the data object.
+     * 
+     * @param data the construct query data object delegate
+	 * @param rangeLogic the logic to use to limit or offset the constrained binding set
+	 * @param translationLogic the logic to create the graph from the bindings, the core of the construct
+     */
+    public DefaultConstructQueryLogic(ConstructQueryData data,
+            SetRangeLogic rangeLogic, GraphTranslationLogic translationLogic) {
+        this.data = data;
+        this.rangeLogic = rangeLogic;
+        this.translationLogic = translationLogic;
+    }
+
+    /**
+     * Executes the query against an RdfSource and returns an RDF graph which is
+     * formed by applying a variable RDF template.
+     * 
+     * @param source the data source of RDF triples
+     * @return an RDF graph containing the formed triples
+     */
+    public RdfGraph execute(RdfSource source) {
+		  ConstraintLogic.CallParams p = new ConstraintLogic.CallParams();
+		  p.bindings = new RdfBindingSetImpl();
+		  p.source = source;
+		
+        // Grab the necessary fields from the data
+        GroupConstraint constraint = this.data.getConstraint();
+        p.defaultDatasets = this.data.getDefaultDatasets();
+        p.namedDatasets = this.data.getNamedDatasets();
+        List orderExpressions = this.data.getOrderExpressions();
+        int limit = this.data.getLimit();
+        int offset = this.data.getOffset();
+
+        // First bind the result table
+        RdfBindingSet results = constraint.constrain(p);
+
+        // Now apply ordering in reverse order to give priority to the first
+        // variable
+        for (int i = orderExpressions.size() - 1; i >= 0; i--) {
+            OrderExpressionLogic orderer = (OrderExpressionLogic) orderExpressions.get(i);
+            orderer.order(results);
+        }
+
+        // Now apply limiting and offsetting
+        if (limit >= 0) {
+            results = this.rangeLogic.limit(results, limit);
+        }
+        if (offset >= 0) {
+            results = this.rangeLogic.offset(results, offset);
+        }
+		
+        return this.translationLogic.translate(this.data.getTriples(), results);
+    }
+
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/DefaultDescribeQueryLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/DefaultDescribeQueryLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/DefaultDescribeQueryLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/DefaultDescribeQueryLogic.java	2007-02-21 07:51:39.000000000 -0500
@@ -22,6 +22,7 @@
 import name.levering.ryan.sparql.common.impl.RdfGraphImpl;
 import name.levering.ryan.sparql.model.GroupConstraint;
 import name.levering.ryan.sparql.model.data.DescribeQueryData;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
 import name.levering.ryan.sparql.model.logic.DescribeQueryLogic;
 import name.levering.ryan.sparql.model.logic.OrderExpressionLogic;
 import name.levering.ryan.sparql.model.logic.helper.SetProjectionLogic;
@@ -83,17 +84,23 @@
 	 * @return an RDF graph containing the formed triples
 	 */
 	public RdfGraph execute(RdfSource source) {
+		ConstraintLogic.CallParams p = new ConstraintLogic.CallParams();
+		p.bindings = new RdfBindingSetImpl();
+		p.source = source;
+		
 		// Grab the necessary fields from the data
 		GroupConstraint constraint = this.data.getConstraint();
-		Collection defaultDatasets = this.data.getDefaultDatasets();
-		Collection namedDatasets = this.data.getNamedDatasets();
+		p.defaultDatasets = this.data.getDefaultDatasets();
+		p.namedDatasets = this.data.getNamedDatasets();
 		List orderExpressions = this.data.getOrderExpressions();
 		List queryResources = this.data.getQueryResources();
 		int limit = this.data.getLimit();
 		int offset = this.data.getOffset();
 
 		// First bind the result table
-		RdfBindingSet results = constraint.constrain(new RdfBindingSetImpl(), source, defaultDatasets, namedDatasets);
+		RdfBindingSet results = new RdfBindingSetImpl();
+		if (constraint != null)
+			results = constraint.constrain(p);
 
 		// Now project to the solution set
 		List variables = new ArrayList();
@@ -106,7 +113,7 @@
 		results = this.logic.project(results, variables);
 
 		// Now apply ordering in reverse order
-		for (int i = orderExpressions.size(); i >= 0; i--) {
+		for (int i = orderExpressions.size()-1; i >= 0; i--) {
 			OrderExpressionLogic orderer = (OrderExpressionLogic) orderExpressions.get(i);
 			orderer.order(results);
 		}
@@ -182,7 +189,7 @@
 					descriptions.addAll(describe(statement.getObject(), source, alreadyDescribed));
 				}
 			}
-			descriptions.add(statements.next());
+			descriptions.add(statement);
 		}
 		return descriptions;
 	}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/DefaultDescribeQueryLogic.java~ work-copy/src/main/name/levering/ryan/sparql/logic/DefaultDescribeQueryLogic.java~
--- upstream/src/main/name/levering/ryan/sparql/logic/DefaultDescribeQueryLogic.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/DefaultDescribeQueryLogic.java~	2007-02-21 07:46:33.000000000 -0500
@@ -0,0 +1,196 @@
+/*
+ * SPARQL Engine
+ * Copyright (C) 2005 Ryan Levering, All rights reserved.
+ * See LICENSE for full license information
+ */
+package name.levering.ryan.sparql.logic;
+
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Set;
+
+import name.levering.ryan.sparql.common.LenientStatement;
+import name.levering.ryan.sparql.common.RdfBindingRow;
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfGraph;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.common.Variable;
+import name.levering.ryan.sparql.common.impl.RdfBindingSetImpl;
+import name.levering.ryan.sparql.common.impl.RdfGraphImpl;
+import name.levering.ryan.sparql.model.GroupConstraint;
+import name.levering.ryan.sparql.model.data.DescribeQueryData;
+import name.levering.ryan.sparql.model.logic.DescribeQueryLogic;
+import name.levering.ryan.sparql.model.logic.OrderExpressionLogic;
+import name.levering.ryan.sparql.model.logic.helper.SetProjectionLogic;
+import name.levering.ryan.sparql.model.logic.helper.SetRangeLogic;
+
+import org.openrdf.model.BNode;
+import org.openrdf.model.Resource;
+import org.openrdf.model.Value;
+
+/**
+ * This query logic constructs an RDF graph by finding the closest non-blank
+ * nodes in every relationship direction. It must first bind the variables
+ * values, then apply ordering and cropping, and finally get the information
+ * about the bound values to form the description graph.
+ * 
+ * @author Ryan Levering
+ * @version 1.1
+ */
+public class DefaultDescribeQueryLogic implements DescribeQueryLogic {
+
+	/**
+	 * The data to delegate the data requests to.
+	 */
+	private final DescribeQueryData data;
+
+	/**
+	 * The logic that projects the binding set to the desired variables for
+	 * construction.
+	 */
+	private final SetProjectionLogic logic;
+
+	/**
+	 * The logic to handle limiting the rows of the binding set results.
+	 */
+	private final SetRangeLogic rangeLogic;
+
+	/**
+	 * Creates a new object that handles the logic of the describe query,
+	 * delegating data calls to the data object.
+	 * 
+	 * @param data the describe query data object delegate
+	 * @param rangeLogic the logic to use to limit or offset the constrained
+	 *            binding set
+	 * @param logic the logic to use to project the variables to the desired
+	 *            variables to describe
+	 */
+	public DefaultDescribeQueryLogic(DescribeQueryData data, SetProjectionLogic logic, SetRangeLogic rangeLogic) {
+		this.data = data;
+		this.logic = logic;
+		this.rangeLogic = rangeLogic;
+	}
+
+	/**
+	 * Executes the query against an RdfSource and returns an RDF graph which
+	 * describes all of the returned resources by returning all the predicate
+	 * paths that eventually reach a non-blank node.
+	 * 
+	 * @param source the data source of RDF triples
+	 * @return an RDF graph containing the formed triples
+	 */
+	public RdfGraph execute(RdfSource source) {
+		ConstraintLogic.CallParams p = new ConstraintLogic.CallParams();
+		p.bindings = new RdfBindingSetImpl();
+		p.source = source;
+		
+		// Grab the necessary fields from the data
+		GroupConstraint constraint = this.data.getConstraint();
+		p.defaultDatasets = this.data.getDefaultDatasets();
+		p.namedDatasets = this.data.getNamedDatasets();
+		List orderExpressions = this.data.getOrderExpressions();
+		List queryResources = this.data.getQueryResources();
+		int limit = this.data.getLimit();
+		int offset = this.data.getOffset();
+
+		// First bind the result table
+		RdfBindingSet results = new RdfBindingSetImpl();
+		if (constraint != null)
+			results = constraint.constrain(p);
+
+		// Now project to the solution set
+		List variables = new ArrayList();
+		for (Iterator i = queryResources.iterator(); i.hasNext();) {
+			Object resource = i.next();
+			if (resource instanceof Variable) {
+				variables.add(resource);
+			}
+		}
+		results = this.logic.project(results, variables);
+
+		// Now apply ordering in reverse order
+		for (int i = orderExpressions.size()-1; i >= 0; i--) {
+			OrderExpressionLogic orderer = (OrderExpressionLogic) orderExpressions.get(i);
+			orderer.order(results);
+		}
+
+		// Now apply limiting and offsetting
+		if (limit >= 0) {
+			results = this.rangeLogic.limit(results, limit);
+		}
+		if (offset >= 0) {
+			results = this.rangeLogic.offset(results, offset);
+		}
+
+		// Now find the next level of concrete nodes
+		// For every resource in the solution set
+
+		// Add the static resources to describe
+		// TODO Fix this when you figure out the semantics
+		Collection[] resources = new Collection[queryResources.size()];
+		for (int i = 0; i < resources.length; i++) {
+			resources[i] = new ArrayList();
+			if (queryResources.get(i) instanceof Value) {
+				resources[i].add(queryResources.get(i));
+			}
+		}
+
+		for (Iterator solutions = results.iterator(); solutions.hasNext();) {
+			RdfBindingRow row = (RdfBindingRow) solutions.next();
+			for (int i = 0; i < resources.length; i++) {
+				if (queryResources.get(i) instanceof Variable) {
+					Value value = row.getValue((Variable) queryResources.get(i));
+					if (value instanceof Resource) {
+						// Found a resource, must describe
+						resources[i].add(value);
+					}
+				}
+			}
+		}
+
+		RdfGraphImpl graph = new RdfGraphImpl();
+		for (int i = 0; i < resources.length; i++) {
+			for (Iterator varResources = resources[i].iterator(); varResources.hasNext();) {
+				graph.addTriples(describe((Resource) varResources.next(), source, new HashSet()));
+			}
+		}
+
+		return graph;
+	}
+
+	/**
+	 * Returns all the statements that describe a particular resource.
+	 * 
+	 * @param value the value to describe
+	 * @param source the RDF triple source
+	 * @param alreadyDescribed the set of already described values so we don't duplicate the descriptions
+	 * @return all of the statements that give a one-level description of a
+	 *         resource
+	 */
+	private Collection describe(Value value, RdfSource source, Set alreadyDescribed) {
+		// First add the current node to the described list
+		alreadyDescribed.add(value);
+
+		// Now accumulate statements
+		Collection descriptions = new ArrayList();
+		Iterator statements = source.getDefaultStatements(value, null, null);
+		while (statements.hasNext()) {
+			LenientStatement statement = (LenientStatement) statements.next();
+
+			// If the statement points to a blank node, recurse and describe
+			// that
+			if (statement.getObject() instanceof BNode) {
+				// Check if we covered the blank node already to prevent loops
+				if (!alreadyDescribed.contains(statement.getObject())) {
+					descriptions.addAll(describe(statement.getObject(), source, alreadyDescribed));
+				}
+			}
+			descriptions.add(statement);
+		}
+		return descriptions;
+	}
+
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/DefaultSelectQueryLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/DefaultSelectQueryLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/DefaultSelectQueryLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/DefaultSelectQueryLogic.java	2007-02-21 07:51:46.000000000 -0500
@@ -12,6 +12,7 @@
 import name.levering.ryan.sparql.common.RdfSource;
 import name.levering.ryan.sparql.model.GroupConstraint;
 import name.levering.ryan.sparql.model.data.SelectQueryData;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
 import name.levering.ryan.sparql.model.logic.OrderExpressionLogic;
 import name.levering.ryan.sparql.model.logic.SelectQueryLogic;
 import name.levering.ryan.sparql.model.logic.helper.SetDistinctionLogic;
@@ -74,10 +75,13 @@
      * @return an RDF graph containing the formed triples
      */
     public RdfBindingSet execute(RdfSource source) {
+		  ConstraintLogic.CallParams p = new ConstraintLogic.CallParams();
+		  p.source = source;
+		
         // Grab the necessary fields from the data
         GroupConstraint constraint = this.data.getConstraint();
-        Collection defaultDatasets = this.data.getDefaultDatasets();
-        Collection namedDatasets = this.data.getNamedDatasets();
+        p.defaultDatasets = this.data.getDefaultDatasets();
+        p.namedDatasets = this.data.getNamedDatasets();
         List orderExpressions = this.data.getOrderExpressions();
         List queryExpressions = this.data.getQueryVariables();
         int limit = this.data.getLimit();
@@ -85,8 +89,7 @@
         boolean distinct = this.data.getDistinct();
 
         // First bind the result table
-        RdfBindingSet results = constraint.constrain(null,
-                source, defaultDatasets, namedDatasets);
+        RdfBindingSet results = constraint.constrain(p);
 
         // Now project to the solution set or the variable set
         if (!queryExpressions.isEmpty()) {
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/DefaultSelectQueryLogic.java~ work-copy/src/main/name/levering/ryan/sparql/logic/DefaultSelectQueryLogic.java~
--- upstream/src/main/name/levering/ryan/sparql/logic/DefaultSelectQueryLogic.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/DefaultSelectQueryLogic.java~	2007-02-21 07:49:18.000000000 -0500
@@ -0,0 +1,122 @@
+/*
+ * SPARQL Engine
+ * Copyright (C) 2005 Ryan Levering, All rights reserved.
+ * See LICENSE for full license information
+ */
+package name.levering.ryan.sparql.logic;
+
+import java.util.Collection;
+import java.util.List;
+
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.model.GroupConstraint;
+import name.levering.ryan.sparql.model.data.SelectQueryData;
+import name.levering.ryan.sparql.model.logic.OrderExpressionLogic;
+import name.levering.ryan.sparql.model.logic.SelectQueryLogic;
+import name.levering.ryan.sparql.model.logic.helper.SetDistinctionLogic;
+import name.levering.ryan.sparql.model.logic.helper.SetProjectionLogic;
+import name.levering.ryan.sparql.model.logic.helper.SetRangeLogic;
+
+/**
+ * This query logic is the basic logic that returns bound variable values. It
+ * constrains the bound variables, applying various transformations to the set,
+ * and eventually returning it as a table of bound variable rows.
+ * 
+ * @author Ryan Levering
+ * @version 1.0
+ */
+public class DefaultSelectQueryLogic implements SelectQueryLogic {
+
+    /**
+     * The data to delegate the data requests to.
+     */
+    private final SelectQueryData data;
+
+    /**
+     * The logic used to do the set projection onto the result variables.
+     */
+    private final SetProjectionLogic logic;
+
+    /**
+     * The logic to remove duplicates from a set.
+     */
+    private final SetDistinctionLogic distinctLogic;
+    
+    /**
+     * The logic to handle limiting the rows of the binding set results.
+     */
+    private final SetRangeLogic rangeLogic;
+
+    /**
+     * Creates a new object that handles the logic of the select query,
+     * delegating data calls to the data object.
+     * 
+     * @param data the select query data object delegate
+     * @param logic the logic to use to project the variables
+     * @param distinctLogic the logic to use to check for distinction
+     * @param rangeLogic the logic to use to limit and offset
+     */
+    public DefaultSelectQueryLogic(SelectQueryData data,
+            SetProjectionLogic logic, SetDistinctionLogic distinctLogic, SetRangeLogic rangeLogic) {
+        this.data = data;
+        this.logic = logic;
+        this.distinctLogic = distinctLogic;
+        this.rangeLogic = rangeLogic;
+    }
+
+    /**
+     * Executes the query against an RdfSource and returns a possibly
+     * transformed set of the bound variable values that satisfy the
+     * constraints.
+     * 
+     * @param source the data source of RDF triples
+     * @return an RDF graph containing the formed triples
+     */
+    public RdfBindingSet execute(RdfSource source) {
+		  ConstraintLogic.CallParams p = new ConstraintLogic.CallParams();
+		  p.source = source;
+		
+        // Grab the necessary fields from the data
+        GroupConstraint constraint = this.data.getConstraint();
+        p.defaultDatasets = this.data.getDefaultDatasets();
+        p.namedDatasets = this.data.getNamedDatasets();
+        List orderExpressions = this.data.getOrderExpressions();
+        List queryExpressions = this.data.getQueryVariables();
+        int limit = this.data.getLimit();
+        int offset = this.data.getOffset();
+        boolean distinct = this.data.getDistinct();
+
+        // First bind the result table
+        RdfBindingSet results = constraint.constrain(p);
+
+        // Now project to the solution set or the variable set
+        if (!queryExpressions.isEmpty()) {
+            results = this.logic.project(results, queryExpressions);
+        } else {
+        	results = this.logic.project(results, this.data.getVariables());
+        }
+
+        // Now apply distinct
+        if (distinct) {
+            results = this.distinctLogic.makeDistinct(results);
+        }
+
+        // Now apply ordering in reverse order
+        for (int i = orderExpressions.size() - 1; i >= 0; i--) {
+            OrderExpressionLogic orderer = (OrderExpressionLogic) orderExpressions.get(i);
+            results = orderer.order(results);
+        }
+
+        // Now apply limiting and offsetting
+        if (limit >= 0) {
+            results = this.rangeLogic.limit(results, limit);
+        }
+        if (offset >= 0) {
+            results = this.rangeLogic.offset(results, offset);
+        }
+
+        return results;
+    }
+
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/DefaultValueOrderingLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/DefaultValueOrderingLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/DefaultValueOrderingLogic.java	2006-12-02 11:09:25.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/DefaultValueOrderingLogic.java	2006-12-02 11:14:00.000000000 -0500
@@ -1,5 +1,9 @@
 package name.levering.ryan.sparql.logic;
 
+import name.levering.ryan.sparql.common.impl.DateTime;
+
+import name.levering.ryan.sparql.model.logic.NumericPromotionLogic;
+import name.levering.ryan.sparql.model.logic.helper.ValueConversionLogic;
 import name.levering.ryan.sparql.model.logic.helper.ValueOrderingLogic;
 
 import org.openrdf.model.BNode;
@@ -22,6 +26,13 @@
  * @version 1.0
  */
 public class DefaultValueOrderingLogic implements ValueOrderingLogic {
+	NumericPromotionLogic promoter;
+	ValueConversionLogic converter;
+	
+	public DefaultValueOrderingLogic(NumericPromotionLogic promoter, ValueConversionLogic converter) {
+		this.promoter = promoter;
+		this.converter = converter;
+	}
 
 	/**
 	 * Compares two value objects according to section 10.1.
@@ -64,14 +75,41 @@
 			return -1;
 		}
 
-		// First value is an untyped literal
-		if (value1 instanceof Literal && ((Literal) value1).getDatatype() == null) {
-			if (value2 == null || value2 instanceof BNode || value2 instanceof URI) {
+		// First value is a literal
+		if (value1 instanceof Literal) {
+			if (value2 == null || value2 instanceof BNode || value2 instanceof URI)
 				return 1;
+
+			if (value2 instanceof Literal) {
+				if (((Literal) value1).getDatatype() == null && ((Literal) value2).getDatatype() == null)
+					return ((Literal) value1).getLabel().compareTo(((Literal) value2).getLabel());
+					
+				if (((Literal) value1).getDatatype() == null)
+					return -1;
+				if (((Literal) value2).getDatatype() == null)
+					return 1;
+				
+				Literal[] promoted = promoter.promote(new Literal[] { (Literal) value1, (Literal) value2 } );
+				
+				Object v1 = converter.convertLiteral(promoted[0]);
+				Object v2 = converter.convertLiteral(promoted[1]);
+				
+				if (v1 instanceof Double)
+					return ((Double)v1).compareTo((Double)v2);
+				if (v1 instanceof Float)
+					return ((Float)v1).compareTo((Float)v2);
+				if (v1 instanceof Long)
+					return ((Long)v1).compareTo((Long)v2);
+				if (v1 instanceof Integer)
+					return ((Integer)v1).compareTo((Integer)v2);
+				if (v1 instanceof Boolean)
+					return ((Boolean)v1).compareTo((Boolean)v2);
+				if (v1 instanceof DateTime)
+					return ((DateTime)v1).compareTo((DateTime)v2);
+				if (v1 instanceof String)
+					return ((String)v1).compareTo((String)v2);
 			}
-			if (value2 instanceof Literal && ((Literal) value2).getDatatype() == null) {
-				return ((Literal) value1).getLabel().compareTo(((Literal) value2).getLabel());
-			}
+			
 			return -1;
 		}
 
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/expression/GreaterThanEqualsLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/expression/GreaterThanEqualsLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/expression/GreaterThanEqualsLogic.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/expression/GreaterThanEqualsLogic.java	2006-12-02 11:00:48.000000000 -0500
@@ -96,11 +96,10 @@
      * 
      * @param string1 the first String to compare
      * @param string2 the second String to compare
-     * @return never
-     * @throws UnsupportedOperationException always
+     * @return true if the first string is greater than or equal to the second
      */
     public boolean evaluateString(String string1, String string2) {
-        throw new UnsupportedOperationException("Strings cannot be compared using a >= operation");
+        return string1.compareTo(string2) >= 0;
     }
 
     /**
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/expression/GreaterThanLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/expression/GreaterThanLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/expression/GreaterThanLogic.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/expression/GreaterThanLogic.java	2006-12-02 11:00:48.000000000 -0500
@@ -96,11 +96,10 @@
      * 
      * @param string1 the first String to compare
      * @param string2 the second String to compare
-     * @return never
-     * @throws UnsupportedOperationException always
+     * @return true if the first string is greater than the second
      */
     public boolean evaluateString(String string1, String string2) {
-        throw new UnsupportedOperationException("Strings cannot be compared using a > operation");
+        return string1.compareTo(string2) > 0;
     }
 
     /**
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/expression/LessThanEqualsLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/expression/LessThanEqualsLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/expression/LessThanEqualsLogic.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/expression/LessThanEqualsLogic.java	2006-12-02 11:00:48.000000000 -0500
@@ -96,11 +96,10 @@
      * 
      * @param string1 the first String to compare
      * @param string2 the second String to compare
-     * @return never
-     * @throws UnsupportedOperationException always
+     * @return true if the first string is less than or equal to the second
      */
     public boolean evaluateString(String string1, String string2) {
-        throw new UnsupportedOperationException("Strings cannot be compared using a <= operation");
+        return string1.compareTo(string2) <= 0;
     }
 
     /**
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/expression/LessThanLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/expression/LessThanLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/expression/LessThanLogic.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/expression/LessThanLogic.java	2006-12-02 11:00:48.000000000 -0500
@@ -96,11 +96,10 @@
      * 
      * @param string1 the first String to compare
      * @param string2 the second String to compare
-     * @return never
-     * @throws UnsupportedOperationException always
+     * @return true if the first string is less than the second
      */
     public boolean evaluateString(String string1, String string2) {
-        throw new UnsupportedOperationException("Fix this");
+        return string1.compareTo(string2) < 0;
     }
     
     /**
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/ExtendedConstructQueryLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/ExtendedConstructQueryLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/ExtendedConstructQueryLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/ExtendedConstructQueryLogic.java	2007-02-21 07:45:27.000000000 -0500
@@ -88,17 +88,21 @@
 	 * @return an RDF graph containing the formed triples
 	 */
 	public RdfGraph execute(RdfSource source) {
+		ConstraintLogic.CallParams p = new ConstraintLogic.CallParams();
+		p.bindings = new RdfBindingSetImpl();
+		p.source = source;
+
 		// Grab the necessary fields from the data
 		GroupConstraint constraint = this.data.getConstraint();
-		Collection defaultDatasets = this.data.getDefaultDatasets();
-		Collection namedDatasets = this.data.getNamedDatasets();
+		p.defaultDatasets = this.data.getDefaultDatasets();
+		p.namedDatasets = this.data.getNamedDatasets();
 		List orderExpressions = this.data.getOrderExpressions();
 		int limit = this.data.getLimit();
 		int offset = this.data.getOffset();
 		boolean distinct = this.data.isDistinct();
 
 		// First bind the result table
-		RdfBindingSet results = constraint.constrain(new RdfBindingSetImpl(), source, defaultDatasets, namedDatasets);
+		RdfBindingSet results = constraint.constrain(p);
 
 		// Now apply ordering in reverse order to give priority to the first
 		// variable
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/ExtendedConstructQueryLogic.java~ work-copy/src/main/name/levering/ryan/sparql/logic/ExtendedConstructQueryLogic.java~
--- upstream/src/main/name/levering/ryan/sparql/logic/ExtendedConstructQueryLogic.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/ExtendedConstructQueryLogic.java~	2007-02-10 09:06:34.000000000 -0500
@@ -0,0 +1,182 @@
+/*
+ * SPARQL Engine
+ * Copyright (C) 2005 Ryan Levering, All rights reserved.
+ * See LICENSE for full license information
+ */
+package name.levering.ryan.sparql.logic;
+
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Iterator;
+import java.util.List;
+
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfGraph;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.common.impl.RdfBindingSetImpl;
+import name.levering.ryan.sparql.common.impl.UnboundStatementImpl;
+import name.levering.ryan.sparql.common.impl.VariableImpl;
+import name.levering.ryan.sparql.model.GraphConstraint;
+import name.levering.ryan.sparql.model.GroupConstraint;
+import name.levering.ryan.sparql.model.OptionalConstraint;
+import name.levering.ryan.sparql.model.TripleConstraint;
+import name.levering.ryan.sparql.model.UnionConstraint;
+import name.levering.ryan.sparql.model.data.ExtendedConstructQueryData;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
+import name.levering.ryan.sparql.model.logic.ConstructQueryLogic;
+import name.levering.ryan.sparql.model.logic.ExpressionLogic;
+import name.levering.ryan.sparql.model.logic.OrderExpressionLogic;
+import name.levering.ryan.sparql.model.logic.helper.GraphDistinctionLogic;
+import name.levering.ryan.sparql.model.logic.helper.GraphTranslationLogic;
+import name.levering.ryan.sparql.model.logic.helper.SetRangeLogic;
+
+import org.openrdf.model.BNode;
+
+/**
+ * This query logic constructs an RDF graph by applying an RDF template to a set
+ * of value bindings. It must first bind the variables values, then apply
+ * ordering and cropping, and finally apply the values to the RDF template.
+ * 
+ * @author Ryan Levering
+ * @version 1.0
+ */
+public class ExtendedConstructQueryLogic implements ConstructQueryLogic {
+
+	/**
+	 * The data to delegate the data requests to.
+	 */
+	private final ExtendedConstructQueryData data;
+
+	/**
+	 * The logic to handle limiting the rows of the binding set results.
+	 */
+	private final SetRangeLogic rangeLogic;
+
+	/**
+	 * Translation logic to create the construct graph.
+	 */
+	private final GraphTranslationLogic translationLogic;
+
+	/**
+	 * Logic to handle the extended DISTINCT keyword.
+	 */
+	private final GraphDistinctionLogic distinctionLogic;
+
+	/**
+	 * Creates a new object that handles the logic of the construct query,
+	 * delegating data calls to the data object.
+	 * 
+	 * @param data the construct query data object delegate
+	 * @param rangeLogic the logic to use to limit or offset the constrained
+	 *            binding set
+	 * @param translationLogic the logic to create the graph from the bindings,
+	 *            the core of the construct
+	 */
+	public ExtendedConstructQueryLogic(ExtendedConstructQueryData data, SetRangeLogic rangeLogic,
+			GraphTranslationLogic translationLogic, GraphDistinctionLogic distinctLogic) {
+		this.data = data;
+		this.rangeLogic = rangeLogic;
+		this.translationLogic = translationLogic;
+		this.distinctionLogic = distinctLogic;
+	}
+
+	/**
+	 * Executes the query against an RdfSource and returns an RDF graph which is
+	 * formed by applying a variable RDF template.
+	 * 
+	 * @param source the data source of RDF triples
+	 * @return an RDF graph containing the formed triples
+	 */
+	public RdfGraph execute(RdfSource source) {
+		// Grab the necessary fields from the data
+		GroupConstraint constraint = this.data.getConstraint();
+		Collection defaultDatasets = this.data.getDefaultDatasets();
+		Collection namedDatasets = this.data.getNamedDatasets();
+		List orderExpressions = this.data.getOrderExpressions();
+		int limit = this.data.getLimit();
+		int offset = this.data.getOffset();
+		boolean distinct = this.data.isDistinct();
+
+		// First bind the result table
+		RdfBindingSet results = constraint.constrain(new RdfBindingSetImpl(), source, defaultDatasets, namedDatasets, null, null);
+
+		// Now apply ordering in reverse order to give priority to the first
+		// variable
+		for (int i = orderExpressions.size() - 1; i >= 0; i--) {
+			OrderExpressionLogic orderer = (OrderExpressionLogic) orderExpressions.get(i);
+			orderer.order(results);
+		}
+
+		// Now apply limiting and offsetting
+		if (limit >= 0) {
+			results = this.rangeLogic.limit(results, limit);
+		}
+		if (offset >= 0) {
+			results = this.rangeLogic.offset(results, offset);
+		}
+
+		Collection triples;
+		if (this.data.getTriples().isEmpty()) {
+			// Form the triples from the statements in the constraints
+			triples = getTripleConstraints(this.data.getConstraint());
+		} else {
+			triples = convertTripleConstraints(this.data.getTriples());
+		}
+		RdfGraph graph = this.translationLogic.translate(triples, results);
+
+		if (distinct) {
+			graph = this.distinctionLogic.makeDistinct(graph);
+		}
+
+		return graph;
+	}
+
+	private Collection convertTripleConstraints(Collection constraints) {
+		Collection triples = new ArrayList();
+		for (Iterator conIt = constraints.iterator(); conIt.hasNext();) {
+			TripleConstraint constraint = (TripleConstraint) conIt.next();
+			triples.add(new UnboundStatementImpl(constraint.getSubjectExpression(),
+					constraint.getPredicateExpression(), constraint.getObjectExpression()));
+		}
+		return triples;
+	}
+
+	private Collection getTripleConstraints(GroupConstraint group) {
+		Collection children = group.getConstraints();
+		Collection triples = new ArrayList();
+		for (Iterator conIt = children.iterator(); conIt.hasNext();) {
+			ConstraintLogic constraint = (ConstraintLogic) conIt.next();
+			if (constraint instanceof GroupConstraint) {
+				triples.addAll(getTripleConstraints((GroupConstraint) constraint));
+			} else if (constraint instanceof UnionConstraint) {
+				Collection groups = ((UnionConstraint) constraint).getConstraints();
+				for (Iterator groupIt = groups.iterator(); groupIt.hasNext();) {
+					triples.addAll(getTripleConstraints((GroupConstraint) groupIt.next()));
+				}
+			} else if (constraint instanceof OptionalConstraint) {
+				triples.addAll(getTripleConstraints(((OptionalConstraint) constraint).getConstraint()));
+			} else if (constraint instanceof TripleConstraint) {
+				// Take the constraints and turn any blank nodes into variables
+				// of the same name
+				ExpressionLogic subject = ((TripleConstraint) constraint).getSubjectExpression();
+				ExpressionLogic predicate = ((TripleConstraint) constraint).getPredicateExpression();
+				ExpressionLogic object = ((TripleConstraint) constraint).getObjectExpression();
+
+				if (subject instanceof BNode) {
+					subject = new VariableImpl(((BNode) subject).getID());
+				}
+				if (predicate instanceof BNode) {
+					predicate = new VariableImpl(((BNode) predicate).getID());
+				}
+				if (object instanceof BNode) {
+					object = new VariableImpl(((BNode) object).getID());
+				}
+				triples.add(new UnboundStatementImpl(subject, predicate, object));
+			} else if (constraint instanceof GraphConstraint) {
+				triples.addAll(getTripleConstraints(((GraphConstraint) constraint).getConstraint()));
+			}
+		}
+		return triples;
+	}
+
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/function/BoundLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/BoundLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/function/BoundLogic.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/BoundLogic.java	2006-12-02 11:00:48.000000000 -0500
@@ -23,12 +23,7 @@
  * @author Ryan Levering
  * @version 1.0
  */
-public class BoundLogic implements ExpressionLogic {
-
-    /**
-     * The data holding the arguments of the bound function.
-     */
-    private final CallExpressionData data;
+public class BoundLogic extends FunctionLogic {
 
     /**
      * The logic to return the correct boolean value.
@@ -43,7 +38,7 @@
      */
     public BoundLogic(CallExpressionData data, ValueConversionLogic converter) {
         //TODO Check for whether the argument is a variable
-        this.data = data;
+        super(data);
         this.converter = converter;
     }
 
@@ -58,5 +53,5 @@
         boolean result = (bindings.getValue(variable) != null);
         return this.converter.convertBoolean(result);
     }
-
+ 
 }
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/function/DataTypeLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/DataTypeLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/function/DataTypeLogic.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/DataTypeLogic.java	2006-12-02 11:00:48.000000000 -0500
@@ -21,22 +21,17 @@
  * @author Ryan Levering
  * @version 1.0
  */
-public class DataTypeLogic implements ExpressionLogic {
+public class DataTypeLogic extends FunctionLogic {
 
-	/**
-	 * The data holding the argument to evaluate.
-	 */
-	private final CallExpressionData data;
-
-	/**
-	 * Creates a new logic object that returns the IRI of the datatype of a
-	 * particular typed literal.
-	 * 
-	 * @param data the argument data
-	 */
-	public DataTypeLogic(CallExpressionData data) {
-		this.data = data;
-	}
+    /**
+     * Creates a new logic object that returns the IRI of the datatype of a
+     * particular typed literal.
+     * 
+     * @param data the argument data
+     */
+    public DataTypeLogic(CallExpressionData data) {
+        super(data);
+    }
 
 	/**
 	 * Evaluates the datatype of a typed literal that is an argument.
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/function/DecimalCastFunction.java work-copy/src/main/name/levering/ryan/sparql/logic/function/DecimalCastFunction.java
--- upstream/src/main/name/levering/ryan/sparql/logic/function/DecimalCastFunction.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/DecimalCastFunction.java	2006-12-02 11:00:48.000000000 -0500
@@ -144,11 +144,11 @@
      */
     public Value castLiteral(Literal literal) throws IllegalCastException {
         try {
-            Long.parseLong(literal.getLabel());
+            Double.parseDouble(literal.getLabel());
             return this.factory.createLiteral(literal.getLabel(),
                     SPARQLConstants.DECIMAL_TYPE);
         } catch (NumberFormatException e) {
-            throw new IllegalCastException("Unable to cast string to integer");
+            throw new IllegalCastException("Unable to cast string to double");
         }
     }
     
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/function/ExternalFunctionLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/ExternalFunctionLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/function/ExternalFunctionLogic.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/ExternalFunctionLogic.java	2006-12-02 11:00:48.000000000 -0500
@@ -23,34 +23,29 @@
  * @author Ryan Levering
  * @version 1.1
  */
-public class ExternalFunctionLogic implements ExpressionLogic {
+public class ExternalFunctionLogic extends FunctionLogic {
 
-	/**
-	 * The data containing the argument expressions to evaluate
-	 */
-	private final CallExpressionData data;
-
-	/**
-	 * The function to delegate the logic to.
-	 */
-	private final ExternalFunction function;
-
-	/**
-	 * The factory that's used to convert returns into SPARQL values.
-	 */
-	private final SPARQLValueFactory factory;
-
-	/**
-	 * Creates a new external function logic that evaluates a function call to
-	 * produce a Value.
-	 * 
-	 * @param data the data containing the function arguments and it's name
-	 */
-	public ExternalFunctionLogic(CallExpressionData data, ExternalFunction function, SPARQLValueFactory factory) {
-		this.data = data;
-		this.function = function;
-		this.factory = factory;
-	}
+    /**
+     * The function to delegate the logic to.
+     */
+    private final ExternalFunction function;
+
+    /**
+     * The factory that's used to convert returns into SPARQL values.
+     */
+    private SPARQLValueFactory factory;
+    
+    /**
+     * Creates a new external function logic that evaluates a function call to
+     * produce a Value.
+     * 
+     * @param data the data containing the function arguments and it's name
+     */
+    public ExternalFunctionLogic(CallExpressionData data, ExternalFunction function, SPARQLValueFactory factory) {
+        super(data);
+        this.function = function;
+        this.factory = factory;
+    }
 
 	/**
 	 * Evaluates the function by evaluating the arguments and passing them to
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/function/FunctionLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/FunctionLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/function/FunctionLogic.java	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/FunctionLogic.java	2006-12-02 11:14:52.000000000 -0500
@@ -0,0 +1,41 @@
+/*
+ * SPARQL Engine
+ * Copyright (C) 2005 Ryan Levering, All rights reserved.
+ * See LICENSE for full license information
+ */
+package name.levering.ryan.sparql.logic.function;
+
+import java.util.Iterator;
+import java.util.Set;
+
+import name.levering.ryan.sparql.common.RdfBindingRow;
+import name.levering.ryan.sparql.common.Variable;
+import name.levering.ryan.sparql.model.data.CallExpressionData;
+import name.levering.ryan.sparql.model.logic.ExpressionLogic;
+import name.levering.ryan.sparql.model.logic.helper.ValueConversionLogic;
+
+import org.openrdf.model.Value;
+
+/**
+ * The base class of function-type logics.
+ * 
+ * @author Ryan Levering
+ * @version 1.0
+ */
+public abstract class FunctionLogic implements ExpressionLogic {
+
+    /**
+     * The data holding the arguments of the bound function.
+     */
+    protected CallExpressionData data;
+
+    /**
+     * Creates a new logic object that handles sop:bound function calls.
+     * 
+     * @param data the data holding the expression arguments to evaluate
+     * @param converter
+     */
+    public FunctionLogic(CallExpressionData data) {
+        this.data = data;
+    }
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/function/IsBlankLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/IsBlankLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/function/IsBlankLogic.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/IsBlankLogic.java	2006-12-02 11:00:48.000000000 -0500
@@ -21,30 +21,23 @@
  * @author Ryan Levering
  * @version 1.0
  */
-public class IsBlankLogic implements ExpressionLogic {
-
-	/**
-	 * The data that holds the argument to evaluate for blank node.
-	 */
-	private final CallExpressionData data;
-
+public class IsBlankLogic extends FunctionLogic {
 	/**
 	 * The converter used to return the true or false value.
 	 */
 	private final ValueConversionLogic converter;
 
-	/**
-	 * Creates a new logic object that can evaluate whether a bound variable or
-	 * value is a blank node.
-	 * 
-	 * @param data the data holding the argument for evaluation
-	 * @param converter the value conversion logic to convert the boolean to a
-	 *            literal
-	 */
-	public IsBlankLogic(CallExpressionData data, ValueConversionLogic converter) {
-		this.data = data;
-		this.converter = converter;
-	}
+    /**
+     * Creates a new logic object that can evaluate whether a bound variable or
+     * value is a blank node.
+     * 
+     * @param data the data holding the argument for evaluation
+     * @param converter the value conversion logic to convert the boolean to a literal
+     */
+    public IsBlankLogic(CallExpressionData data, ValueConversionLogic converter) {
+        super(data);
+        this.converter = converter;
+    }
 
 	/**
 	 * Evaluates whether the value returned by an expression is a blank node.
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/function/IsIRILogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/IsIRILogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/function/IsIRILogic.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/IsIRILogic.java	2006-12-02 11:00:48.000000000 -0500
@@ -21,38 +21,30 @@
  * @author Ryan Levering
  * @version 1.0
  */
-public class IsIRILogic implements ExpressionLogic {
-
-	/**
-	 * The data that holds the argument to evaluate for IRI.
-	 */
-	private final CallExpressionData data;
-
-	/**
-	 * The converter used to return the true or false value.
-	 */
-	private final ValueConversionLogic converter;
-
-	/**
-	 * Creates a new logic object that can evaluate whether a bound variable or
-	 * value is an IRI.
-	 * 
-	 * @param data the data holding the argument for evaluation
-	 * @param converter the value conversion logic to convert the boolean to a
-	 *            literal
-	 */
-	public IsIRILogic(CallExpressionData data, ValueConversionLogic converter) {
-		this.data = data;
-		this.converter = converter;
-	}
-
-	/**
-	 * Evaluates whether the value returned by an expression is an IRI.
-	 * 
-	 * @param bindings the value bindings to use in argument evaluation
-	 * @return true or false literals representing whether the argument is an
-	 *         IRI
-	 */
+public class IsIRILogic extends FunctionLogic {
+    /**
+     * The converter used to return the true or false value.
+     */
+    private final ValueConversionLogic converter;
+    
+    /**
+     * Creates a new logic object that can evaluate whether a bound variable or
+     * value is an IRI.
+     * 
+     * @param data the data holding the argument for evaluation
+     * @param converter the value conversion logic to convert the boolean to a literal
+     */
+    public IsIRILogic(CallExpressionData data, ValueConversionLogic converter) {
+        super(data);
+        this.converter = converter;
+    }
+    
+    /**
+     * Evaluates whether the value returned by an expression is an IRI.
+     * 
+     * @param bindings the value bindings to use in argument evaluation
+     * @return true or false literals representing whether the argument is an IRI
+     */
 	public Value evaluate(RdfBindingRow bindings) {
 		ExpressionLogic expression = (ExpressionLogic) this.data.getArguments().get(0);
 		Object value = expression.evaluate(bindings);
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/function/IsLiteralLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/IsLiteralLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/function/IsLiteralLogic.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/IsLiteralLogic.java	2006-12-02 11:00:48.000000000 -0500
@@ -21,38 +21,31 @@
  * @author Ryan Levering
  * @version 1.0
  */
-public class IsLiteralLogic implements ExpressionLogic {
-
-	/**
-	 * The data that holds the argument to evaluate for literal.
-	 */
-	private final CallExpressionData data;
-
-	/**
-	 * The converter used to return the true or false value.
-	 */
-	private final ValueConversionLogic converter;
-
-	/**
-	 * Creates a new logic object that can evaluate whether a bound variable or
-	 * value is a literal.
-	 * 
-	 * @param data the data holding the argument for evaluation
-	 * @param converter the value conversion logic to convert the boolean to a
-	 *            literal
-	 */
-	public IsLiteralLogic(CallExpressionData data, ValueConversionLogic converter) {
-		this.data = data;
-		this.converter = converter;
-	}
-
-	/**
-	 * Evaluates whether the value returned by an expression is a literal.
-	 * 
-	 * @param bindings the value bindings to use in argument evaluation
-	 * @return true or false literals representing whether the argument is an
-	 *         literal
-	 */
+public class IsLiteralLogic extends FunctionLogic {
+   
+    /**
+     * The converter used to return the true or false value.
+     */
+    private final ValueConversionLogic converter;
+    
+    /**
+     * Creates a new logic object that can evaluate whether a bound variable or
+     * value is a literal.
+     * 
+     * @param data the data holding the argument for evaluation
+     * @param converter the value conversion logic to convert the boolean to a literal
+     */
+    public IsLiteralLogic(CallExpressionData data, ValueConversionLogic converter) {
+        super(data);
+        this.converter = converter;
+    }
+    
+    /**
+     * Evaluates whether the value returned by an expression is a literal.
+     * 
+     * @param bindings the value bindings to use in argument evaluation
+     * @return true or false literals representing whether the argument is an literal
+     */
 	public Value evaluate(RdfBindingRow bindings) {
 		ExpressionLogic expression = (ExpressionLogic) this.data.getArguments().get(0);
 		Object value = expression.evaluate(bindings);
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/function/LangLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/LangLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/function/LangLogic.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/LangLogic.java	2006-12-02 11:00:48.000000000 -0500
@@ -21,30 +21,22 @@
  * @author Ryan Levering
  * @version 1.0
  */
-public class LangLogic implements ExpressionLogic {
-
-	/**
-	 * The data that holds the argument to evaluate for literal language.
-	 */
-	private final CallExpressionData data;
-
+public class LangLogic extends FunctionLogic {
 	/**
 	 * The converter used to return the string value.
 	 */
 	private final ValueConversionLogic converter;
 
-	/**
-	 * Creates a new logic object that can return the language of a given
-	 * literal.
-	 * 
-	 * @param data the data holding the argument for evaluation
-	 * @param converter the value conversion logic to convert the string to a
-	 *            literal
-	 */
-	public LangLogic(CallExpressionData data, ValueConversionLogic converter) {
-		this.data = data;
-		this.converter = converter;
-	}
+   /**
+    * Creates a new logic object that can return the language of a given literal.
+    * 
+    * @param data the data holding the argument for evaluation
+    * @param converter the value conversion logic to convert the string to a literal
+    */
+    public LangLogic(CallExpressionData data, ValueConversionLogic converter) {
+        super(data);
+        this.converter = converter;
+    }
 
 	/**
 	 * Returns the language of a language tagged literal.
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/function/LangMatchesLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/LangMatchesLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/function/LangMatchesLogic.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/LangMatchesLogic.java	2006-12-02 11:00:48.000000000 -0500
@@ -21,14 +21,7 @@
  * @author Ryan Levering
  * @version 1.0
  */
-public class LangMatchesLogic implements ExpressionLogic {
-
-	/**
-	 * The data that holds the arguments to evaluate for language range and
-	 * literal to match.
-	 */
-	private final CallExpressionData data;
-
+public class LangMatchesLogic extends FunctionLogic {
 	/**
 	 * The converter used to return the boolean value.
 	 */
@@ -43,7 +36,7 @@
 	 *            literal
 	 */
 	public LangMatchesLogic(CallExpressionData data, ValueConversionLogic converter) {
-		this.data = data;
+		super(data);
 		this.converter = converter;
 	}
 
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/function/RegexLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/RegexLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/function/RegexLogic.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/RegexLogic.java	2006-12-02 11:00:48.000000000 -0500
@@ -25,31 +25,25 @@
  * @author Ryan Levering
  * @version 1.1
  */
-public class RegexLogic implements ExpressionLogic {
-
-	/**
-	 * The data that holds the argument to evaluate for string matching.
-	 */
-	private final CallExpressionData data;
-
-	/**
-	 * The converter used to return the boolean literal and convert the string
-	 * value.
-	 */
-	private final ValueConversionLogic converter;
-
-	/**
-	 * Creates a new logic object that can evaluate whether one string occurs in
-	 * another.
-	 * 
-	 * @param data the data holding the argument for evaluation
-	 * @param converter the value conversion logic to convert the result to a
-	 *            literal and the strings to Java strings
-	 */
-	public RegexLogic(CallExpressionData data, ValueConversionLogic converter) {
-		this.data = data;
-		this.converter = converter;
-	}
+public class RegexLogic extends FunctionLogic {
+    /**
+     * The converter used to return the boolean literal and convert the string
+     * value.
+     */
+    private final ValueConversionLogic converter;
+
+    /**
+     * Creates a new logic object that can evaluate whether one string occurs in
+     * another.
+     * 
+     * @param data the data holding the argument for evaluation
+     * @param converter the value conversion logic to convert the result to a
+     *            literal and the strings to Java strings
+     */
+    public RegexLogic(CallExpressionData data, ValueConversionLogic converter) {
+        super(data);
+        this.converter = converter;
+    }
 
 	/**
 	 * Converts the evaluated arguments to strings and uses Java string matching
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/function/StrLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/StrLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/function/StrLogic.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/StrLogic.java	2006-12-02 11:00:48.000000000 -0500
@@ -23,28 +23,22 @@
  * @author Ryan Levering
  * @version 1.2
  */
-public class StrLogic implements ExpressionLogic {
-
-	/**
-	 * The data that holds the argument to evaluate for string conversion.
-	 */
-	private final CallExpressionData data;
-
-	/**
-	 * The factory used to create new string literals.
-	 */
-	private final SPARQLValueFactory factory;
-
-	/**
-	 * Creates a new logic object that can evaluate the string representation of
-	 * a IRI or literal.
-	 * 
-	 * @param data the data holding the argument for evaluation
-	 */
-	public StrLogic(CallExpressionData data, SPARQLValueFactory factory) {
-		this.data = data;
-		this.factory = factory;
-	}
+public class StrLogic extends FunctionLogic {
+    /**
+     * The factory used to create new string literals.
+     */
+    private final SPARQLValueFactory factory;
+
+    /**
+     * Creates a new logic object that can evaluate the string representation of
+     * a IRI or literal.
+     * 
+     * @param data the data holding the argument for evaluation
+     */
+    public StrLogic(CallExpressionData data, SPARQLValueFactory factory) {
+        super(data);
+        this.factory = factory;
+    }
 
 	/**
 	 * Evaluates the argument to the function and does simplistic conversion to
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/naive/DefaultFilterConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultFilterConstraintLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/naive/DefaultFilterConstraintLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultFilterConstraintLogic.java	2007-02-21 07:11:04.000000000 -0500
@@ -8,6 +8,7 @@
 import java.util.Collection;
 import java.util.Collections;
 import java.util.Iterator;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingRow;
 import name.levering.ryan.sparql.common.RdfBindingSet;
@@ -74,17 +75,16 @@
      *            this constraint
      * @return a binding set with values that pass through the filter expression
      */
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source,
-            Collection defaultDatasets, Collection namedDatasets) {
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
         // Grab the necessary fields from the data
         ExpressionLogic filterExpression = this.data.getExpression();
 
         // Create a new binding set with the same variables
         RdfBindingSetImpl newBindings = new RdfBindingSetImpl(
-                bindings.getVariables());
+                p.bindings.getVariables());
 
         // Only add rows to the new set if they return true boolean literals
-        for (Iterator rows = bindings.iterator(); rows.hasNext();) {
+        for (Iterator rows = p.bindings.iterator(); rows.hasNext();) {
             RdfBindingRow row = (RdfBindingRow) rows.next();
             try {
                 Value rawEvaluate = filterExpression.evaluate(row);
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/naive/DefaultFilterConstraintLogic.java~ work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultFilterConstraintLogic.java~
--- upstream/src/main/name/levering/ryan/sparql/logic/naive/DefaultFilterConstraintLogic.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultFilterConstraintLogic.java~	2007-02-10 09:06:34.000000000 -0500
@@ -0,0 +1,113 @@
+/*
+ * SPARQL Engine
+ * Copyright (C) 2005 Ryan Levering, All rights reserved.
+ * See LICENSE for full license information
+ */
+package name.levering.ryan.sparql.logic.naive;
+
+import java.util.Collection;
+import java.util.Collections;
+import java.util.Iterator;
+import java.util.Map;
+
+import name.levering.ryan.sparql.common.RdfBindingRow;
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.common.impl.RdfBindingSetImpl;
+import name.levering.ryan.sparql.logic.expression.TypeError;
+import name.levering.ryan.sparql.model.data.FilterConstraintData;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
+import name.levering.ryan.sparql.model.logic.ExpressionLogic;
+import name.levering.ryan.sparql.model.logic.helper.EffectiveBooleanLogic;
+import name.levering.ryan.sparql.model.logic.helper.ValueConversionLogic;
+
+import org.openrdf.model.Value;
+
+/**
+ * The default logic that controls how the bound results are filtered by
+ * evaluation against value expressions. This will apply an expression to each
+ * row, eliminating any value rows that produce a false or erroneous output.
+ * 
+ * @author Ryan Levering
+ * @version 1.0
+ */
+public class DefaultFilterConstraintLogic implements ConstraintLogic {
+
+    /**
+     * The data that contains the expression to evaluate.
+     */
+    private final FilterConstraintData data;
+
+    /**
+     * The logic to force the expression results to a boolean value.
+     */
+    private final EffectiveBooleanLogic boolLogic;
+
+    /**
+     * The logic to convert the boolean literal to a Java boolean for
+     * evaluation.
+     */
+    private final ValueConversionLogic converter;
+
+    /**
+     * Creates a new default filter logic, that uses the expression data with
+     * the boolean and conversion logic to filter bound data values.
+     * 
+     * @param data the data containing the filter expression
+     * @param boolLogic the logic to coerce boolean values
+     * @param converter the logic to convert to Java boolean
+     */
+    public DefaultFilterConstraintLogic(FilterConstraintData data,
+            EffectiveBooleanLogic boolLogic, ValueConversionLogic converter) {
+        this.data = data;
+        this.boolLogic = boolLogic;
+        this.converter = converter;
+    }
+
+    /**
+     * Filters the passed in binding set, only adding those rows that return a
+     * true boolean value to the returned binding set.
+     * 
+     * @param bindings the current bound values
+     * @param source the RDF source, not used in this constraint
+     * @param defaultDatasets the datasets to query, not used in this constraint
+     * @param namedDatasets the named datasets for graph queries, not used in
+     *            this constraint
+     * @return a binding set with values that pass through the filter expression
+     */
+    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source,
+            Collection defaultDatasets, Collection namedDatasets, Map knownValues, Map knownFilters) {
+        // Grab the necessary fields from the data
+        ExpressionLogic filterExpression = this.data.getExpression();
+
+        // Create a new binding set with the same variables
+        RdfBindingSetImpl newBindings = new RdfBindingSetImpl(
+                bindings.getVariables());
+
+        // Only add rows to the new set if they return true boolean literals
+        for (Iterator rows = bindings.iterator(); rows.hasNext();) {
+            RdfBindingRow row = (RdfBindingRow) rows.next();
+            try {
+                Value rawEvaluate = filterExpression.evaluate(row);
+                if (this.converter.convertBoolean(this.boolLogic.forceBoolean(rawEvaluate))) {
+                    newBindings.addRow(row);
+                }
+            } catch (TypeError e) {
+                // Ignore and don't add
+            }
+        }
+        return newBindings;
+    }
+
+    /**
+     * Currently does nothing, as I'm not even sure what this method is used for
+     * and the filter constraint doesn't really change the variable bindings at
+     * all.
+     * 
+     * @return an empty list always
+     */
+    public Collection getVariables() {
+        return Collections.EMPTY_LIST;
+    }
+
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/naive/DefaultGroupConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultGroupConstraintLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/naive/DefaultGroupConstraintLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultGroupConstraintLogic.java	2007-02-21 07:16:02.000000000 -0500
@@ -9,6 +9,7 @@
 import java.util.Iterator;
 import java.util.LinkedList;
 import java.util.List;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -73,18 +74,19 @@
 	 * @param namedDatasets the named datasets to query in an unbound graph
 	 *            query, passed on to subconstraints
 	 */
-	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
-		return this.constrain(bindings, source, defaultDatasets, namedDatasets, true);
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+		return this.constrain(p, true);
 	}
 
-	private RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets, boolean withFilter) {
+	private RdfBindingSet constrain(ConstraintLogic.CallParams p, boolean withFilter) {
 
 		List filterQueue = new LinkedList();
 		List optionalQueue = new LinkedList();
 		List graphQueue = new LinkedList();
 
+		ConstraintLogic.CallParams p2 = p.clone();
+		p2.bindings = null;
+
 		RdfBindingSet current = null;
 		// Constrain in order, unless we hit an optional, graph, or value filter
 		// These things all kind of depend on the previous bindings
@@ -99,7 +101,7 @@
 			} else if (c instanceof GraphConstraintData) {
 				graphQueue.add(c);
 			} else {
-				this.orderLogic.addBindingSet(c.constrain(null, source, defaultDatasets, namedDatasets));
+				this.orderLogic.addBindingSet(c.constrain(p2));
 			}
 
 		}
@@ -108,10 +110,11 @@
 		// This scoped graphing isn't required by the spec, but it's allowed
 		for (Iterator graphs = graphQueue.iterator(); graphs.hasNext();) {
 			ConstraintLogic c = (ConstraintLogic) graphs.next();
+			p2.bindings = current;
 			if (current == null) {
-				current = c.constrain(null, source, defaultDatasets, namedDatasets);
+				current = c.constrain(p2);
 			} else {
-				current = this.logic.intersect(current, c.constrain(current, source, defaultDatasets, namedDatasets));
+				current = this.logic.intersect(current, c.constrain(p2));
 			}
 		}
 
@@ -123,11 +126,13 @@
 
 		for (Iterator optionals = optionalQueue.iterator(); optionals.hasNext();) {
 			ConstraintLogic c = (ConstraintLogic) optionals.next();
-			current = c.constrain(current, source, defaultDatasets, namedDatasets);
+			p2.bindings = current;
+			current = c.constrain(p2);
 		}
 		for (Iterator filters = filterQueue.iterator(); filters.hasNext();) {
 			ConstraintLogic c = (ConstraintLogic) filters.next();
-			current = c.constrain(current, source, defaultDatasets, namedDatasets);
+			p2.bindings = current;
+			current = c.constrain(p2);
 		}
 		return current;
 	}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/naive/DefaultGroupConstraintLogic.java~ work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultGroupConstraintLogic.java~
--- upstream/src/main/name/levering/ryan/sparql/logic/naive/DefaultGroupConstraintLogic.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultGroupConstraintLogic.java~	2007-02-21 07:04:58.000000000 -0500
@@ -0,0 +1,135 @@
+/*
+ * SPARQL Engine
+ * Copyright (C) 2005 Ryan Levering, All rights reserved.
+ * See LICENSE for full license information
+ */
+package name.levering.ryan.sparql.logic.naive;
+
+import java.util.Collection;
+import java.util.Iterator;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.common.impl.RdfBindingSetImpl;
+import name.levering.ryan.sparql.model.data.FilterConstraintData;
+import name.levering.ryan.sparql.model.data.GraphConstraintData;
+import name.levering.ryan.sparql.model.data.GroupConstraintData;
+import name.levering.ryan.sparql.model.data.OptionalConstraintData;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
+import name.levering.ryan.sparql.model.logic.helper.IntersectOrderLogic;
+import name.levering.ryan.sparql.model.logic.helper.SetIntersectLogic;
+
+/**
+ * This logic is the default logic for the main constraint that is used as an
+ * aggregate of other constraints. TripleConstraints, UnionConstraints, and
+ * GraphConstraints all are intersected with the running binding set. After
+ * that, OptionalConstraints and FilterConstraints modify the set themselves.
+ * 
+ * @author Ryan Levering
+ * @version 1.0
+ */
+public class DefaultGroupConstraintLogic implements ConstraintLogic {
+
+	/**
+	 * The data that holds the constraints that this group constraint
+	 * aggregates.
+	 */
+	private final GroupConstraintData data;
+
+	/**
+	 * This logic that intersects the parts of the graph pattern.
+	 */
+	private final SetIntersectLogic logic;
+
+	/**
+	 * This logic determines the order of set intersection to maximize variable
+	 * intersection.
+	 */
+	private final IntersectOrderLogic orderLogic;
+
+	/**
+	 * Creates a new default group logic, with the given subconstraints found in
+	 * the data.
+	 * 
+	 * @param data the data holding the subconstraints to bind
+	 */
+	public DefaultGroupConstraintLogic(GroupConstraintData data, SetIntersectLogic logic, IntersectOrderLogic orderLogic) {
+		this.data = data;
+		this.logic = logic;
+		this.orderLogic = orderLogic;
+	}
+
+	/**
+	 * Applies each subconstraint in turn, saving filter and optional
+	 * constraints for last, as according to specification.
+	 * 
+	 * @param bindings the current running bindings, ignored here
+	 * @param source the source to query RDF triples, passed on to
+	 *            subconstraints
+	 * @param defaultDatasets the datasets to query by default, passed on to
+	 *            subconstraints
+	 * @param namedDatasets the named datasets to query in an unbound graph
+	 *            query, passed on to subconstraints
+	 */
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+		return this.constrain(bindings, source, defaultDatasets, namedDatasets, knownValues, knownFilters, true);
+	}
+
+	private RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
+			Collection namedDatasets, Map knownValues, Map knownFilters, boolean withFilter) {
+
+		List filterQueue = new LinkedList();
+		List optionalQueue = new LinkedList();
+		List graphQueue = new LinkedList();
+
+		RdfBindingSet current = null;
+		// Constrain in order, unless we hit an optional, graph, or value filter
+		// These things all kind of depend on the previous bindings
+		// Graph probably shouldn't technically, but I think in this
+		// implementation it does
+		for (Iterator cons = this.data.getConstraints().iterator(); cons.hasNext();) {
+			ConstraintLogic c = (ConstraintLogic) cons.next();
+			if (c instanceof OptionalConstraintData) {
+				optionalQueue.add(c);
+			} else if (c instanceof FilterConstraintData) {
+				filterQueue.add(c);
+			} else if (c instanceof GraphConstraintData) {
+				graphQueue.add(c);
+			} else {
+				this.orderLogic.addBindingSet(c.constrain(null, source, defaultDatasets, namedDatasets, knownValues, knownFilters));
+			}
+
+		}
+		current = this.orderLogic.removeIntersectedSet();
+
+		// This scoped graphing isn't required by the spec, but it's allowed
+		for (Iterator graphs = graphQueue.iterator(); graphs.hasNext();) {
+			ConstraintLogic c = (ConstraintLogic) graphs.next();
+			if (current == null) {
+				current = c.constrain(null, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
+			} else {
+				current = this.logic.intersect(current, c.constrain(current, source, defaultDatasets, namedDatasets, knownValues, knownFilters));
+			}
+		}
+
+		// At this point, we don't have any constraints so just bring the whole
+		// set in
+		if (current == null) {
+			current = RdfBindingSetImpl.EMPTY_SET;
+		}
+
+		for (Iterator optionals = optionalQueue.iterator(); optionals.hasNext();) {
+			ConstraintLogic c = (ConstraintLogic) optionals.next();
+			current = c.constrain(current, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
+		}
+		for (Iterator filters = filterQueue.iterator(); filters.hasNext();) {
+			ConstraintLogic c = (ConstraintLogic) filters.next();
+			current = c.constrain(current, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
+		}
+		return current;
+	}
+
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/naive/DefaultOptionalConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultOptionalConstraintLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/naive/DefaultOptionalConstraintLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultOptionalConstraintLogic.java	2007-02-21 07:48:26.000000000 -0500
@@ -9,6 +9,7 @@
 import java.util.Iterator;
 import java.util.LinkedList;
 import java.util.List;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -74,13 +75,16 @@
 	 * @param namedDatasets the named datasets for named queries, passed onto
 	 *            the grouped constraint
 	 */
-	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
 		List filterQueue = new LinkedList();
 		List optionalQueue = new LinkedList();
 		List graphQueue = new LinkedList();
 
 		RdfBindingSet current = null;
+		
+		ConstraintLogic.CallParams p2 = p.clone();
+		p2.bindings = null;
+
 		// Constrain in order, unless we hit an optional, graph, or value filter
 		// These things all kind of depend on the previous bindings
 		// Graph probably shouldn't technically, but I think in this
@@ -94,7 +98,7 @@
 			} else if (c instanceof GraphConstraint) {
 				graphQueue.add(c);
 			} else {
-				this.orderLogic.addBindingSet(c.constrain(null, source, defaultDatasets, namedDatasets));
+				this.orderLogic.addBindingSet(c.constrain(p2));
 			}
 
 		}
@@ -104,10 +108,10 @@
 		for (Iterator graphs = graphQueue.iterator(); graphs.hasNext();) {
 			ConstraintLogic c = (ConstraintLogic) graphs.next();
 			if (current == null) {
-				current = c.constrain(null, source, defaultDatasets, namedDatasets);
+				current = c.constrain(p2);
 			} else {
-				current = this.intersectLogic.intersect(current, c.constrain(current, source, defaultDatasets,
-						namedDatasets));
+				p2.bindings = current;
+				current = this.intersectLogic.intersect(current, c.constrain(p2));
 			}
 		}
 
@@ -119,10 +123,11 @@
 
 		for (Iterator optionals = optionalQueue.iterator(); optionals.hasNext();) {
 			ConstraintLogic c = (ConstraintLogic) optionals.next();
-			current = c.constrain(current, source, defaultDatasets, namedDatasets);
+			p2.bindings = current;
+			current = c.constrain(p2);
 		}
 		
-		return this.logic.join(bindings, current, filterQueue);
+		return this.logic.join(p.bindings, current, filterQueue);
 	}
 
 }
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/naive/DefaultOptionalConstraintLogic.java~ work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultOptionalConstraintLogic.java~
--- upstream/src/main/name/levering/ryan/sparql/logic/naive/DefaultOptionalConstraintLogic.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultOptionalConstraintLogic.java~	2007-02-21 07:29:07.000000000 -0500
@@ -0,0 +1,133 @@
+/*
+ * SPARQL Engine
+ * Copyright (C) 2005 Ryan Levering, All rights reserved.
+ * See LICENSE for full license information
+ */
+package name.levering.ryan.sparql.logic.naive;
+
+import java.util.Collection;
+import java.util.Iterator;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.common.impl.RdfBindingSetImpl;
+import name.levering.ryan.sparql.model.FilterConstraint;
+import name.levering.ryan.sparql.model.GraphConstraint;
+import name.levering.ryan.sparql.model.OptionalConstraint;
+import name.levering.ryan.sparql.model.data.OptionalConstraintData;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
+import name.levering.ryan.sparql.model.logic.helper.IntersectOrderLogic;
+import name.levering.ryan.sparql.model.logic.helper.SetIntersectLogic;
+import name.levering.ryan.sparql.model.logic.helper.SetJoinLogic;
+
+/**
+ * The default logic for the OPTIONAL constraint in the SPARQL query language.
+ * This logic appends variable bindings where row values intersect and sets the
+ * other rows to hold null values.
+ * 
+ * @author Ryan Levering
+ * @version 1.0
+ */
+public class DefaultOptionalConstraintLogic implements ConstraintLogic {
+
+	/**
+	 * The data that holds the group constraint to expand the current constraint
+	 * with.
+	 */
+	private final OptionalConstraintData data;
+
+	/**
+	 * The logic to calculate the set join operation.
+	 */
+	private final SetJoinLogic logic;
+
+	private final IntersectOrderLogic orderLogic;
+
+	private final SetIntersectLogic intersectLogic;
+
+	/**
+	 * Creates a new optional constraint logic object that expands a binding set
+	 * with another.
+	 * 
+	 * @param data the data that holds the constraints
+	 * @param logic the logic to calculate the set join operation
+	 */
+	public DefaultOptionalConstraintLogic(OptionalConstraintData data, SetIntersectLogic intersectLogic,
+			IntersectOrderLogic orderLogic, SetJoinLogic logic) {
+		this.data = data;
+		this.logic = logic;
+		this.orderLogic = orderLogic;
+		this.intersectLogic = intersectLogic;
+	}
+
+	/**
+	 * Calculates a new binding set by expanding the passed bindings with the
+	 * bindings from the enclosed constraints.
+	 * 
+	 * @param bindings the current value bindings, used as the base for
+	 *            expansion
+	 * @param source the RDF triple source, passed onto the grouped constraint
+	 * @param defaultDatasets the datasets to query, passed onto the grouped
+	 *            constraint
+	 * @param namedDatasets the named datasets for named queries, passed onto
+	 *            the grouped constraint
+	 */
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+		List filterQueue = new LinkedList();
+		List optionalQueue = new LinkedList();
+		List graphQueue = new LinkedList();
+
+		RdfBindingSet current = null;
+		
+		ConstraintLogic.CallParams p2 = p.clone();
+		p2.bindings = null;
+
+		// Constrain in order, unless we hit an optional, graph, or value filter
+		// These things all kind of depend on the previous bindings
+		// Graph probably shouldn't technically, but I think in this
+		// implementation it does
+		for (Iterator cons = this.data.getConstraint().getConstraints().iterator(); cons.hasNext();) {
+			ConstraintLogic c = (ConstraintLogic) cons.next();
+			if (c instanceof OptionalConstraint) {
+				optionalQueue.add(c);
+			} else if (c instanceof FilterConstraint) {
+				filterQueue.add(c);
+			} else if (c instanceof GraphConstraint) {
+				graphQueue.add(c);
+			} else {
+				this.orderLogic.addBindingSet(c.constrain(p2));
+			}
+
+		}
+		current = this.orderLogic.removeIntersectedSet();
+
+		// This isn't required by the spec, but it's allowed
+		for (Iterator graphs = graphQueue.iterator(); graphs.hasNext();) {
+			ConstraintLogic c = (ConstraintLogic) graphs.next();
+			if (current == null) {
+				current = c.constrain(p2);
+			} else {
+				p2.bindings = current;
+				current = this.intersectLogic.intersect(current, c.constrain(p2));
+			}
+		}
+
+		// At this point, we don't have any constraints so just bring the whole
+		// set in
+		if (current == null) {
+			current = new RdfBindingSetImpl();
+		}
+
+		for (Iterator optionals = optionalQueue.iterator(); optionals.hasNext();) {
+			ConstraintLogic c = (ConstraintLogic) optionals.next();
+			p2.bindings = current;
+			current = c.constrain(p2);
+		}
+		
+		return this.logic.join(bindings, current, filterQueue);
+	}
+
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/naive/DefaultTripleConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultTripleConstraintLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/naive/DefaultTripleConstraintLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultTripleConstraintLogic.java	2007-02-21 07:48:10.000000000 -0500
@@ -9,6 +9,7 @@
 import java.util.Collection;
 import java.util.Iterator;
 import java.util.List;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.GraphStatement;
 import name.levering.ryan.sparql.common.LenientStatement;
@@ -63,8 +64,7 @@
      *            used in this constraint
      * 
      */
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source,
-            Collection defaultDatasets, Collection namedDatasets) {
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
 
         ExpressionLogic subExpr = this.data.getSubjectExpression();
         ExpressionLogic predExpr = this.data.getPredicateExpression();
@@ -110,25 +110,25 @@
 
         Iterator statements;
         if (!variables.isEmpty()) {
-            if (defaultDatasets == null) {
+            if (p.defaultDatasets == null) {
                 // This adds an extra column to the returned set for the GRAPH
                 // constraint to process
                 variables.add(StreamedGraphConstraintLogic.CONTEXT_VARIABLE);
                 newBindings = new RdfBindingSetImpl(
                         (Variable[]) variables.toArray(new Variable[0]));
-                statements = source.getStatements(subject, verb, object);
+                statements = p.source.getStatements(subject, verb, object);
                 addGraphStatements(newBindings, statements, flags);
             } else {
-                if (defaultDatasets.isEmpty()) {
+                if (p.defaultDatasets.isEmpty()) {
                     // This is if no FROM graphs are specified
-                    statements = source.getDefaultStatements(subject, verb,
+                    statements = p.source.getDefaultStatements(subject, verb,
                             object);
                     addStatements(newBindings, statements, flags);
                 } else {
                     // This is if FROM graphs are specified or FROM NAMED and
                     // we're in a GRAPH constraint
-                    for (Iterator i = defaultDatasets.iterator(); i.hasNext();) {
-                        statements = source.getStatements(subject, verb,
+                    for (Iterator i = p.defaultDatasets.iterator(); i.hasNext();) {
+                        statements = p.source.getStatements(subject, verb,
                                 object, (URI) i.next());
                         addStatements(newBindings, statements, flags);
                     }
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/naive/DefaultTripleConstraintLogic.java~ work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultTripleConstraintLogic.java~
--- upstream/src/main/name/levering/ryan/sparql/logic/naive/DefaultTripleConstraintLogic.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultTripleConstraintLogic.java~	2007-02-21 07:47:55.000000000 -0500
@@ -0,0 +1,226 @@
+/*
+ * SPARQL Engine
+ * Copyright (C) 2005 Ryan Levering, All rights reserved.
+ * See LICENSE for full license information
+ */
+package name.levering.ryan.sparql.logic.naive;
+
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+
+import name.levering.ryan.sparql.common.GraphStatement;
+import name.levering.ryan.sparql.common.LenientStatement;
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.common.Variable;
+import name.levering.ryan.sparql.common.impl.RdfBindingRowImpl;
+import name.levering.ryan.sparql.common.impl.RdfBindingSetImpl;
+import name.levering.ryan.sparql.logic.streamed.StreamedGraphConstraintLogic;
+import name.levering.ryan.sparql.model.data.TripleConstraintData;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
+import name.levering.ryan.sparql.model.logic.ExpressionLogic;
+
+import org.openrdf.model.URI;
+import org.openrdf.model.Value;
+
+/**
+ * This is the logic that handles most of the interaction with the end
+ * RdfSource. Most other constraints pass the source down to triple constraints,
+ * which provide the core bound values to manipulate. This is responsible for
+ * querying the defaultDatasets for statements with wildcard placeholders.
+ * 
+ * @author Ryan Levering
+ * @version 1.1
+ */
+public class DefaultTripleConstraintLogic implements ConstraintLogic {
+
+    /**
+     * The data containing the possible subject, predicate, and object to find.
+     */
+    private final TripleConstraintData data;
+
+    /**
+     * Creates a new triple constraint logic that constrains a database to match
+     * particular statement criteria.
+     * 
+     * @param data the data holding the statement data to match
+     */
+    public DefaultTripleConstraintLogic(TripleConstraintData data) {
+        this.data = data;
+    }
+
+    /**
+     * Returns a binding set of bound values matching a particular subject,
+     * predicate, and object where one or more of them is a wildcard.
+     * 
+     * @param bindings the current bindings, not used in this constraint
+     * @param source the source to query for the statement constraints
+     * @param defaultDatasets the datasets to query, if non-default graphs are
+     *            being used
+     * @param namedDatasets the named datasets to use in graph constraints, not
+     *            used in this constraint
+     * 
+     */
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+
+        ExpressionLogic subExpr = this.data.getSubjectExpression();
+        ExpressionLogic predExpr = this.data.getPredicateExpression();
+        ExpressionLogic objExpr = this.data.getObjectExpression();
+
+        int[] flags = new int[3];
+        List variables = new ArrayList();
+        Value subject = null;
+        if (subExpr instanceof Variable) {
+            variables.add(subExpr);
+            flags[0] = 1;
+            if (subExpr.equals(predExpr)) {
+                flags[1] = 1;
+            }
+            if (subExpr.equals(objExpr)) {
+                flags[2] = 1;
+            }
+        } else {
+            subject = (Value) subExpr;
+        }
+
+        URI verb = null;
+        if (predExpr instanceof Variable && flags[1] == 0) {
+            variables.add(predExpr);
+            flags[1] = 2;
+            if (predExpr.equals(objExpr)) {
+                flags[2] = 2;
+            }
+        } else {
+            verb = (URI) predExpr;
+        }
+
+        Value object = null;
+        if (objExpr instanceof Variable && flags[2] == 0) {
+            variables.add(objExpr);
+            flags[2] = 3;
+        } else if (flags[2] == 0) {
+            object = (Value) objExpr;
+        }
+
+        RdfBindingSetImpl newBindings = new RdfBindingSetImpl(
+                (Variable[]) variables.toArray(new Variable[0]));
+
+        Iterator statements;
+        if (!variables.isEmpty()) {
+            if (defaultDatasets == null) {
+                // This adds an extra column to the returned set for the GRAPH
+                // constraint to process
+                variables.add(StreamedGraphConstraintLogic.CONTEXT_VARIABLE);
+                newBindings = new RdfBindingSetImpl(
+                        (Variable[]) variables.toArray(new Variable[0]));
+                statements = p.source.getStatements(subject, verb, object);
+                addGraphStatements(newBindings, statements, flags);
+            } else {
+                if (p.defaultDatasets.isEmpty()) {
+                    // This is if no FROM graphs are specified
+                    statements = p.source.getDefaultStatements(subject, verb,
+                            object);
+                    addStatements(newBindings, statements, flags);
+                } else {
+                    // This is if FROM graphs are specified or FROM NAMED and
+                    // we're in a GRAPH constraint
+                    for (Iterator i = p.defaultDatasets.iterator(); i.hasNext();) {
+                        statements = p.source.getStatements(subject, verb,
+                                object, (URI) i.next());
+                        addStatements(newBindings, statements, flags);
+                    }
+                }
+            }
+        }
+        return newBindings;
+    }
+
+    /**
+     * Adds statements to a binding set, according to whether the field was
+     * being bound to a variable or not.
+     * 
+     * @param set the set to add the statements to
+     * @param statements the fully realized statements from the source
+     * @param flags an array holding flags that specify which fields to use
+     */
+    private void addStatements(RdfBindingSetImpl set, Iterator statements,
+            int[] flags) {
+        while (statements.hasNext()) {
+            LenientStatement statement = (LenientStatement) statements.next();
+            if (flags[0] != 0 && flags[0] == flags[2]) {
+                if (!statement.getSubject().equals(statement.getObject())) {
+                    continue;
+                }
+            }
+            if (flags[0] != 0 && flags[0] == flags[1]) {
+                if (!statement.getSubject().equals(statement.getPredicate())) {
+                    continue;
+                }
+            }
+            if (flags[1] != 0 && flags[1] == flags[2]) {
+                if (!statement.getPredicate().equals(statement.getObject())) {
+                    continue;
+                }
+            }
+            
+            RdfBindingRowImpl newRow = new RdfBindingRowImpl();
+            if (flags[0] == 1) {
+                newRow.addBinding((Variable) this.data.getSubjectExpression(), statement.getSubject());
+            }
+            if (flags[1] == 2) {
+                newRow.addBinding((Variable) this.data.getPredicateExpression(), statement.getPredicate());
+            }
+            if (flags[2] == 3) {
+                newRow.addBinding((Variable) this.data.getObjectExpression(), statement.getObject());
+            }
+            set.addRow(newRow);
+        }
+    }
+
+    /**
+     * Adds statements to a binding set, according to whether the field was
+     * being bound to a variable or not.
+     * 
+     * @param set the set to add the statements to
+     * @param statements the fully realized statements from the source
+     * @param flags an array holding flags that specify which fields to use
+     */
+    private void addGraphStatements(RdfBindingSetImpl set, Iterator statements,
+            int[] flags) {
+        while (statements.hasNext()) {
+            GraphStatement statement = (GraphStatement) statements.next();
+            if (flags[0] != 0 && flags[0] == flags[2]) {
+                if (!statement.getSubject().equals(statement.getObject())) {
+                    continue;
+                }
+            }
+            if (flags[0] != 0 && flags[0] == flags[1]) {
+                if (!statement.getSubject().equals(statement.getPredicate())) {
+                    continue;
+                }
+            }
+            if (flags[1] != 0 && flags[1] == flags[2]) {
+                if (!statement.getPredicate().equals(statement.getObject())) {
+                    continue;
+                }
+            }
+            
+            RdfBindingRowImpl newRow = new RdfBindingRowImpl();
+            if (flags[0] == 1) {
+                newRow.addBinding((Variable) this.data.getSubjectExpression(), statement.getSubject());
+            }
+            if (flags[1] == 2) {
+                newRow.addBinding((Variable) this.data.getPredicateExpression(), statement.getPredicate());
+            }
+            if (flags[2] == 3) {
+                newRow.addBinding((Variable) this.data.getObjectExpression(), statement.getObject());
+            }
+            newRow.addBinding(StreamedGraphConstraintLogic.CONTEXT_VARIABLE, statement.getGraphName());
+            set.addRow(newRow);
+        }
+    }
+
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/naive/DefaultUnionConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultUnionConstraintLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/naive/DefaultUnionConstraintLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultUnionConstraintLogic.java	2007-02-21 07:30:41.000000000 -0500
@@ -7,6 +7,7 @@
 
 import java.util.Collection;
 import java.util.Iterator;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -62,15 +63,16 @@
 	 * @return a set containing the union of all the bound values of all the sub
 	 *         constraints
 	 */
-	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
 		RdfBindingSet current = null;
+		ConstraintLogic.CallParams p2 = p.clone();
 		for (Iterator groupOrUnions = this.data.getConstraints().iterator(); groupOrUnions.hasNext();) {
 			ConstraintLogic group = (ConstraintLogic) groupOrUnions.next();
+			p2.bindings = current;
 			if (current == null) {
-				current = group.constrain(current, source, defaultDatasets, namedDatasets);
+				current = group.constrain(p2);
 			} else {
-				current = this.logic.union(current, group.constrain(current, source, defaultDatasets, namedDatasets));
+				current = this.logic.union(current, group.constrain(p2));
 			}
 		}
 
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/naive/DefaultUnionConstraintLogic.java~ work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultUnionConstraintLogic.java~
--- upstream/src/main/name/levering/ryan/sparql/logic/naive/DefaultUnionConstraintLogic.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultUnionConstraintLogic.java~	2007-02-21 07:05:10.000000000 -0500
@@ -0,0 +1,80 @@
+/*
+ * SPARQL Engine
+ * Copyright (C) 2005 Ryan Levering, All rights reserved.
+ * See LICENSE for full license information
+ */
+package name.levering.ryan.sparql.logic.naive;
+
+import java.util.Collection;
+import java.util.Iterator;
+import java.util.Map;
+
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.common.impl.RdfBindingSetImpl;
+import name.levering.ryan.sparql.model.GroupConstraint;
+import name.levering.ryan.sparql.model.data.UnionConstraintData;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
+import name.levering.ryan.sparql.model.logic.helper.SetUnionLogic;
+
+/**
+ * This constraint logic represents the UNION constraint logic found in the
+ * SPARQL specification. The constraint essentially merges two or more binding
+ * sets into one, forming null values where variables are not bound in certain
+ * sets.
+ * 
+ * @author Ryan Levering
+ * @version 1.0
+ */
+public class DefaultUnionConstraintLogic implements ConstraintLogic {
+
+	/**
+	 * The data holding the collection of subconstraints.
+	 */
+	private final UnionConstraintData data;
+
+	/**
+	 * The logic to use for the combinatory set union.
+	 */
+	private final SetUnionLogic logic;
+
+	/**
+	 * Creates a new logic object that forms the union of several value binding
+	 * sets.
+	 * 
+	 * @param data the data to form a union with
+	 * @param logic the logic to use for the combinatory set union
+	 */
+	public DefaultUnionConstraintLogic(UnionConstraintData data, SetUnionLogic logic) {
+		this.data = data;
+		this.logic = logic;
+	}
+
+	/**
+	 * Iterates over the collection of binding sets returned by the group
+	 * constraints and forms the aggregate union of all of them.
+	 * 
+	 * @param bindings the current bindings, not used in this constraint
+	 * @param source the RDF triple source, passed onto the sub constraints
+	 * @param defaultDatasets the default graphs to query, passed on to the sub
+	 *            constraints
+	 * @param namedDatasets the named graphs to query, passed on to the sub
+	 *            constraints
+	 * @return a set containing the union of all the bound values of all the sub
+	 *         constraints
+	 */
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+		RdfBindingSet current = null;
+		for (Iterator groupOrUnions = this.data.getConstraints().iterator(); groupOrUnions.hasNext();) {
+			ConstraintLogic group = (ConstraintLogic) groupOrUnions.next();
+			if (current == null) {
+				current = group.constrain(current, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
+			} else {
+				current = this.logic.union(current, group.constrain(current, source, defaultDatasets, namedDatasets, knownValues, knownFilters));
+			}
+		}
+
+		return current;
+	}
+
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/streamed/AdvancedGroupConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/streamed/AdvancedGroupConstraintLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/streamed/AdvancedGroupConstraintLogic.java	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/streamed/AdvancedGroupConstraintLogic.java	2007-02-21 07:43:36.000000000 -0500
@@ -0,0 +1,568 @@
+/*
+ * SPARQL Engine
+ * Copyright (C) 2005 Ryan Levering, All rights reserved.
+ * See LICENSE for full license information
+ */
+package name.levering.ryan.sparql.logic;
+
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+
+import org.openrdf.model.URI;
+import org.openrdf.model.BNode;
+import org.openrdf.model.Literal;
+import org.openrdf.model.Value;
+
+import name.levering.ryan.sparql.common.impl.AbstractRdfBindingRow;
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfBindingRow;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.common.Variable;
+import name.levering.ryan.sparql.common.impl.RdfBindingSetImpl;
+import name.levering.ryan.sparql.logic.function.ExternalFunctionLogic;
+import name.levering.ryan.sparql.model.TripleConstraint;
+import name.levering.ryan.sparql.model.data.FilterConstraintData;
+import name.levering.ryan.sparql.model.data.GroupConstraintData;
+import name.levering.ryan.sparql.model.data.OptionalConstraintData;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
+import name.levering.ryan.sparql.model.logic.ExpressionLogic;
+import name.levering.ryan.sparql.model.logic.helper.SetIntersectLogic;
+import name.levering.ryan.sparql.parser.model.ASTAndNode;
+import name.levering.ryan.sparql.parser.model.ASTEqualsNode;
+import name.levering.ryan.sparql.parser.model.ASTOrNode;
+import name.levering.ryan.sparql.parser.model.ASTVar;
+import name.levering.ryan.sparql.parser.model.BinaryExpressionNode;
+import name.levering.ryan.sparql.parser.model.DelegatingTripleConstraint;
+import name.levering.ryan.sparql.parser.model.EmptyVisitor;
+import name.levering.ryan.sparql.parser.model.SimpleNode;
+
+/**
+ * This logic is the default logic for the main constraint that is used as an
+ * aggregate of other constraints. TripleConstraints, UnionConstraints, and
+ * GraphConstraints all are intersected with the running binding set. After
+ * that, OptionalConstraints and FilterConstraints modify the set themselves.
+ * 
+ * @author Ryan Levering
+ * @version 1.0
+ */
+public class AdvancedGroupConstraintLogic implements ConstraintLogic {
+
+    /**
+     * The data that holds the constraints that this group constraint
+     * aggregates.
+     */
+    private final GroupConstraintData data;
+
+    /**
+     * This logic that intersects the parts of the graph pattern.
+     */
+    private final SetIntersectLogic logic;
+    
+    private static final Map
+		isFunctional = new HashMap(),
+    	isInverseFunctional = new HashMap();
+    
+    /**
+     * Creates a new default group logic, with the given subconstraints found in
+     * the data.
+     * 
+     * @param data the data holding the subconstraints to bind
+     */
+    public AdvancedGroupConstraintLogic(GroupConstraintData data, SetIntersectLogic logic) {
+        this.logic = logic;
+        this.data = data;
+    }
+
+    /**
+     * Applies each subconstraint in turn, saving filter and optional
+     * constraints for last, as according to specification.
+     * 
+     * @param bindings the current running bindings, ignored here
+     * @param source the source to query RDF triples, passed on to
+     *            subconstraints
+     * @param defaultDatasets the datasets to query by default, passed on to
+     *            subconstraints
+     * @param namedDatasets the named datasets to query in an unbound graph
+     *            query, passed on to subconstraints
+     */
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+	
+		// Build separate lists for the different constraints that this group may contain.
+
+		List tripleConstraints = new LinkedList();
+        List filterQueue = new LinkedList();
+        List optionalQueue = new LinkedList();
+		List otherQueue = new LinkedList();
+
+		// Clone knownValues and knownFilters so we can freely modify it without affecting the caller.
+		
+		p = p.clone();
+		if (p.knownValues == null)
+			p.knownValues = new HashMap();
+		else
+			p.knownValues = new HashMap(p.knownValues);
+			
+		if (p.knownFilters == null)
+			p.knownFilters = new HashMap();
+		else
+			p.knownFilters = new HashMap(p.knownFilters);
+		
+		// Get a list of variables that have known values, and of those the ones that are really cheap
+		// (i.e. have just a few values).
+		// We'll build these sets in the course of reordering the statements to query most efficiently.
+
+		Set knownVars = new HashSet();
+		Set cheapVars = new HashSet();
+		
+		// Any variables known by groups on top of us are known here, and cheap (I guess).
+		knownVars.addAll(p.knownValues.keySet());
+		cheapVars.addAll(p.knownValues.keySet());
+		
+		// Split out the types of constraints and look for filters that tell us interesting things.
+		
+        for (Iterator cons = data.getConstraints().iterator(); cons.hasNext();) {
+            ConstraintLogic c = (ConstraintLogic) cons.next();
+            if (c instanceof OptionalConstraintData) {
+				optionalQueue.add(c);
+            } else if (c instanceof FilterConstraintData) {
+				filterQueue.add(c);
+				
+				FilterConstraintData f = (FilterConstraintData)c;
+				if (f.getExpression() instanceof BinaryExpressionNode) {
+					// If this filter is of the form FILTER(?var = <uri> || ?var = <uri> || ...)
+					// then this is giving us some known values for the variable.
+					BinaryExpressionNode b = (BinaryExpressionNode)f.getExpression();
+					Variable v = getFilterPrimaryVariable(b);
+					if (v != null) {
+						Set values = new HashSet();
+						getFilterValues(b, values);
+						if (!p.knownValues.containsKey(v)) {
+							p.knownValues.put(v, values);
+							knownVars.add(v);
+							cheapVars.add(v);
+						} else {
+							Set othervalues = (Set)p.knownValues.get(v);
+							othervalues.retainAll(values);
+						}
+					}
+				}
+				
+				// This by default does nothing, but subclassors may decide to do things here.
+				extractLiteralFilters(f.getExpression(), p.knownFilters);
+				
+			} else if (c instanceof TripleConstraint) {
+				tripleConstraints.add(c);
+			} else {
+				otherQueue.add(c);
+			}
+		}
+		
+		// Reorder the triple constraints so that complex constraints are done
+		// after some of their variables have already been evaluated.  This is
+		// a bit N^2-ish in the number of triple constraints, but it can be improved.
+		List constraintOrder = new LinkedList();
+		Set selectedVars = new HashSet();
+		while (tripleConstraints.size() > 0) {
+			TripleConstraint leastConstraint = null;
+			float leastComplexity = -1;
+			
+			if (tripleConstraints.size() == 1) {
+				leastConstraint = (TripleConstraint)tripleConstraints.get(0);
+			} else {
+				//System.err.println(">>>");
+				
+				for (Iterator cons = tripleConstraints.iterator(); cons.hasNext();) {
+					TripleConstraint c = (TripleConstraint) cons.next();
+					float complexity = getComplexity(c, knownVars, cheapVars, p.knownFilters, p.source);
+					//System.err.println(">>> " + complexity + "\t" + c);
+					if (leastConstraint == null || complexity < leastComplexity) {
+						leastComplexity = complexity;
+						leastConstraint = c;
+					}
+				}
+			}
+
+			tripleConstraints.remove(leastConstraint);
+			constraintOrder.add(leastConstraint);
+			
+			// Get the variables mentioned in this triple constraint
+			Set constraintVars = new HashSet();
+			getVariables(leastConstraint, constraintVars);
+			
+			// Keep a list of variables that have been selected on so far
+			selectedVars.addAll(constraintVars);
+			
+			// And all of these variables are now considered 'known' for the purposes of
+			// selecting which statement goes next.  But they're not considered 'cheap'.
+			knownVars.addAll(constraintVars);
+			
+			// Well, if this triple was functional or inverse functional, we *can*
+			// consider the variables mentioned in the triple cheap.
+			if (leastComplexity <= 1)
+				cheapVars.addAll(constraintVars);
+			
+			// Perform any filters that are such that all of the
+			// variables mentioned in the filter have already been selected
+			// on.  The earlier we filter the better.  (We have to know not just
+			// which variables are known so far, because ones that are known from
+			// filters may not yet be actually bound in the binding set.  Rather,
+			// we have to know which ones have actually been selected on in a
+			// triple.  Here, we only know what's been selected on in this group,
+			// and not at a higher level.)
+	        for (Iterator filters = filterQueue.iterator(); filters.hasNext();) {
+	            FilterConstraintData c = (FilterConstraintData) filters.next();
+	            /*boolean allvarsknown = true;
+	            Set filterVars = getFilterVariables((SimpleNode)c);
+	            for (Iterator vars = filterVars.iterator(); vars.hasNext(); ) {
+	            	if (!selectedVars.contains(vars.next())) {
+	            		allvarsknown = false;
+	            		break;
+	            	}
+	            }
+	            if (allvarsknown) {
+	            	constraintOrder.add(c);
+	            	filters.remove();
+	            }*/
+	        }
+        }
+		
+		// Add the otherQueue back in.
+		constraintOrder.addAll(otherQueue);
+
+		// Run the constraints in the new order.
+        RdfBindingSet current = null;
+		
+		// Allow a subclass to take over running the constraints.
+		current = runTripleConstraints(constraintOrder, p.source, p.defaultDatasets, p.namedDatasets, p.knownValues, p.knownFilters);
+		if (current != null) {
+			constraintOrder.clear();
+			if (optionalQueue.size() > 0)
+				current = updateKnownVariables(current, p.knownValues);
+		}
+		
+		for (Iterator cons = constraintOrder.iterator(); cons.hasNext();) {
+			ConstraintLogic c = (ConstraintLogic) cons.next();
+			
+			p.bindings = current;
+			
+			if (current == null) {
+				current = c.constrain(p);
+			} else if (c instanceof FilterConstraintData) {
+	            current = c.constrain(p);
+	            filterQueue.remove(c);
+			} else {
+				current = logic.intersect(current, c.constrain(p));
+			}
+
+			if (cons.hasNext() || optionalQueue.size() > 0)
+				current = updateKnownVariables(current, p.knownValues);
+        }
+        
+        // At this point, we're operating on the set, so let's make it an empty one
+        if (current == null) {
+            current = new RdfBindingSetImpl();
+        }
+
+		// Any optionals...
+        for (Iterator optionals = optionalQueue.iterator(); optionals.hasNext();) {
+            ConstraintLogic c = (ConstraintLogic) optionals.next();
+				p.bindings = current;
+            current = c.constrain(p);
+        }
+		
+		// Any filters that were not moved up in the logic to process them as early as possible.
+        for (Iterator filters = filterQueue.iterator(); filters.hasNext();) {
+            ConstraintLogic c = (ConstraintLogic) filters.next();
+				p.bindings = current;
+            current = c.constrain(p);
+        }
+        return current;
+    }
+
+	protected RdfBindingSet runTripleConstraints(List tripleConstraints, RdfSource source,
+            Collection defaultDatasets, Collection namedDatasets, Map knownValues, Map knownFilters) {
+		return null;
+	}
+	
+	private RdfBindingSet updateKnownVariables(RdfBindingSet current, Map knownValues) {
+		// If there are more things happening later, update our knownValue
+		// mapping based on what has currently been queried.  We have to
+		// loop through all of the bindings found so far, so we'll put
+		// those bindings into a new set to cache them.
+		
+		current = new RdfBindingSetImpl(current);
+		List variables = current.getVariables();
+		
+		Set hadNewValues = new HashSet();
+		for (Iterator biter = current.iterator(); biter.hasNext(); ) {
+			RdfBindingRow row = (RdfBindingRow)biter.next();
+			List rowvalues = row.getValues();
+			
+			for (int i = 0; i < variables.size(); i++) {
+				Variable var = (Variable) variables.get(i);
+				Value val = (Value) rowvalues.get(i);
+				
+				if (val == null) continue;
+				
+				Set values = (Set)knownValues.get(var);
+				
+				// If knownValues has no mapping for this variable yet,
+				// or if knownValues had a mapping, we want to clear
+				// the mapping and start fresh with the values actually
+				// found.
+				if (values == null || !hadNewValues.contains(var)) { 
+					values = new HashSet();
+					knownValues.put(var, values);
+					hadNewValues.add(var);
+				}
+					
+				values.add(val);
+			}
+		}
+		
+		extractVariableFunctions(knownValues);	
+		
+		return current;
+	}
+	
+    /**
+     * Creates a mapping from variables to a List of filters based on
+	 * the expression.
+     * 
+     * @param node the expression to extract filters from
+	 * @param literalFilters a map from variables to a List of filters (of any type
+	 *                       supported by the underlying AdvancedRdfSource).
+     */
+	protected void extractLiteralFilters(ExpressionLogic node, Map literalFilters) {
+		if (node instanceof ASTAndNode) {
+			extractLiteralFilters(((ASTAndNode)node).getLeftExpression(), literalFilters);
+			extractLiteralFilters(((ASTAndNode)node).getRightExpression(), literalFilters);
+		}
+	}
+	
+	protected void addLiteralFilter(Variable variable, Object filter, Map literalFilters) {
+		List list = (List)literalFilters.get(variable);
+		if (list == null) {
+			list = new java.util.ArrayList();
+			literalFilters.put(variable, list);
+		}
+		list.add(filter);
+	}
+	
+	private void extractVariableFunctions(Map knownValues) {
+        for (Iterator cons = data.getConstraints().iterator(); cons.hasNext();) {
+            ConstraintLogic c = (ConstraintLogic) cons.next();
+            if (c instanceof FilterConstraintData) {
+				FilterConstraintData f = (FilterConstraintData)c;
+				extractVariableFunctions(f.getExpression(), knownValues);
+			}
+		}
+	}
+	
+	private void extractVariableFunctions(ExpressionLogic node, Map knownValues) {
+		if (node instanceof ASTAndNode) {
+			extractVariableFunctions(((ASTAndNode)node).getLeftExpression(), knownValues);
+			extractVariableFunctions(((ASTAndNode)node).getRightExpression(), knownValues);
+		}
+		if (node instanceof ASTOrNode) {
+			Map a = new HashMap();
+			Map b = new HashMap();
+			extractVariableFunctions(((ASTOrNode)node).getLeftExpression(), a);
+			extractVariableFunctions(((ASTOrNode)node).getRightExpression(), b);
+			for (Iterator i = a.keySet().iterator(); i.hasNext(); ) {
+				Variable v = (Variable)i.next();
+				if (b.containsKey(v)) {
+					Set av = (Set)a.get(v);
+					Set bv = (Set)b.get(v);
+					av.addAll(bv);
+					if (knownValues.containsKey(v)) {
+						((Set)knownValues.get(v)).retainAll(av);
+					} else {
+						knownValues.put(v, av);
+					}
+				}
+			}
+		}
+		if (node instanceof ASTEqualsNode) {
+			extractVariableFunctions(((ASTEqualsNode)node).getLeftExpression(), ((ASTEqualsNode)node).getRightExpression(), knownValues);
+			extractVariableFunctions(((ASTEqualsNode)node).getRightExpression(), ((ASTEqualsNode)node).getLeftExpression(), knownValues);
+		}
+	}
+	
+	private void extractVariableFunctions(ExpressionLogic a, ExpressionLogic b, Map knownValues) {
+		if (!(a instanceof Variable)) return;
+		if (knownValues.containsKey(a)) return; // we could intersect with existing values, but be sure not to do this for values we just inserted into the hash
+		
+		if (b instanceof Variable && knownValues.containsKey(b)) {
+			knownValues.put(a, knownValues.get(b));
+		
+		} else if (b instanceof ExternalFunctionLogic) {
+			// if this is a function of one variable, get the values by applying the function
+			// to all of the variables values.  (if it's of more than one variable, we could
+			// permute through the variables...)
+			ExternalFunctionLogic f = (ExternalFunctionLogic)b;
+			Set varargs =  getFilterVariables((SimpleNode)b);
+			
+			if (varargs.size() == 0) { // a constant, ok
+				Value v = f.evaluate(new MyBindingRow(new HashMap()));
+				HashSet vs = new HashSet();
+				vs.add(v);
+				knownValues.put(a, vs);
+				return;
+			}
+			
+			if (varargs.size() > 1) return;
+			
+			for (Iterator i = varargs.iterator(); i.hasNext(); ) {
+				Variable var = (Variable)i.next();
+				if (!knownValues.containsKey(var))
+					return;
+				
+				Set varvalues = (Set)knownValues.get(var);
+				Set newvalues = new HashSet();
+				Map bindings = new HashMap();
+				for (Iterator j = varvalues.iterator(); j.hasNext(); ) {
+					bindings.put(var, j.next());
+					newvalues.add( f.evaluate(new MyBindingRow(bindings)) );
+				}
+				
+				knownValues.put(a, newvalues);
+			}
+		}
+		
+		
+		// TODO: if b is a function whose arguments are all constants or known values, evaluate the function
+	}
+	
+	private class MyBindingRow extends AbstractRdfBindingRow {
+		Map values;
+		public MyBindingRow(Map values) { super(null); this.values = values; }
+		public List getVariables() { return new java.util.ArrayList(values.keySet()); }
+		public Value getValue(Variable v) { return (Value)values.get(v); }
+	}
+	
+    /**
+     * Returns the complexity of the triple constraint, given a set of
+	 * variables that already have known values.  The return value is a
+	 * measure of the number of statements that we expect to match the
+	 * filter, on a nonsensical scale.
+     * 
+     * @param variablesKnown a set of variables whose values are known
+     */
+	private float getComplexity(TripleConstraint triple, Set variablesKnown, Set cheapVariables, Map knownFilters, RdfSource source) {
+		Object subject = triple.getSubjectExpression();
+		Object predicate = triple.getPredicateExpression();
+		Object object = triple.getObjectExpression();
+		
+		boolean isFunctional = predicate instanceof URI && isFunctional((URI)predicate, source, true);
+		boolean isInverseFunctional = predicate instanceof URI && isFunctional((URI)predicate, source, false);
+		
+		// Properties in RDF tend to be many-to-few.  That is, lots of people
+		// may have a particular foaf:name, and one person has very few foaf:names.
+		// Thus, we give a penalty when a new variable occurs in subject position.
+		// Furthermore, we give an even bigger penality for variables in predicate position.
+		
+		float subjComplexity = getComplexity2(subject, variablesKnown, cheapVariables, knownFilters, 3);
+		float predComplexity = getComplexity2(predicate, variablesKnown, cheapVariables, knownFilters, 4);
+		float objComplexity = getComplexity2(object, variablesKnown, cheapVariables, knownFilters, 2);
+
+		// If this is a functional or inverse functional statement, then we reduce the
+		// complexity of the object because we know it is in a 1-to-1 relation with
+		// the subject (or the other way around).  (And, in these cases the predicate
+		// isn't a variable, so its complexity is zero anyway.)  Note that these
+		// computations are based on the 1 + maximum possible complexity for the
+		// subject and object, so *modifications to the getComplexity2 function and
+		// the penalities should be reflected here.
+		
+		if (isFunctional) objComplexity /= (6 - subjComplexity);
+		if (isInverseFunctional) subjComplexity /= (5 - objComplexity);
+		// If both functional and inverse functional, then does this make sense?
+		
+		return subjComplexity + predComplexity + objComplexity;
+	}
+	
+	private int getComplexity2(Object thing, Set variablesKnown, Set cheapVariables, Map knownFilters, int penalty) {
+		int ret = 0;
+		if (thing instanceof Variable && !cheapVariables.contains(thing)) {
+			ret++;
+			if (!knownFilters.containsKey(thing)) ret++;
+			if (!variablesKnown.contains(thing)) ret += penalty;
+		}
+		return ret;
+	}
+	
+	private boolean isFunctional(URI predicate, RdfSource source, boolean forward) {
+		Map map = forward ? isFunctional : isInverseFunctional;
+		if (map.containsKey(predicate)) return ((Boolean)map.get(predicate)).booleanValue();
+	
+		URI rdftype = new org.openrdf.model.impl.URIImpl("http://www.w3.org/1999/02/22-rdf-syntax-ns#type");
+		String typeuri = "http://www.w3.org/2002/07/owl#" +
+			( forward ? "FunctionalProperty" : "InverseFunctionalProperty");
+		boolean ret = source.hasDefaultStatement(predicate, rdftype, new org.openrdf.model.impl.URIImpl(typeuri));
+		map.put(predicate, new Boolean(ret));
+		return ret;
+	}
+
+	
+    /**
+     * Adds the variables in the constraint into the set.
+     * 
+     * @param variablesKnown a set of variables whose values are known
+     */
+	private void getVariables(TripleConstraint triple, Set variablesKnown) {
+		if (triple.getSubjectExpression() instanceof Variable) variablesKnown.add(triple.getSubjectExpression());
+		if (triple.getPredicateExpression() instanceof Variable) variablesKnown.add(triple.getPredicateExpression());
+		if (triple.getObjectExpression() instanceof Variable) variablesKnown.add(triple.getObjectExpression());
+	}
+	
+   /**
+     * Gets a variable for the filter.  If the filter is a ASTEqualsNode,
+	 * return the variable on the left hand side.  If the filter is a
+	 * ASTOrNode, return the variable if its the same on both sides,
+	 * or else null.
+     */
+	private Variable getFilterPrimaryVariable(BinaryExpressionNode expr) {
+		if (expr instanceof ASTOrNode
+			&& expr.getLeftExpression() instanceof BinaryExpressionNode
+			&& expr.getRightExpression() instanceof BinaryExpressionNode) {
+			Variable left = getFilterPrimaryVariable((BinaryExpressionNode)expr.getLeftExpression());
+			Variable right = getFilterPrimaryVariable((BinaryExpressionNode)expr.getRightExpression());
+			if (left != null && right != null && left.equals(right)) return left;
+		} else if (expr instanceof ASTEqualsNode
+			&& expr.getLeftExpression() instanceof Variable && (expr.getRightExpression() instanceof URI || expr.getRightExpression() instanceof BNode || expr.getRightExpression() instanceof Literal)) {
+			return (Variable)expr.getLeftExpression(); 
+		}
+		return null;
+	}
+	
+   /**
+     * Gets the values for a filter.  For an ASTEqualsNode, returns
+	 * the right hand side.  For an ASTOrNode, returns the values of its parts.
+     */
+	private void getFilterValues(BinaryExpressionNode expr, Set set) {
+		if (expr instanceof ASTOrNode) {
+			getFilterValues((BinaryExpressionNode)expr.getLeftExpression(), set);
+			getFilterValues((BinaryExpressionNode)expr.getRightExpression(), set);
+		} else if (expr instanceof ASTEqualsNode && (expr.getRightExpression() instanceof URI || expr.getRightExpression() instanceof BNode || expr.getRightExpression() instanceof Literal)) {
+			set.add(expr.getRightExpression());
+		}
+	}
+
+	private Set getFilterVariables(SimpleNode filter) {
+		final HashSet ret = new HashSet();
+		filter.jjtAccept(
+			new EmptyVisitor() {
+				public void visit(ASTVar node) {
+					ret.add(node);
+				}
+			}
+			);
+		return ret;
+	}
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/streamed/AdvancedGroupConstraintLogic.java~ work-copy/src/main/name/levering/ryan/sparql/logic/streamed/AdvancedGroupConstraintLogic.java~
--- upstream/src/main/name/levering/ryan/sparql/logic/streamed/AdvancedGroupConstraintLogic.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/streamed/AdvancedGroupConstraintLogic.java~	2007-02-21 07:33:42.000000000 -0500
@@ -0,0 +1,568 @@
+/*
+ * SPARQL Engine
+ * Copyright (C) 2005 Ryan Levering, All rights reserved.
+ * See LICENSE for full license information
+ */
+package name.levering.ryan.sparql.logic;
+
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+
+import org.openrdf.model.URI;
+import org.openrdf.model.BNode;
+import org.openrdf.model.Literal;
+import org.openrdf.model.Value;
+
+import name.levering.ryan.sparql.common.impl.AbstractRdfBindingRow;
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfBindingRow;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.common.Variable;
+import name.levering.ryan.sparql.common.impl.RdfBindingSetImpl;
+import name.levering.ryan.sparql.logic.function.ExternalFunctionLogic;
+import name.levering.ryan.sparql.model.TripleConstraint;
+import name.levering.ryan.sparql.model.data.FilterConstraintData;
+import name.levering.ryan.sparql.model.data.GroupConstraintData;
+import name.levering.ryan.sparql.model.data.OptionalConstraintData;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
+import name.levering.ryan.sparql.model.logic.ExpressionLogic;
+import name.levering.ryan.sparql.model.logic.helper.SetIntersectLogic;
+import name.levering.ryan.sparql.parser.model.ASTAndNode;
+import name.levering.ryan.sparql.parser.model.ASTEqualsNode;
+import name.levering.ryan.sparql.parser.model.ASTOrNode;
+import name.levering.ryan.sparql.parser.model.ASTVar;
+import name.levering.ryan.sparql.parser.model.BinaryExpressionNode;
+import name.levering.ryan.sparql.parser.model.DelegatingTripleConstraint;
+import name.levering.ryan.sparql.parser.model.EmptyVisitor;
+import name.levering.ryan.sparql.parser.model.SimpleNode;
+
+/**
+ * This logic is the default logic for the main constraint that is used as an
+ * aggregate of other constraints. TripleConstraints, UnionConstraints, and
+ * GraphConstraints all are intersected with the running binding set. After
+ * that, OptionalConstraints and FilterConstraints modify the set themselves.
+ * 
+ * @author Ryan Levering
+ * @version 1.0
+ */
+public class AdvancedGroupConstraintLogic implements ConstraintLogic {
+
+    /**
+     * The data that holds the constraints that this group constraint
+     * aggregates.
+     */
+    private final GroupConstraintData data;
+
+    /**
+     * This logic that intersects the parts of the graph pattern.
+     */
+    private final SetIntersectLogic logic;
+    
+    private static final Map
+		isFunctional = new HashMap(),
+    	isInverseFunctional = new HashMap();
+    
+    /**
+     * Creates a new default group logic, with the given subconstraints found in
+     * the data.
+     * 
+     * @param data the data holding the subconstraints to bind
+     */
+    public AdvancedGroupConstraintLogic(GroupConstraintData data, SetIntersectLogic logic) {
+        this.logic = logic;
+        this.data = data;
+    }
+
+    /**
+     * Applies each subconstraint in turn, saving filter and optional
+     * constraints for last, as according to specification.
+     * 
+     * @param bindings the current running bindings, ignored here
+     * @param source the source to query RDF triples, passed on to
+     *            subconstraints
+     * @param defaultDatasets the datasets to query by default, passed on to
+     *            subconstraints
+     * @param namedDatasets the named datasets to query in an unbound graph
+     *            query, passed on to subconstraints
+     */
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+	
+		// Build separate lists for the different constraints that this group may contain.
+
+		List tripleConstraints = new LinkedList();
+        List filterQueue = new LinkedList();
+        List optionalQueue = new LinkedList();
+		List otherQueue = new LinkedList();
+
+		// Clone knownValues and knownFilters so we can freely modify it without affecting the caller.
+		
+		p = p.clone();
+		if (p.knownValues == null)
+			p.knownValues = new HashMap();
+		else
+			p.knownValues = new HashMap(p.knownValues);
+			
+		if (p.knownFilters == null)
+			p.knownFilters = new HashMap();
+		else
+			p.knownFilters = new HashMap(p.knownFilters);
+		
+		// Get a list of variables that have known values, and of those the ones that are really cheap
+		// (i.e. have just a few values).
+		// We'll build these sets in the course of reordering the statements to query most efficiently.
+
+		Set knownVars = new HashSet();
+		Set cheapVars = new HashSet();
+		
+		// Any variables known by groups on top of us are known here, and cheap (I guess).
+		knownVars.addAll(p.knownValues.keySet());
+		cheapVars.addAll(p.knownValues.keySet());
+		
+		// Split out the types of constraints and look for filters that tell us interesting things.
+		
+        for (Iterator cons = data.getConstraints().iterator(); cons.hasNext();) {
+            ConstraintLogic c = (ConstraintLogic) cons.next();
+            if (c instanceof OptionalConstraintData) {
+				optionalQueue.add(c);
+            } else if (c instanceof FilterConstraintData) {
+				filterQueue.add(c);
+				
+				FilterConstraintData f = (FilterConstraintData)c;
+				if (f.getExpression() instanceof BinaryExpressionNode) {
+					// If this filter is of the form FILTER(?var = <uri> || ?var = <uri> || ...)
+					// then this is giving us some known values for the variable.
+					BinaryExpressionNode b = (BinaryExpressionNode)f.getExpression();
+					Variable v = getFilterPrimaryVariable(b);
+					if (v != null) {
+						Set values = new HashSet();
+						getFilterValues(b, values);
+						if (!p.knownValues.containsKey(v)) {
+							p.knownValues.put(v, values);
+							knownVars.add(v);
+							cheapVars.add(v);
+						} else {
+							Set othervalues = (Set)knownValues.get(v);
+							othervalues.retainAll(values);
+						}
+					}
+				}
+				
+				// This by default does nothing, but subclassors may decide to do things here.
+				extractLiteralFilters(f.getExpression(), p.knownFilters);
+				
+			} else if (c instanceof TripleConstraint) {
+				tripleConstraints.add(c);
+			} else {
+				otherQueue.add(c);
+			}
+		}
+		
+		// Reorder the triple constraints so that complex constraints are done
+		// after some of their variables have already been evaluated.  This is
+		// a bit N^2-ish in the number of triple constraints, but it can be improved.
+		List constraintOrder = new LinkedList();
+		Set selectedVars = new HashSet();
+		while (tripleConstraints.size() > 0) {
+			TripleConstraint leastConstraint = null;
+			float leastComplexity = -1;
+			
+			if (tripleConstraints.size() == 1) {
+				leastConstraint = (TripleConstraint)tripleConstraints.get(0);
+			} else {
+				//System.err.println(">>>");
+				
+				for (Iterator cons = tripleConstraints.iterator(); cons.hasNext();) {
+					TripleConstraint c = (TripleConstraint) cons.next();
+					float complexity = getComplexity(c, knownVars, cheapVars, knownFilters, source);
+					//System.err.println(">>> " + complexity + "\t" + c);
+					if (leastConstraint == null || complexity < leastComplexity) {
+						leastComplexity = complexity;
+						leastConstraint = c;
+					}
+				}
+			}
+
+			tripleConstraints.remove(leastConstraint);
+			constraintOrder.add(leastConstraint);
+			
+			// Get the variables mentioned in this triple constraint
+			Set constraintVars = new HashSet();
+			getVariables(leastConstraint, constraintVars);
+			
+			// Keep a list of variables that have been selected on so far
+			selectedVars.addAll(constraintVars);
+			
+			// And all of these variables are now considered 'known' for the purposes of
+			// selecting which statement goes next.  But they're not considered 'cheap'.
+			knownVars.addAll(constraintVars);
+			
+			// Well, if this triple was functional or inverse functional, we *can*
+			// consider the variables mentioned in the triple cheap.
+			if (leastComplexity <= 1)
+				cheapVars.addAll(constraintVars);
+			
+			// Perform any filters that are such that all of the
+			// variables mentioned in the filter have already been selected
+			// on.  The earlier we filter the better.  (We have to know not just
+			// which variables are known so far, because ones that are known from
+			// filters may not yet be actually bound in the binding set.  Rather,
+			// we have to know which ones have actually been selected on in a
+			// triple.  Here, we only know what's been selected on in this group,
+			// and not at a higher level.)
+	        for (Iterator filters = filterQueue.iterator(); filters.hasNext();) {
+	            FilterConstraintData c = (FilterConstraintData) filters.next();
+	            /*boolean allvarsknown = true;
+	            Set filterVars = getFilterVariables((SimpleNode)c);
+	            for (Iterator vars = filterVars.iterator(); vars.hasNext(); ) {
+	            	if (!selectedVars.contains(vars.next())) {
+	            		allvarsknown = false;
+	            		break;
+	            	}
+	            }
+	            if (allvarsknown) {
+	            	constraintOrder.add(c);
+	            	filters.remove();
+	            }*/
+	        }
+        }
+		
+		// Add the otherQueue back in.
+		constraintOrder.addAll(otherQueue);
+
+		// Run the constraints in the new order.
+        RdfBindingSet current = null;
+		
+		// Allow a subclass to take over running the constraints.
+		current = runTripleConstraints(constraintOrder, p.source, p.defaultDatasets, p.namedDatasets, p.knownValues, p.knownFilters);
+		if (current != null) {
+			constraintOrder.clear();
+			if (optionalQueue.size() > 0)
+				current = updateKnownVariables(current, p.knownValues);
+		}
+		
+		for (Iterator cons = constraintOrder.iterator(); cons.hasNext();) {
+			ConstraintLogic c = (ConstraintLogic) cons.next();
+			
+			p.bindings = current;
+			
+			if (current == null) {
+				current = c.constrain(p);
+			} else if (c instanceof FilterConstraintData) {
+	            current = c.constrain(p);
+	            filterQueue.remove(c);
+			} else {
+				current = logic.intersect(current, c.constrain(p));
+			}
+
+			if (cons.hasNext() || optionalQueue.size() > 0)
+				current = updateKnownVariables(current, p.knownValues);
+        }
+        
+        // At this point, we're operating on the set, so let's make it an empty one
+        if (current == null) {
+            current = new RdfBindingSetImpl();
+        }
+
+		// Any optionals...
+        for (Iterator optionals = optionalQueue.iterator(); optionals.hasNext();) {
+            ConstraintLogic c = (ConstraintLogic) optionals.next();
+				p.bindings = current;
+            current = c.constrain(p);
+        }
+		
+		// Any filters that were not moved up in the logic to process them as early as possible.
+        for (Iterator filters = filterQueue.iterator(); filters.hasNext();) {
+            ConstraintLogic c = (ConstraintLogic) filters.next();
+				p.bindings = current;
+            current = c.constrain(p);
+        }
+        return current;
+    }
+
+	protected RdfBindingSet runTripleConstraints(List tripleConstraints, RdfSource source,
+            Collection defaultDatasets, Collection namedDatasets, Map knownValues, Map knownFilters) {
+		return null;
+	}
+	
+	private RdfBindingSet updateKnownVariables(RdfBindingSet current, Map knownValues) {
+		// If there are more things happening later, update our knownValue
+		// mapping based on what has currently been queried.  We have to
+		// loop through all of the bindings found so far, so we'll put
+		// those bindings into a new set to cache them.
+		
+		current = new RdfBindingSetImpl(current);
+		List variables = current.getVariables();
+		
+		Set hadNewValues = new HashSet();
+		for (Iterator biter = current.iterator(); biter.hasNext(); ) {
+			RdfBindingRow row = (RdfBindingRow)biter.next();
+			List rowvalues = row.getValues();
+			
+			for (int i = 0; i < variables.size(); i++) {
+				Variable var = (Variable) variables.get(i);
+				Value val = (Value) rowvalues.get(i);
+				
+				if (val == null) continue;
+				
+				Set values = (Set)knownValues.get(var);
+				
+				// If knownValues has no mapping for this variable yet,
+				// or if knownValues had a mapping, we want to clear
+				// the mapping and start fresh with the values actually
+				// found.
+				if (values == null || !hadNewValues.contains(var)) { 
+					values = new HashSet();
+					knownValues.put(var, values);
+					hadNewValues.add(var);
+				}
+					
+				values.add(val);
+			}
+		}
+		
+		extractVariableFunctions(knownValues);	
+		
+		return current;
+	}
+	
+    /**
+     * Creates a mapping from variables to a List of filters based on
+	 * the expression.
+     * 
+     * @param node the expression to extract filters from
+	 * @param literalFilters a map from variables to a List of filters (of any type
+	 *                       supported by the underlying AdvancedRdfSource).
+     */
+	protected void extractLiteralFilters(ExpressionLogic node, Map literalFilters) {
+		if (node instanceof ASTAndNode) {
+			extractLiteralFilters(((ASTAndNode)node).getLeftExpression(), literalFilters);
+			extractLiteralFilters(((ASTAndNode)node).getRightExpression(), literalFilters);
+		}
+	}
+	
+	protected void addLiteralFilter(Variable variable, Object filter, Map literalFilters) {
+		List list = (List)literalFilters.get(variable);
+		if (list == null) {
+			list = new java.util.ArrayList();
+			literalFilters.put(variable, list);
+		}
+		list.add(filter);
+	}
+	
+	private void extractVariableFunctions(Map knownValues) {
+        for (Iterator cons = data.getConstraints().iterator(); cons.hasNext();) {
+            ConstraintLogic c = (ConstraintLogic) cons.next();
+            if (c instanceof FilterConstraintData) {
+				FilterConstraintData f = (FilterConstraintData)c;
+				extractVariableFunctions(f.getExpression(), knownValues);
+			}
+		}
+	}
+	
+	private void extractVariableFunctions(ExpressionLogic node, Map knownValues) {
+		if (node instanceof ASTAndNode) {
+			extractVariableFunctions(((ASTAndNode)node).getLeftExpression(), knownValues);
+			extractVariableFunctions(((ASTAndNode)node).getRightExpression(), knownValues);
+		}
+		if (node instanceof ASTOrNode) {
+			Map a = new HashMap();
+			Map b = new HashMap();
+			extractVariableFunctions(((ASTOrNode)node).getLeftExpression(), a);
+			extractVariableFunctions(((ASTOrNode)node).getRightExpression(), b);
+			for (Iterator i = a.keySet().iterator(); i.hasNext(); ) {
+				Variable v = (Variable)i.next();
+				if (b.containsKey(v)) {
+					Set av = (Set)a.get(v);
+					Set bv = (Set)b.get(v);
+					av.addAll(bv);
+					if (knownValues.containsKey(v)) {
+						((Set)knownValues.get(v)).retainAll(av);
+					} else {
+						knownValues.put(v, av);
+					}
+				}
+			}
+		}
+		if (node instanceof ASTEqualsNode) {
+			extractVariableFunctions(((ASTEqualsNode)node).getLeftExpression(), ((ASTEqualsNode)node).getRightExpression(), knownValues);
+			extractVariableFunctions(((ASTEqualsNode)node).getRightExpression(), ((ASTEqualsNode)node).getLeftExpression(), knownValues);
+		}
+	}
+	
+	private void extractVariableFunctions(ExpressionLogic a, ExpressionLogic b, Map knownValues) {
+		if (!(a instanceof Variable)) return;
+		if (knownValues.containsKey(a)) return; // we could intersect with existing values, but be sure not to do this for values we just inserted into the hash
+		
+		if (b instanceof Variable && knownValues.containsKey(b)) {
+			knownValues.put(a, knownValues.get(b));
+		
+		} else if (b instanceof ExternalFunctionLogic) {
+			// if this is a function of one variable, get the values by applying the function
+			// to all of the variables values.  (if it's of more than one variable, we could
+			// permute through the variables...)
+			ExternalFunctionLogic f = (ExternalFunctionLogic)b;
+			Set varargs =  getFilterVariables((SimpleNode)b);
+			
+			if (varargs.size() == 0) { // a constant, ok
+				Value v = f.evaluate(new MyBindingRow(new HashMap()));
+				HashSet vs = new HashSet();
+				vs.add(v);
+				knownValues.put(a, vs);
+				return;
+			}
+			
+			if (varargs.size() > 1) return;
+			
+			for (Iterator i = varargs.iterator(); i.hasNext(); ) {
+				Variable var = (Variable)i.next();
+				if (!knownValues.containsKey(var))
+					return;
+				
+				Set varvalues = (Set)knownValues.get(var);
+				Set newvalues = new HashSet();
+				Map bindings = new HashMap();
+				for (Iterator j = varvalues.iterator(); j.hasNext(); ) {
+					bindings.put(var, j.next());
+					newvalues.add( f.evaluate(new MyBindingRow(bindings)) );
+				}
+				
+				knownValues.put(a, newvalues);
+			}
+		}
+		
+		
+		// TODO: if b is a function whose arguments are all constants or known values, evaluate the function
+	}
+	
+	private class MyBindingRow extends AbstractRdfBindingRow {
+		Map values;
+		public MyBindingRow(Map values) { super(null); this.values = values; }
+		public List getVariables() { return new java.util.ArrayList(values.keySet()); }
+		public Value getValue(Variable v) { return (Value)values.get(v); }
+	}
+	
+    /**
+     * Returns the complexity of the triple constraint, given a set of
+	 * variables that already have known values.  The return value is a
+	 * measure of the number of statements that we expect to match the
+	 * filter, on a nonsensical scale.
+     * 
+     * @param variablesKnown a set of variables whose values are known
+     */
+	private float getComplexity(TripleConstraint triple, Set variablesKnown, Set cheapVariables, Map knownFilters, RdfSource source) {
+		Object subject = triple.getSubjectExpression();
+		Object predicate = triple.getPredicateExpression();
+		Object object = triple.getObjectExpression();
+		
+		boolean isFunctional = predicate instanceof URI && isFunctional((URI)predicate, source, true);
+		boolean isInverseFunctional = predicate instanceof URI && isFunctional((URI)predicate, source, false);
+		
+		// Properties in RDF tend to be many-to-few.  That is, lots of people
+		// may have a particular foaf:name, and one person has very few foaf:names.
+		// Thus, we give a penalty when a new variable occurs in subject position.
+		// Furthermore, we give an even bigger penality for variables in predicate position.
+		
+		float subjComplexity = getComplexity2(subject, variablesKnown, cheapVariables, knownFilters, 3);
+		float predComplexity = getComplexity2(predicate, variablesKnown, cheapVariables, knownFilters, 4);
+		float objComplexity = getComplexity2(object, variablesKnown, cheapVariables, knownFilters, 2);
+
+		// If this is a functional or inverse functional statement, then we reduce the
+		// complexity of the object because we know it is in a 1-to-1 relation with
+		// the subject (or the other way around).  (And, in these cases the predicate
+		// isn't a variable, so its complexity is zero anyway.)  Note that these
+		// computations are based on the 1 + maximum possible complexity for the
+		// subject and object, so *modifications to the getComplexity2 function and
+		// the penalities should be reflected here.
+		
+		if (isFunctional) objComplexity /= (6 - subjComplexity);
+		if (isInverseFunctional) subjComplexity /= (5 - objComplexity);
+		// If both functional and inverse functional, then does this make sense?
+		
+		return subjComplexity + predComplexity + objComplexity;
+	}
+	
+	private int getComplexity2(Object thing, Set variablesKnown, Set cheapVariables, Map knownFilters, int penalty) {
+		int ret = 0;
+		if (thing instanceof Variable && !cheapVariables.contains(thing)) {
+			ret++;
+			if (!knownFilters.containsKey(thing)) ret++;
+			if (!variablesKnown.contains(thing)) ret += penalty;
+		}
+		return ret;
+	}
+	
+	private boolean isFunctional(URI predicate, RdfSource source, boolean forward) {
+		Map map = forward ? isFunctional : isInverseFunctional;
+		if (map.containsKey(predicate)) return ((Boolean)map.get(predicate)).booleanValue();
+	
+		URI rdftype = new org.openrdf.model.impl.URIImpl("http://www.w3.org/1999/02/22-rdf-syntax-ns#type");
+		String typeuri = "http://www.w3.org/2002/07/owl#" +
+			( forward ? "FunctionalProperty" : "InverseFunctionalProperty");
+		boolean ret = source.hasDefaultStatement(predicate, rdftype, new org.openrdf.model.impl.URIImpl(typeuri));
+		map.put(predicate, new Boolean(ret));
+		return ret;
+	}
+
+	
+    /**
+     * Adds the variables in the constraint into the set.
+     * 
+     * @param variablesKnown a set of variables whose values are known
+     */
+	private void getVariables(TripleConstraint triple, Set variablesKnown) {
+		if (triple.getSubjectExpression() instanceof Variable) variablesKnown.add(triple.getSubjectExpression());
+		if (triple.getPredicateExpression() instanceof Variable) variablesKnown.add(triple.getPredicateExpression());
+		if (triple.getObjectExpression() instanceof Variable) variablesKnown.add(triple.getObjectExpression());
+	}
+	
+   /**
+     * Gets a variable for the filter.  If the filter is a ASTEqualsNode,
+	 * return the variable on the left hand side.  If the filter is a
+	 * ASTOrNode, return the variable if its the same on both sides,
+	 * or else null.
+     */
+	private Variable getFilterPrimaryVariable(BinaryExpressionNode expr) {
+		if (expr instanceof ASTOrNode
+			&& expr.getLeftExpression() instanceof BinaryExpressionNode
+			&& expr.getRightExpression() instanceof BinaryExpressionNode) {
+			Variable left = getFilterPrimaryVariable((BinaryExpressionNode)expr.getLeftExpression());
+			Variable right = getFilterPrimaryVariable((BinaryExpressionNode)expr.getRightExpression());
+			if (left != null && right != null && left.equals(right)) return left;
+		} else if (expr instanceof ASTEqualsNode
+			&& expr.getLeftExpression() instanceof Variable && (expr.getRightExpression() instanceof URI || expr.getRightExpression() instanceof BNode || expr.getRightExpression() instanceof Literal)) {
+			return (Variable)expr.getLeftExpression(); 
+		}
+		return null;
+	}
+	
+   /**
+     * Gets the values for a filter.  For an ASTEqualsNode, returns
+	 * the right hand side.  For an ASTOrNode, returns the values of its parts.
+     */
+	private void getFilterValues(BinaryExpressionNode expr, Set set) {
+		if (expr instanceof ASTOrNode) {
+			getFilterValues((BinaryExpressionNode)expr.getLeftExpression(), set);
+			getFilterValues((BinaryExpressionNode)expr.getRightExpression(), set);
+		} else if (expr instanceof ASTEqualsNode && (expr.getRightExpression() instanceof URI || expr.getRightExpression() instanceof BNode || expr.getRightExpression() instanceof Literal)) {
+			set.add(expr.getRightExpression());
+		}
+	}
+
+	private Set getFilterVariables(SimpleNode filter) {
+		final HashSet ret = new HashSet();
+		filter.jjtAccept(
+			new EmptyVisitor() {
+				public void visit(ASTVar node) {
+					ret.add(node);
+				}
+			}
+			);
+		return ret;
+	}
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/streamed/IndexedSetIntersectLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/streamed/IndexedSetIntersectLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/streamed/IndexedSetIntersectLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/streamed/IndexedSetIntersectLogic.java	2006-12-02 11:01:18.000000000 -0500
@@ -64,7 +64,7 @@
         final List variables;
 
         final List commonVariables;
-
+		
         RdfBindingIntersect(RdfBindingSet set1, RdfBindingSet set2) {
             this.set1 = set1;
             this.set2 = set2;
@@ -259,10 +259,11 @@
             }
 
             public Value getValue(Variable variable) {
-                Value returnValue = this.row1.getValue(variable);
-                if (returnValue == null) {
+				Value returnValue = null;
+				if (set1.getVariables().contains(variable))
+					returnValue = this.row1.getValue(variable);
+                if (returnValue == null && set2.getVariables().contains(variable))
                     returnValue = this.row2.getValue(variable);
-                }
                 return returnValue;
             }
 
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/streamed/IndexedSetJoinLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/streamed/IndexedSetJoinLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/streamed/IndexedSetJoinLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/streamed/IndexedSetJoinLogic.java	2006-12-02 11:01:18.000000000 -0500
@@ -81,7 +81,7 @@
 		final List variables;
 
 		final List commonVariables;
-
+		
 		RdfBindingJoin(RdfBindingSet set1, RdfBindingSet set2, Collection filters) {
 			this.set1 = set1;
 			this.set2 = set2;
@@ -293,14 +293,11 @@
 			}
 
 			public Value getValue(Variable variable) {
-				Value returnValue = this.row1.getValue(variable);
-				if (returnValue == null) {
-					if (this.row2 == null) {
-						returnValue = null;
-					} else {
-						returnValue = this.row2.getValue(variable);
-					}
-				}
+				Value returnValue = null;
+				if (set1.getVariables().contains(variable))
+					returnValue = this.row1.getValue(variable);
+				if (returnValue == null && this.row2 != null && set2.getVariables().contains(variable))
+					returnValue = this.row2.getValue(variable);
 				return returnValue;
 			}
 
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/streamed/StreamedFilterConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/streamed/StreamedFilterConstraintLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/streamed/StreamedFilterConstraintLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/streamed/StreamedFilterConstraintLogic.java	2007-02-21 07:33:50.000000000 -0500
@@ -10,6 +10,7 @@
 import java.util.Iterator;
 import java.util.LinkedList;
 import java.util.List;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingRow;
 import name.levering.ryan.sparql.common.RdfBindingSet;
@@ -76,9 +77,8 @@
 	 *            this constraint
 	 * @return a binding set with values that pass through the filter expression
 	 */
-	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
-		return new FilterBindingSet(bindings, this.data.getExpression());
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+		return new FilterBindingSet(p.bindings, this.data.getExpression());
 	}
 
 	private class FilterBindingSet extends AbstractRdfBindingSet implements StackedRdfBindingSet {
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/streamed/StreamedFilterConstraintLogic.java~ work-copy/src/main/name/levering/ryan/sparql/logic/streamed/StreamedFilterConstraintLogic.java~
--- upstream/src/main/name/levering/ryan/sparql/logic/streamed/StreamedFilterConstraintLogic.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/streamed/StreamedFilterConstraintLogic.java~	2007-02-21 07:05:14.000000000 -0500
@@ -0,0 +1,170 @@
+/*
+ * SPARQL Engine
+ * Copyright (C) 2005 Ryan Levering, All rights reserved.
+ * See LICENSE for full license information
+ */
+package name.levering.ryan.sparql.logic.streamed;
+
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Iterator;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+
+import name.levering.ryan.sparql.common.RdfBindingRow;
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.common.impl.AbstractRdfBindingSet;
+import name.levering.ryan.sparql.logic.expression.TypeError;
+import name.levering.ryan.sparql.model.data.FilterConstraintData;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
+import name.levering.ryan.sparql.model.logic.ExpressionLogic;
+import name.levering.ryan.sparql.model.logic.helper.EffectiveBooleanLogic;
+import name.levering.ryan.sparql.model.logic.helper.ValueConversionLogic;
+
+import org.openrdf.model.Value;
+
+/**
+ * The default logic that controls how the bound results are filtered by
+ * evaluation against value expressions. This will apply an expression to each
+ * row, eliminating any value rows that produce a false or erroneous output.
+ * 
+ * @author Ryan Levering
+ * @version 1.0
+ */
+public class StreamedFilterConstraintLogic implements ConstraintLogic {
+
+	/**
+	 * The data that contains the expression to evaluate.
+	 */
+	private final FilterConstraintData data;
+
+	/**
+	 * The logic to force the expression results to a boolean value.
+	 */
+	final EffectiveBooleanLogic boolLogic;
+
+	/**
+	 * The logic to convert the boolean literal to a Java boolean for
+	 * evaluation.
+	 */
+	final ValueConversionLogic converter;
+
+	/**
+	 * Creates a new default filter logic, that uses the expression data with
+	 * the boolean and conversion logic to filter bound data values.
+	 * 
+	 * @param data the data containing the filter expression
+	 * @param boolLogic the logic to coerce boolean values
+	 * @param converter the logic to convert to Java boolean
+	 */
+	public StreamedFilterConstraintLogic(FilterConstraintData data, EffectiveBooleanLogic boolLogic,
+			ValueConversionLogic converter) {
+		this.data = data;
+		this.boolLogic = boolLogic;
+		this.converter = converter;
+	}
+
+	/**
+	 * Filters the passed in binding set, only adding those rows that return a
+	 * true boolean value to the returned binding set.
+	 * 
+	 * @param bindings the current bound values
+	 * @param source the RDF source, not used in this constraint
+	 * @param defaultDatasets the datasets to query, not used in this constraint
+	 * @param namedDatasets the named datasets for graph queries, not used in
+	 *            this constraint
+	 * @return a binding set with values that pass through the filter expression
+	 */
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+		return new FilterBindingSet(bindings, this.data.getExpression());
+	}
+
+	private class FilterBindingSet extends AbstractRdfBindingSet implements StackedRdfBindingSet {
+
+		final ExpressionLogic filterExpression;
+
+		final RdfBindingSet set;
+
+		FilterBindingSet(RdfBindingSet set, ExpressionLogic filterExpression) {
+			this.set = set;
+			this.filterExpression = filterExpression;
+		}
+
+		public Iterator iterator() {
+			return new FilterIterator();
+		}
+
+		public List getVariables() {
+			return this.set.getVariables();
+		}
+
+		public String describeSet() {
+			return "FILTER SET BY " + filterExpression;
+		}
+
+		private class FilterIterator implements Iterator {
+
+			private final Iterator iterator = FilterBindingSet.this.set.iterator();
+
+			private RdfBindingRow nextRow = null;
+
+			private FilterIterator() {
+				this.nextRow = getNextRow();
+			}
+
+			public void remove() {
+				throw new UnsupportedOperationException();
+			}
+
+			public boolean hasNext() {
+				return this.nextRow != null;
+			}
+
+			public Object next() {
+				RdfBindingRow currentRow = this.nextRow;
+				this.nextRow = getNextRow();
+				return currentRow;
+			}
+
+			private RdfBindingRow getNextRow() {
+				while (this.iterator.hasNext()) {
+					RdfBindingRow potential = (RdfBindingRow) this.iterator.next();
+					try {
+						Value rawEvaluate = FilterBindingSet.this.filterExpression.evaluate(potential);
+						if (StreamedFilterConstraintLogic.this.converter
+								.convertBoolean(StreamedFilterConstraintLogic.this.boolLogic.forceBoolean(rawEvaluate))) {
+							return potential;
+						}
+					} catch (TypeError e) {
+						// Ignore and don't return
+					}
+				}
+				return null;
+			}
+
+		}
+
+		public void accept(StreamedBindingSetVisitor setVisitor) {
+			setVisitor.visit(this);
+		}
+		public Collection getDependencies() {
+			return Arrays.asList(new RdfBindingSet[] { this.set });
+		}
+
+
+	}
+
+	/**
+	 * Currently does nothing, as I'm not even sure what this method is used for
+	 * and the filter constraint doesn't really change the variable bindings at
+	 * all.
+	 * 
+	 * @return an empty list always
+	 */
+	public Collection getVariables() {
+		return new LinkedList();
+	}
+
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/streamed/StreamedGraphConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/streamed/StreamedGraphConstraintLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/streamed/StreamedGraphConstraintLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/streamed/StreamedGraphConstraintLogic.java	2007-02-21 07:42:47.000000000 -0500
@@ -10,6 +10,7 @@
 import java.util.Collection;
 import java.util.Iterator;
 import java.util.List;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingRow;
 import name.levering.ryan.sparql.common.RdfBindingSet;
@@ -85,21 +86,21 @@
      * @return a binding set of values bound in the named graphs, potentially
      *         with a bound graph variable
      */
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source,
-            Collection defaultDatasets, Collection namedDatasets) {
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
 
         RdfBindingSet fullSet = new RdfBindingSetImpl();
-        if (bindings != null && bindings.iterator().hasNext()) {
-            for (Iterator i = bindings.iterator(); i.hasNext();) {
+        if (p.bindings != null && p.bindings.iterator().hasNext()) {
+            for (Iterator i = p.bindings.iterator(); i.hasNext();) {
                 RdfBindingRow row = (RdfBindingRow) i.next();
                 Object evaluation = this.data.getGraph().evaluate(row);
                 // If this evaluates to an un-bound variable, assume we want to
                 // apply the group to any named dataset
                 if (evaluation instanceof Variable) {
-                    if (namedDatasets.isEmpty()) {
+                    if (p.namedDatasets.isEmpty()) {
                         // Here we want to use any named dataset in the data
-                        RdfBindingSet namedResults = this.data.getConstraint().constrain(
-                                bindings, source, null, namedDatasets);
+								 ConstraintLogic.CallParams p2 = p.clone();
+								 p2.defaultDatasets = null;
+                        RdfBindingSet namedResults = this.data.getConstraint().constrain(p2);
 
                         RdfBindingSet sourcedSet = changeSource(
                                 (Variable) evaluation, namedResults);
@@ -107,12 +108,13 @@
                         fullSet = this.unionLogic.union(fullSet, sourcedSet);
                     } else {
                         // If there are named datasets, only use those
-                        for (Iterator j = namedDatasets.iterator(); j.hasNext();) {
+                        for (Iterator j = p.namedDatasets.iterator(); j.hasNext();) {
                             URI namedSet = (URI) j.next();
-                            Collection datasets = Arrays.asList(new Object[] { namedSet });
 
-                            RdfBindingSet namedResults = this.data.getConstraint().constrain(
-                                    bindings, source, datasets, namedDatasets);
+									  ConstraintLogic.CallParams p2 = p.clone();
+									  p2.defaultDatasets = Arrays.asList(new Object[] { namedSet });
+									  
+                            RdfBindingSet namedResults = this.data.getConstraint().constrain(p2);
 
                             RdfBindingSet sourcedSet = addSource(
                                     (Variable) evaluation, namedSet,
@@ -122,25 +124,27 @@
                         }
                     }
                 } else if (this.data.getGraph() instanceof Variable) {
-                    Collection datasets = Arrays.asList(new Object[] { evaluation });
-                    RdfBindingSet namedResults = this.data.getConstraint().constrain(
-                            bindings, source, datasets, namedDatasets);
+						   ConstraintLogic.CallParams p2 = p.clone();
+						   p2.defaultDatasets = Arrays.asList(new Object[] { evaluation });
+                    RdfBindingSet namedResults = this.data.getConstraint().constrain(p2);
                     fullSet = this.unionLogic.union(fullSet, addSource(
                             (Variable) this.data.getGraph(), (URI) evaluation,
                             namedResults));
                 } else {
-                    Collection datasets = Arrays.asList(new Object[] { evaluation });
+						   ConstraintLogic.CallParams p2 = p.clone();
+						   p2.defaultDatasets = Arrays.asList(new Object[] { evaluation });
                     fullSet = this.unionLogic.union(fullSet,
-                            this.data.getConstraint().constrain(bindings,
-                                    source, datasets, namedDatasets));
+                            this.data.getConstraint().constrain(p2));
                 }
             }
         } else {
             if (this.data.getGraph() instanceof Variable) {
-                if (namedDatasets.isEmpty()) {
+                if (p.namedDatasets.isEmpty()) {
                     // Here we want to use any named dataset in the data
-                    RdfBindingSet namedResults = this.data.getConstraint().constrain(
-                            bindings, source, null, namedDatasets);
+							ConstraintLogic.CallParams p2 = p.clone();
+							p2.defaultDatasets = null;
+
+							RdfBindingSet namedResults = this.data.getConstraint().constrain(p2);
 
                     RdfBindingSet sourcedSet = changeSource(
                             (Variable) this.data.getGraph(), namedResults);
@@ -148,12 +152,13 @@
                     fullSet = this.unionLogic.union(fullSet, sourcedSet);
                 } else {
                     // If there are named datasets, only use those
-                    for (Iterator j = namedDatasets.iterator(); j.hasNext();) {
+                    for (Iterator j = p.namedDatasets.iterator(); j.hasNext();) {
                         URI namedSet = (URI) j.next();
-                        Collection datasets = Arrays.asList(new Object[] { namedSet });
+							
+								 ConstraintLogic.CallParams p2 = p.clone();
+								 p2.defaultDatasets = Arrays.asList(new Object[] { namedSet });
 
-                        RdfBindingSet namedResults = this.data.getConstraint().constrain(
-                                bindings, source, datasets, namedDatasets);
+                        RdfBindingSet namedResults = this.data.getConstraint().constrain(p2);
 
                         RdfBindingSet sourcedSet = addSource(
                                 (Variable) this.data.getGraph(), namedSet,
@@ -163,10 +168,10 @@
                     }
                 }
             } else {
-                Collection datasets = Arrays.asList(new Object[] { this.data.getGraph() });
+					  ConstraintLogic.CallParams p2 = p.clone();
+					  p2.defaultDatasets = Arrays.asList(new Object[] { this.data.getGraph() });
                 fullSet = this.unionLogic.union(fullSet,
-                        this.data.getConstraint().constrain(bindings, source,
-                                datasets, namedDatasets));
+                        this.data.getConstraint().constrain(p2));
             }
         }
         return fullSet;
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/streamed/StreamedGraphConstraintLogic.java~ work-copy/src/main/name/levering/ryan/sparql/logic/streamed/StreamedGraphConstraintLogic.java~
--- upstream/src/main/name/levering/ryan/sparql/logic/streamed/StreamedGraphConstraintLogic.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/streamed/StreamedGraphConstraintLogic.java~	2007-02-21 07:38:56.000000000 -0500
@@ -0,0 +1,381 @@
+/*
+ * SPARQL Engine
+ * Copyright (C) 2005 Ryan Levering, All rights reserved.
+ * See LICENSE for full license information
+ */
+package name.levering.ryan.sparql.logic.streamed;
+
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+
+import name.levering.ryan.sparql.common.RdfBindingRow;
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.common.Variable;
+import name.levering.ryan.sparql.common.impl.AbstractRdfBindingRow;
+import name.levering.ryan.sparql.common.impl.AbstractRdfBindingSet;
+import name.levering.ryan.sparql.common.impl.RdfBindingSetImpl;
+import name.levering.ryan.sparql.common.impl.VariableImpl;
+import name.levering.ryan.sparql.model.data.GraphConstraintData;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
+import name.levering.ryan.sparql.model.logic.helper.SetUnionLogic;
+
+import org.openrdf.model.URI;
+import org.openrdf.model.Value;
+
+/**
+ * This constraint is responsible for the unique named graph binding that SPARQL
+ * brings to RDF querying. This constraint is interesting in that logically it
+ * does several things. It can be used to query a particular graph by specifying
+ * an URI as the graph or can specify a large number of graphs by evaluating
+ * IRIs that have been bound as variables. Or the variable can be unbound, in
+ * which case the constraints are applied to all the named graphs in the query.
+ * 
+ * @author Ryan Levering
+ * @version 1.0
+ */
+public class StreamedGraphConstraintLogic implements ConstraintLogic {
+
+    /**
+     * This dummy variable is used to bind in inner triples and then be matched
+     * in this constraint.
+     */
+    public static final Variable CONTEXT_VARIABLE = new VariableImpl(
+            StreamedGraphConstraintLogic.class.getName());
+
+    /**
+     * The data that holds the group constraint and the URI/variable list of
+     * named graphs.
+     */
+    private final GraphConstraintData data;
+
+    /**
+     * The logic to combine multiple result bindings from several different
+     * sources.
+     */
+    private final SetUnionLogic unionLogic;
+
+    /**
+     * Creates a new default graph constraint logic that applies a subgroup of
+     * constraints to named graphs according to the specification logic.
+     * 
+     * @param data the data holding the constraints and graph names
+     */
+    public StreamedGraphConstraintLogic(GraphConstraintData data,
+            SetUnionLogic unionLogic) {
+        this.data = data;
+        this.unionLogic = unionLogic;
+    }
+
+    /**
+     * Does the constraining of the binding set, by returning a binding set of
+     * variables bound in the named graphs by the subconstraints. It is expected
+     * to be intersected with the previous constraints in the containing group
+     * constraint.
+     * 
+     * @param bindings the current bindings, not used in this constraint
+     * @param source the source, passed on to the group constraint
+     * @param defaultDatasets the datasets to use in the query, not used in this
+     *            constraint
+     * @param namedDatasets the named datasets, used in case the graph variable
+     *            is not bound
+     * @return a binding set of values bound in the named graphs, potentially
+     *         with a bound graph variable
+     */
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+
+        RdfBindingSet fullSet = new RdfBindingSetImpl();
+        if (p.bindings != null && p.bindings.iterator().hasNext()) {
+            for (Iterator i = p.bindings.iterator(); i.hasNext();) {
+                RdfBindingRow row = (RdfBindingRow) i.next();
+                Object evaluation = this.data.getGraph().evaluate(row);
+                // If this evaluates to an un-bound variable, assume we want to
+                // apply the group to any named dataset
+                if (evaluation instanceof Variable) {
+                    if (namedDatasets.isEmpty()) {
+                        // Here we want to use any named dataset in the data
+								 ConstraintLogic.CallParams p2 = p.clone();
+								 p2.defaultDatasets = null;
+                        RdfBindingSet namedResults = this.data.getConstraint().constrain(p2);
+
+                        RdfBindingSet sourcedSet = changeSource(
+                                (Variable) evaluation, namedResults);
+
+                        fullSet = this.unionLogic.union(fullSet, sourcedSet);
+                    } else {
+                        // If there are named datasets, only use those
+                        for (Iterator j = namedDatasets.iterator(); j.hasNext();) {
+                            URI namedSet = (URI) j.next();
+
+									  ConstraintLogic.CallParams p2 = p.clone();
+									  p2.defaultDatasets = Arrays.asList(new Object[] { namedSet });
+									  
+                            RdfBindingSet namedResults = this.data.getConstraint().constrain(p2);
+
+                            RdfBindingSet sourcedSet = addSource(
+                                    (Variable) evaluation, namedSet,
+                                    namedResults);
+
+                            fullSet = this.unionLogic.union(fullSet, sourcedSet);
+                        }
+                    }
+                } else if (this.data.getGraph() instanceof Variable) {
+						   ConstraintLogic.CallParams p2 = p.clone();
+						   p2.defaultDatasets = Arrays.asList(new Object[] { evaluation });
+                    RdfBindingSet namedResults = this.data.getConstraint().constrain(p2);
+                    fullSet = this.unionLogic.union(fullSet, addSource(
+                            (Variable) this.data.getGraph(), (URI) evaluation,
+                            namedResults));
+                } else {
+						   ConstraintLogic.CallParams p2 = p.clone();
+						   p2.defaultDatasets = Arrays.asList(new Object[] { evaluation });
+                    fullSet = this.unionLogic.union(fullSet,
+                            this.data.getConstraint().constrain(p2));
+                }
+            }
+        } else {
+            if (this.data.getGraph() instanceof Variable) {
+                if (namedDatasets.isEmpty()) {
+                    // Here we want to use any named dataset in the data
+							ConstraintLogic.CallParams p2 = p.clone();
+							p2.defaultDatasets = null;
+
+							RdfBindingSet namedResults = this.data.getConstraint().constrain(p2);
+
+                    RdfBindingSet sourcedSet = changeSource(
+                            (Variable) this.data.getGraph(), namedResults);
+
+                    fullSet = this.unionLogic.union(fullSet, sourcedSet);
+                } else {
+                    // If there are named datasets, only use those
+                    for (Iterator j = namedDatasets.iterator(); j.hasNext();) {
+                        URI namedSet = (URI) j.next();
+							
+								 ConstraintLogic.CallParams p2 = p.clone();
+								 p2.defaultDatasets = Arrays.asList(new Object[] { namedSet });
+
+                        RdfBindingSet namedResults = this.data.getConstraint().constrain(p2);
+
+                        RdfBindingSet sourcedSet = addSource(
+                                (Variable) this.data.getGraph(), namedSet,
+                                namedResults);
+
+                        fullSet = this.unionLogic.union(fullSet, sourcedSet);
+                    }
+                }
+            } else {
+					  ConstraintLogic.CallParams p2 = p.clone();
+					  p2.defaultDatasets = Arrays.asList(new Object[] { this.data.getGraph() });
+                fullSet = this.unionLogic.union(fullSet,
+                        this.data.getConstraint().constrain(p2));
+            }
+        }
+        return fullSet;
+    }
+
+    /**
+     * Adds the source column to a value binding set, when variables are
+     * specified in the graph name list. This helper method refactors out some
+     * logic from the constraint method.
+     * 
+     * @param variable the variable to bind the source to
+     * @param source the source that will be the value in the column for the
+     *            rows
+     * @param set the set to add the source column to
+     * @return a set with the source value added to each row under a variable
+     *         header
+     */
+    private RdfBindingSet addSource(Variable variable, URI source,
+            RdfBindingSet set) {
+        return new VariableAddSourceSet(set, variable, source);
+    }
+
+    /**
+     * Changes the source column to have the appropriate variable name as
+     * defined in a GRAPH ?var query.
+     * 
+     * @param variable the variable that will be the new header
+     * @param set the set to modify the column in
+     */
+    private RdfBindingSet changeSource(Variable variable, RdfBindingSet set) {
+        return new VariableNameChangeSet(set, variable);
+    }
+    
+    private class VariableNameChangeSet extends AbstractRdfBindingSet implements StackedRdfBindingSet {
+
+        final RdfBindingSet set;
+
+        final Variable newVar;
+
+        VariableNameChangeSet(RdfBindingSet set, Variable newVar) {
+            this.set = set;
+            this.newVar = newVar;
+        }
+
+        public Iterator iterator() {
+            return new VariableNameChangeIterator();
+        }
+
+        public List getVariables() {
+            List setVars = new ArrayList(this.set.getVariables());
+            setVars.remove(CONTEXT_VARIABLE);
+            setVars.add(this.newVar);
+            return setVars;
+        }
+
+        private class VariableNameChangeIterator implements Iterator {
+
+            private Iterator setIterator = VariableNameChangeSet.this.set.iterator();
+
+            public void remove() {
+                this.setIterator.remove();
+            }
+
+            public boolean hasNext() {
+                return this.setIterator.hasNext();
+            }
+
+            public Object next() {
+                return new VariableNameChangeRow(
+                        (RdfBindingRow) this.setIterator.next());
+            }
+
+            private class VariableNameChangeRow extends AbstractRdfBindingRow {
+
+                private RdfBindingRow row;
+
+                VariableNameChangeRow(RdfBindingRow row) {
+                    super(VariableNameChangeSet.this);
+                    this.row = row;
+                }
+
+                public Value getValue(Variable variable) {
+                    if (variable.equals(VariableNameChangeSet.this.newVar)) {
+                        return this.row.getValue(CONTEXT_VARIABLE);
+                    } else {
+                        return this.row.getValue(variable);
+                    }
+                }
+
+                public List getVariables() {
+                    return VariableNameChangeSet.this.getVariables();
+                }
+            }
+        }
+
+        public String describeSet() {
+            return "SET GRAPH VARIABLE";
+        }
+
+		public void setSource(RdfSource source) {
+			if (this.set instanceof SourcedRdfBindingSet) {
+				((SourcedRdfBindingSet) this.set).setSource(source);
+			}
+		}
+
+		public void accept(StreamedBindingSetVisitor setVisitor) {
+			setVisitor.visit(this);
+		}
+		public Collection getDependencies() {
+			return Arrays.asList(new RdfBindingSet[] { this.set });
+		}
+
+    }
+
+    private class VariableAddSourceSet extends AbstractRdfBindingSet implements StackedRdfBindingSet {
+
+        RdfBindingSet set;
+
+        Variable newVar;
+
+        URI source;
+
+        VariableAddSourceSet(RdfBindingSet set, Variable newVar, URI source) {
+            this.set = set;
+            this.newVar = newVar;
+            this.source = source;
+        }
+
+        public Iterator iterator() {
+            return new VariableAddSourceIterator();
+        }
+
+        public List getVariables() {
+            List setVars = new ArrayList(this.set.getVariables());
+            setVars.add(this.newVar);
+            return setVars;
+        }
+
+        private class VariableAddSourceIterator implements Iterator {
+
+            private Iterator setIterator = VariableAddSourceSet.this.set.iterator();
+
+            public void remove() {
+                this.setIterator.remove();
+            }
+
+            public boolean hasNext() {
+                return this.setIterator.hasNext();
+            }
+
+            public Object next() {
+                return new VariableAddSourceRow(
+                        (RdfBindingRow) this.setIterator.next());
+            }
+
+            private class VariableAddSourceRow extends AbstractRdfBindingRow {
+
+                private RdfBindingRow row;
+
+                VariableAddSourceRow(RdfBindingRow row) {
+                    super(VariableAddSourceSet.this);
+                    this.row = row;
+                }
+
+                public Value getValue(Variable variable) {
+                    if (variable.equals(VariableAddSourceSet.this.newVar)) {
+                        return VariableAddSourceSet.this.source;
+                    } else {
+                        return this.row.getValue(variable);
+                    }
+                }
+
+                public List getVariables() {
+                    return VariableAddSourceSet.this.getVariables();
+                }
+            }
+        }
+
+        public String describeSet() {
+            return "ADD STATEMENT SOURCE";
+        }
+
+		public void accept(StreamedBindingSetVisitor setVisitor) {
+			setVisitor.visit(this);
+		}
+		public Collection getDependencies() {
+			return Arrays.asList(new RdfBindingSet[] { this.set });
+		}
+
+    }
+
+    /**
+     * Gets the variables that are found in the subconstraints and the graph
+     * names.
+     * 
+     * @return a collection of all named variables in the graph constraint
+     */
+    public Collection getVariables() {
+        Collection variables = new ArrayList(
+                this.data.getConstraint().getVariables());
+        if (this.data.getGraph() instanceof Variable) {
+            variables.add(this.data.getGraph());
+        }
+        return variables;
+    }
+
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/streamed/StreamedSetProjectionLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/streamed/StreamedSetProjectionLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/streamed/StreamedSetProjectionLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/streamed/StreamedSetProjectionLogic.java	2007-02-09 07:54:16.000000000 -0500
@@ -130,8 +130,10 @@
 			}
 
 			public Value getValue(Variable variable) {
-				return ((ExpressionLogic) RdfBindingProjection.this.variableExpressions.get(variable))
-						.evaluate(this.row);
+				ExpressionLogic expr = (ExpressionLogic) RdfBindingProjection.this.variableExpressions.get(variable);
+				if (expr == null)
+					throw new IllegalArgumentException("Variable " + variable + " is not bound in this row.");
+				return expr.evaluate(this.row);
 			}
 
 			public List getVariables() {
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/streamed/StreamedTripleConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/streamed/StreamedTripleConstraintLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/streamed/StreamedTripleConstraintLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/streamed/StreamedTripleConstraintLogic.java	2007-02-21 07:42:10.000000000 -0500
@@ -10,11 +10,14 @@
 import java.util.Iterator;
 import java.util.List;
 import java.util.NoSuchElementException;
+import java.util.Map;
+import java.util.Set;
 
 import name.levering.ryan.sparql.common.GraphStatement;
 import name.levering.ryan.sparql.common.RdfBindingRow;
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.common.AdvancedRdfSource;
 import name.levering.ryan.sparql.common.Variable;
 import name.levering.ryan.sparql.common.impl.AbstractRdfBindingRow;
 import name.levering.ryan.sparql.common.impl.AbstractRdfBindingSet;
@@ -63,8 +66,7 @@
 	 * @param namedDatasets the named datasets to use in graph constraints, not
 	 *            used in this constraint
 	 */
-	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
 
 		ExpressionLogic subExpr = this.data.getSubjectExpression();
 		ExpressionLogic predExpr = this.data.getPredicateExpression();
@@ -75,12 +77,12 @@
 		Value subject = null;
 		if (subExpr instanceof Variable) {
 			variables.add(subExpr);
-			flags[0] = 1;
+			flags[0] = variables.size();
 			if (subExpr.equals(predExpr)) {
-				flags[1] = 1;
+				flags[1] = flags[0];
 			}
 			if (subExpr.equals(objExpr)) {
-				flags[2] = 1;
+				flags[2] = flags[0];
 			}
 		} else {
 			subject = (Value) subExpr;
@@ -89,10 +91,10 @@
 		URI verb = null;
 		if (predExpr instanceof Variable && flags[1] == 0) {
 			variables.add(predExpr);
-			flags[1] = 2;
+			flags[1] = variables.size();
 			if (predExpr.equals(objExpr)) {
-				flags[2] = 2;
-			}
+				flags[2] = flags[2];
+			}                               
 		} else {
 			verb = (URI) predExpr;
 		}
@@ -100,46 +102,57 @@
 		Value object = null;
 		if (objExpr instanceof Variable && flags[2] == 0) {
 			variables.add(objExpr);
-			flags[2] = 3;
+			flags[2] = variables.size();
 		} else if (flags[2] == 0) {
 			object = (Value) objExpr;
 		}
+		
+		TripleQueryOptions query = new TripleQueryOptions();
+		query.source = p.source;
+		query.variables = variables;
+		query.flags = flags;
+		query.knownValues = p.knownValues;
+		query.knownFilters = p.knownFilters;
+
+		if (p.defaultDatasets == null) {
+			query.includeSource = true;
 
-		if (defaultDatasets == null) {
 			// This adds an extra column to the returned set for the GRAPH
 			// constraint to process
-			if (source != null) {
-				StatementBindingSet bindingSet = new StatementBindingSet(source, variables, flags, true);
+			if (p.source != null) {
+				StatementBindingSet bindingSet = new StatementBindingSet(query);
 				bindingSet.addIterator(new StatementImpl(subject, verb, object));
 				return bindingSet;
 			} else {
-				StreamedTripleBindingSet bindingSet = new StreamedTripleBindingSet(variables, flags, true);
+				StreamedTripleBindingSet bindingSet = new StreamedTripleBindingSet(query);
 				bindingSet.addIterator(new StatementImpl(subject, verb, object));
 				return bindingSet;
 			}
 		} else {
-			if (source != null) {
-				StatementBindingSet bindingSet = new StatementBindingSet(source, variables, flags, false);
-				if (defaultDatasets.isEmpty()) {
+			query.includeSource = false;
+			
+			if (p.source != null) {
+				StatementBindingSet bindingSet = new StatementBindingSet(query);
+				if (p.defaultDatasets.isEmpty()) {
 					// This is if no FROM graphs are specified
 					bindingSet.addIterator(new StatementImpl(subject, verb, object));
 				} else {
 					// This is if FROM graphs are specified or FROM NAMED and
 					// we're in a GRAPH constraint
-					for (Iterator i = defaultDatasets.iterator(); i.hasNext();) {
+					for (Iterator i = p.defaultDatasets.iterator(); i.hasNext();) {
 						bindingSet.addIterator(new StatementImpl(subject, verb, object, (URI) i.next()));
 					}
 				}
 				return bindingSet;
 			} else {
-				StreamedTripleBindingSet bindingSet = new StreamedTripleBindingSet(variables, flags, false);
-				if (defaultDatasets.isEmpty()) {
+				StreamedTripleBindingSet bindingSet = new StreamedTripleBindingSet(query);
+				if (p.defaultDatasets.isEmpty()) {
 					// This is if no FROM graphs are specified
 					bindingSet.addIterator(new StatementImpl(subject, verb, object));
 				} else {
 					// This is if FROM graphs are specified or FROM NAMED and
 					// we're in a GRAPH constraint
-					for (Iterator i = defaultDatasets.iterator(); i.hasNext();) {
+					for (Iterator i = p.defaultDatasets.iterator(); i.hasNext();) {
 						bindingSet.addIterator(new StatementImpl(subject, verb, object, (URI) i.next()));
 					}
 				}
@@ -147,43 +160,67 @@
 			}
 		}
 	}
-
-	/**
-	 * This set is the lowest level binding set that wraps a request to an
-	 * RdfSource. It returns an iterator that uses the row iterators from the
-	 * RdfSource getStatement call to check if returned rows match the equality
-	 * criteria in the passed in flags.
-	 * 
-	 * @author Ryan Levering
-	 * @version 1.1
-	 */
-	private class StatementBindingSet extends AbstractRdfBindingSet {
-
+	
+	private class TripleQueryOptions implements Cloneable {
 		/**
 		 * The RDF source that's being queried.
 		 */
-		final RdfSource source;
+		RdfSource source;
 
 		/**
 		 * The variables that are being bound to values in the RDF source.
 		 */
-		final List variables;
+		List variables;
 
 		/**
 		 * Flags that allow a shortcut to checking for the equality of two
 		 * equivalent variables.
 		 */
-		final int[] flags;
+		int[] flags;
+		
+		/**
+		 * Whether or not to include the graph name in the returned bindings.
+		 */
+		boolean includeSource;
 
 		/**
-		 * The statements that are matched against the RDF source.
+		 * A mapping from variables to Lists of Values that the bindings
+		 * must be drawn from.  (Possibly null if not applicable.)
 		 */
-		final List statementIterators = new ArrayList();
+		Map knownValues;
 
 		/**
-		 * Whether or not to include the graph name in the returned bindings.
+		 * A mapping from variables to Lists of filters (objects) that the bindings
+		 * must satisfy.  (Possibly null if not applicable.)
 		 */
-		final boolean includeSource;
+		Map knownFilters;
+		
+		public TripleQueryOptions clone() {
+			try {
+				return (TripleQueryOptions)super.clone();
+			} catch (CloneNotSupportedException e) {
+				// lame
+				throw new RuntimeException(e);
+			}
+		}
+	}
+
+	/**
+	 * This set is the lowest level binding set that wraps a request to an
+	 * RdfSource. It returns an iterator that uses the row iterators from the
+	 * RdfSource getStatement call to check if returned rows match the equality
+	 * criteria in the passed in flags.
+	 * 
+	 * @author Ryan Levering
+	 * @version 1.1
+	 */
+	private class StatementBindingSet extends AbstractRdfBindingSet {
+		final TripleQueryOptions query;
+		
+		/**
+		 * The statements that are matched against the RDF source.
+		 */
+		final List statementIterators = new ArrayList();
 
 		/**
 		 * Creates a new binding set that queries a particular RdfSource,
@@ -195,11 +232,8 @@
 		 * @param flags indicates the presence of variable equivalency
 		 * @param includeSource whether to bind the graph name as well
 		 */
-		private StatementBindingSet(RdfSource source, List variables, int[] flags, boolean includeSource) {
-			this.source = source;
-			this.variables = variables;
-			this.flags = flags;
-			this.includeSource = includeSource;
+		private StatementBindingSet(TripleQueryOptions query) {
+			this.query = query;
 		}
 
 		void addIterator(GraphStatement statementIterator) {
@@ -211,8 +245,8 @@
 		}
 
 		public List getVariables() {
-			List extVariables = new ArrayList(this.variables);
-			if (this.includeSource) {
+			List extVariables = new ArrayList(this.query.variables);
+			if (this.query.includeSource) {
 				extVariables.add(StreamedGraphConstraintLogic.CONTEXT_VARIABLE);
 			}
 			return extVariables;
@@ -273,24 +307,70 @@
 				// We should only get here if there was never a chance
 				return null;
 			}
-
+			
 			private Iterator getStatements(GraphStatement statement) {
+				if (StatementBindingSet.this.query.source instanceof AdvancedRdfSource)
+					return getStatementsAdvanced(statement);
+				else
+					return getStatementsSimple(statement);
+			}
+			
+			private Iterator getStatementsSimple(GraphStatement statement) {
+				Value s = statement.getSubject();
+				URI p = statement.getPredicate();
+				Value o = statement.getObject();
+				
+				if (statement.getGraphName() == null) {
+					if (StatementBindingSet.this.query.includeSource) {
+						return StatementBindingSet.this.query.source.getStatements(s, p, o);
+					} else {
+						return StatementBindingSet.this.query.source.getDefaultStatements(s, p, o);
+					}
+				} else {
+					return StatementBindingSet.this.query.source.getStatements(s, p, o, statement.getGraphName());
+				}
+			}
+			
+			private Iterator getStatementsAdvanced(GraphStatement statement) {
+				AdvancedRdfSource source = (AdvancedRdfSource)StatementBindingSet.this.query.source;
+				
+				Value[] s = getValues(statement.getSubject(), 0);
+				Value[] p = getValues(statement.getPredicate(), 1);
+				Value[] o = getValues(statement.getObject(), 2);
+				Object[] litFilters = getFilters(statement.getObject());
+				
 				if (statement.getGraphName() == null) {
-					if (StatementBindingSet.this.includeSource) {
-						return StatementBindingSet.this.source.getStatements(statement.getSubject(), statement
-								.getPredicate(), statement.getObject());
+					if (StatementBindingSet.this.query.includeSource) {
+						return source.getStatements(s, p, o, litFilters);
 					} else {
-						return StatementBindingSet.this.source.getDefaultStatements(statement.getSubject(), statement
-								.getPredicate(), statement.getObject());
+						return source.getDefaultStatements(s, p, o, litFilters);
 					}
 				} else {
-					return StatementBindingSet.this.source.getStatements(statement.getSubject(), statement
-							.getPredicate(), statement.getObject(), statement.getGraphName());
+					return source.getStatements(s, p, o, new URI[] { statement.getGraphName() }, litFilters);
 				}
 			}
+			
+			private Value[] getValues(Value value, int index) {
+				if (value != null) return new Value[] { value };
+				if (StatementBindingSet.this.query.knownValues == null) return null;
+				int varIndex = StatementBindingSet.this.query.flags[index]-1;
+				Variable variable = (Variable)StatementBindingSet.this.query.variables.get(varIndex); 
+				Set values = (Set)StatementBindingSet.this.query.knownValues.get(variable);
+				if (values == null) return null;
+				return (Value[])values.toArray(new Value[0]);
+			}
+			private Object[] getFilters(Value value) {
+				if (value != null) return null;
+				if (StatementBindingSet.this.query.knownFilters == null) return null;
+				int varIndex = StatementBindingSet.this.query.flags[2]-1;
+				Variable variable = (Variable)StatementBindingSet.this.query.variables.get(varIndex);
+				List filters = (List)StatementBindingSet.this.query.knownFilters.get(variable);
+				if (filters == null) return null;
+				return filters.toArray();
+			}
 
 			private boolean checkStatement(GraphStatement statement) {
-				int[] localFlags = StatementBindingSet.this.flags;
+				int[] localFlags = StatementBindingSet.this.query.flags;
 
 				if (localFlags[0] != 0 && localFlags[0] == localFlags[2]) {
 					if (!statement.getSubject().equals(statement.getObject())) {
@@ -338,14 +418,14 @@
 
 				public Value getValue(Variable variable) {
 					// Special case for the source
-					if (StatementBindingSet.this.includeSource
+					if (StatementBindingSet.this.query.includeSource
 							&& variable.equals(StreamedGraphConstraintLogic.CONTEXT_VARIABLE)) {
 						return this.statement.getGraphName();
 					}
 					// First get the index
 					int index = getIndex(variable);
 
-					int[] localFlags = StatementBindingSet.this.flags;
+					int[] localFlags = StatementBindingSet.this.query.flags;
 					if (index == 2) {
 						// If the variable is in the last spot, it's got to be
 						// the object
@@ -375,7 +455,7 @@
 
 				private int getIndex(Variable variable) {
 					int index = 0;
-					for (Iterator vars = StatementBindingSet.this.variables.iterator(); vars.hasNext(); index++) {
+					for (Iterator vars = StatementBindingSet.this.query.variables.iterator(); vars.hasNext(); index++) {
 						Variable var = (Variable) vars.next();
 						if (variable.equals(var)) {
 							return index;
@@ -405,22 +485,18 @@
 
 	private class StreamedTripleBindingSet extends VirtualRdfBindingSet {
 
-		private final List variables;
-
-		private final int[] flags;
-
-		private final boolean includeSource;
-
+		private final TripleQueryOptions query;
+		
 		private final List statementIterators = new ArrayList();
 
-		public StreamedTripleBindingSet(List variables, int[] flags, boolean includeSource) {
-			this.variables = variables;
-			this.flags = flags;
-			this.includeSource = includeSource;
+		public StreamedTripleBindingSet(TripleQueryOptions query) {
+			this.query = query;
 		}
 
 		public void setSource(RdfSource source) {
-			StatementBindingSet set = new StatementBindingSet(source, this.variables, this.flags, this.includeSource);
+			TripleQueryOptions q = query.clone();
+			q.source = source;
+			StatementBindingSet set = new StatementBindingSet(q);
 			for (Iterator statementIt = statementIterators.iterator(); statementIt.hasNext();) {
 				set.addIterator((GraphStatement) statementIt.next());
 			}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/streamed/StreamedTripleConstraintLogic.java~ work-copy/src/main/name/levering/ryan/sparql/logic/streamed/StreamedTripleConstraintLogic.java~
--- upstream/src/main/name/levering/ryan/sparql/logic/streamed/StreamedTripleConstraintLogic.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/streamed/StreamedTripleConstraintLogic.java~	2007-02-21 07:39:49.000000000 -0500
@@ -0,0 +1,520 @@
+/*
+ * SPARQL Engine
+ * Copyright (C) 2005 Ryan Levering, All rights reserved.
+ * See LICENSE for full license information
+ */
+package name.levering.ryan.sparql.logic.streamed;
+
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Iterator;
+import java.util.List;
+import java.util.NoSuchElementException;
+import java.util.Map;
+import java.util.Set;
+
+import name.levering.ryan.sparql.common.GraphStatement;
+import name.levering.ryan.sparql.common.RdfBindingRow;
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.common.AdvancedRdfSource;
+import name.levering.ryan.sparql.common.Variable;
+import name.levering.ryan.sparql.common.impl.AbstractRdfBindingRow;
+import name.levering.ryan.sparql.common.impl.AbstractRdfBindingSet;
+import name.levering.ryan.sparql.common.impl.StatementImpl;
+import name.levering.ryan.sparql.model.data.TripleConstraintData;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
+import name.levering.ryan.sparql.model.logic.ExpressionLogic;
+
+import org.openrdf.model.URI;
+import org.openrdf.model.Value;
+
+/**
+ * This is the logic that handles most of the interaction with the end
+ * RdfSource. Most other constraints pass the source down to triple constraints,
+ * which provide the core bound values to manipulate. This is responsible for
+ * querying the defaultDatasets for statements with wildcard placeholders.
+ * 
+ * @author Ryan Levering
+ * @version 1.1
+ */
+public class StreamedTripleConstraintLogic implements ConstraintLogic {
+
+	/**
+	 * The data containing the possible subject, predicate, and object to find.
+	 */
+	final TripleConstraintData data;
+
+	/**
+	 * Creates a new triple constraint logic that constrains a database to match
+	 * particular statement criteria.
+	 * 
+	 * @param data the data holding the statement data to match
+	 */
+	public StreamedTripleConstraintLogic(TripleConstraintData data) {
+		this.data = data;
+	}
+
+	/**
+	 * Returns a binding set of bound values matching a particular subject,
+	 * predicate, and object where one or more of them is a wildcard.
+	 * 
+	 * @param bindings the current bindings, not used in this constraint
+	 * @param source the source to query for the statement constraints
+	 * @param defaultDatasets the datasets to query, if non-default graphs are
+	 *            being used
+	 * @param namedDatasets the named datasets to use in graph constraints, not
+	 *            used in this constraint
+	 */
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+
+		ExpressionLogic subExpr = this.data.getSubjectExpression();
+		ExpressionLogic predExpr = this.data.getPredicateExpression();
+		ExpressionLogic objExpr = this.data.getObjectExpression();
+
+		int[] flags = new int[3];
+		List variables = new ArrayList();
+		Value subject = null;
+		if (subExpr instanceof Variable) {
+			variables.add(subExpr);
+			flags[0] = variables.size();
+			if (subExpr.equals(predExpr)) {
+				flags[1] = flags[0];
+			}
+			if (subExpr.equals(objExpr)) {
+				flags[2] = flags[0];
+			}
+		} else {
+			subject = (Value) subExpr;
+		}
+
+		URI verb = null;
+		if (predExpr instanceof Variable && flags[1] == 0) {
+			variables.add(predExpr);
+			flags[1] = variables.size();
+			if (predExpr.equals(objExpr)) {
+				flags[2] = flags[2];
+			}                               
+		} else {
+			verb = (URI) predExpr;
+		}
+
+		Value object = null;
+		if (objExpr instanceof Variable && flags[2] == 0) {
+			variables.add(objExpr);
+			flags[2] = variables.size();
+		} else if (flags[2] == 0) {
+			object = (Value) objExpr;
+		}
+		
+		TripleQueryOptions query = new TripleQueryOptions();
+		query.source = source;
+		query.variables = variables;
+		query.flags = flags;
+		query.knownValues = knownValues;
+		query.knownFilters = knownFilters;
+
+		if (p.defaultDatasets == null) {
+			query.includeSource = true;
+
+			// This adds an extra column to the returned set for the GRAPH
+			// constraint to process
+			if (source != null) {
+				StatementBindingSet bindingSet = new StatementBindingSet(query);
+				bindingSet.addIterator(new StatementImpl(subject, verb, object));
+				return bindingSet;
+			} else {
+				StreamedTripleBindingSet bindingSet = new StreamedTripleBindingSet(query);
+				bindingSet.addIterator(new StatementImpl(subject, verb, object));
+				return bindingSet;
+			}
+		} else {
+			query.includeSource = false;
+			
+			if (p.source != null) {
+				StatementBindingSet bindingSet = new StatementBindingSet(query);
+				if (p.defaultDatasets.isEmpty()) {
+					// This is if no FROM graphs are specified
+					bindingSet.addIterator(new StatementImpl(subject, verb, object));
+				} else {
+					// This is if FROM graphs are specified or FROM NAMED and
+					// we're in a GRAPH constraint
+					for (Iterator i = p.defaultDatasets.iterator(); i.hasNext();) {
+						bindingSet.addIterator(new StatementImpl(subject, verb, object, (URI) i.next()));
+					}
+				}
+				return bindingSet;
+			} else {
+				StreamedTripleBindingSet bindingSet = new StreamedTripleBindingSet(query);
+				if (p.defaultDatasets.isEmpty()) {
+					// This is if no FROM graphs are specified
+					bindingSet.addIterator(new StatementImpl(subject, verb, object));
+				} else {
+					// This is if FROM graphs are specified or FROM NAMED and
+					// we're in a GRAPH constraint
+					for (Iterator i = p.defaultDatasets.iterator(); i.hasNext();) {
+						bindingSet.addIterator(new StatementImpl(subject, verb, object, (URI) i.next()));
+					}
+				}
+				return bindingSet;
+			}
+		}
+	}
+	
+	private class TripleQueryOptions implements Cloneable {
+		/**
+		 * The RDF source that's being queried.
+		 */
+		RdfSource source;
+
+		/**
+		 * The variables that are being bound to values in the RDF source.
+		 */
+		List variables;
+
+		/**
+		 * Flags that allow a shortcut to checking for the equality of two
+		 * equivalent variables.
+		 */
+		int[] flags;
+		
+		/**
+		 * Whether or not to include the graph name in the returned bindings.
+		 */
+		boolean includeSource;
+
+		/**
+		 * A mapping from variables to Lists of Values that the bindings
+		 * must be drawn from.  (Possibly null if not applicable.)
+		 */
+		Map knownValues;
+
+		/**
+		 * A mapping from variables to Lists of filters (objects) that the bindings
+		 * must satisfy.  (Possibly null if not applicable.)
+		 */
+		Map knownFilters;
+		
+		public TripleQueryOptions clone() {
+			try {
+				return (TripleQueryOptions)super.clone();
+			} catch (CloneNotSupportedException e) {
+				// lame
+				throw new RuntimeException(e);
+			}
+		}
+	}
+
+	/**
+	 * This set is the lowest level binding set that wraps a request to an
+	 * RdfSource. It returns an iterator that uses the row iterators from the
+	 * RdfSource getStatement call to check if returned rows match the equality
+	 * criteria in the passed in flags.
+	 * 
+	 * @author Ryan Levering
+	 * @version 1.1
+	 */
+	private class StatementBindingSet extends AbstractRdfBindingSet {
+		final TripleQueryOptions query;
+		
+		/**
+		 * The statements that are matched against the RDF source.
+		 */
+		final List statementIterators = new ArrayList();
+
+		/**
+		 * Creates a new binding set that queries a particular RdfSource,
+		 * binding particular variables using shortcut flags and potentially
+		 * including the source graph name in the output bound variables.
+		 * 
+		 * @param source the source to get the data from
+		 * @param variables the variables being bound in the binding set
+		 * @param flags indicates the presence of variable equivalency
+		 * @param includeSource whether to bind the graph name as well
+		 */
+		private StatementBindingSet(TripleQueryOptions query) {
+			this.query = query;
+		}
+
+		void addIterator(GraphStatement statementIterator) {
+			this.statementIterators.add(statementIterator);
+		}
+
+		public Iterator iterator() {
+			return new BoundStatementIterator();
+		}
+
+		public List getVariables() {
+			List extVariables = new ArrayList(this.query.variables);
+			if (this.query.includeSource) {
+				extVariables.add(StreamedGraphConstraintLogic.CONTEXT_VARIABLE);
+			}
+			return extVariables;
+		}
+
+		private class BoundStatementIterator implements Iterator {
+
+			private final Iterator itIterator = StatementBindingSet.this.statementIterators.iterator();
+
+			private Iterator statementIterator = null;
+
+			private GraphStatement nextStatement = null;
+
+			private BoundStatementIterator() {
+				if (this.itIterator.hasNext()) {
+					this.statementIterator = getStatements((GraphStatement) this.itIterator.next());
+				}
+
+				this.nextStatement = nextStatement();
+			}
+
+			private GraphStatement nextStatement() {
+				while (this.statementIterator != null) {
+
+					// Only come out of this loop if statementIterator is null
+					// (doomed)
+					// or we have a good statementIterator
+					while (this.statementIterator != null && !this.statementIterator.hasNext()) {
+						if (this.itIterator.hasNext()) {
+							this.statementIterator = getStatements((GraphStatement) this.itIterator.next());
+						} else {
+							// This is one end condition, there are no more
+							// iterators
+							this.statementIterator = null;
+							return null;
+						}
+					}
+
+					if (this.statementIterator != null) {
+						// We've found a statement iterator that has elements
+						GraphStatement statement = (GraphStatement) this.statementIterator.next();
+						while (statement != null && !this.checkStatement(statement)) {
+							if (this.statementIterator.hasNext()) {
+								statement = (GraphStatement) this.statementIterator.next();
+							} else {
+								// We ran out of statements here, go back for
+								// another iterator
+								statement = null;
+							}
+						}
+						if (statement != null) {
+							// This is another end condition, we found a match
+							return statement;
+						}
+					}
+				}
+
+				// We should only get here if there was never a chance
+				return null;
+			}
+			
+			private Iterator getStatements(GraphStatement statement) {
+				if (StatementBindingSet.this.query.source instanceof AdvancedRdfSource)
+					return getStatementsAdvanced(statement);
+				else
+					return getStatementsSimple(statement);
+			}
+			
+			private Iterator getStatementsSimple(GraphStatement statement) {
+				Value s = statement.getSubject();
+				URI p = statement.getPredicate();
+				Value o = statement.getObject();
+				
+				if (statement.getGraphName() == null) {
+					if (StatementBindingSet.this.query.includeSource) {
+						return StatementBindingSet.this.query.source.getStatements(s, p, o);
+					} else {
+						return StatementBindingSet.this.query.source.getDefaultStatements(s, p, o);
+					}
+				} else {
+					return StatementBindingSet.this.query.source.getStatements(s, p, o, statement.getGraphName());
+				}
+			}
+			
+			private Iterator getStatementsAdvanced(GraphStatement statement) {
+				AdvancedRdfSource source = (AdvancedRdfSource)StatementBindingSet.this.query.source;
+				
+				Value[] s = getValues(statement.getSubject(), 0);
+				Value[] p = getValues(statement.getPredicate(), 1);
+				Value[] o = getValues(statement.getObject(), 2);
+				Object[] litFilters = getFilters(statement.getObject());
+				
+				if (statement.getGraphName() == null) {
+					if (StatementBindingSet.this.query.includeSource) {
+						return source.getStatements(s, p, o, litFilters);
+					} else {
+						return source.getDefaultStatements(s, p, o, litFilters);
+					}
+				} else {
+					return source.getStatements(s, p, o, new URI[] { statement.getGraphName() }, litFilters);
+				}
+			}
+			
+			private Value[] getValues(Value value, int index) {
+				if (value != null) return new Value[] { value };
+				if (StatementBindingSet.this.query.knownValues == null) return null;
+				int varIndex = StatementBindingSet.this.query.flags[index]-1;
+				Variable variable = (Variable)StatementBindingSet.this.query.variables.get(varIndex); 
+				Set values = (Set)StatementBindingSet.this.query.knownValues.get(variable);
+				if (values == null) return null;
+				return (Value[])values.toArray(new Value[0]);
+			}
+			private Object[] getFilters(Value value) {
+				if (value != null) return null;
+				if (StatementBindingSet.this.query.knownFilters == null) return null;
+				int varIndex = StatementBindingSet.this.query.flags[2]-1;
+				Variable variable = (Variable)StatementBindingSet.this.query.variables.get(varIndex);
+				List filters = (List)StatementBindingSet.this.query.knownFilters.get(variable);
+				if (filters == null) return null;
+				return filters.toArray();
+			}
+
+			private boolean checkStatement(GraphStatement statement) {
+				int[] localFlags = StatementBindingSet.this.query.flags;
+
+				if (localFlags[0] != 0 && localFlags[0] == localFlags[2]) {
+					if (!statement.getSubject().equals(statement.getObject())) {
+						return false;
+					}
+				}
+				if (localFlags[0] != 0 && localFlags[0] == localFlags[1]) {
+					if (!statement.getSubject().equals(statement.getPredicate())) {
+						return false;
+					}
+				}
+				if (localFlags[1] != 0 && localFlags[1] == localFlags[2]) {
+					if (!statement.getPredicate().equals(statement.getObject())) {
+						return false;
+					}
+				}
+				return true;
+			}
+
+			public void remove() {
+				throw new UnsupportedOperationException();
+			}
+
+			public boolean hasNext() {
+				return this.nextStatement != null;
+			}
+
+			public Object next() {
+				if (this.nextStatement == null) {
+					throw new NoSuchElementException();
+				}
+				RdfBindingRow row = new StatementBindingRow(this.nextStatement);
+				this.nextStatement = nextStatement();
+				return row;
+			}
+
+			private class StatementBindingRow extends AbstractRdfBindingRow {
+
+				private final GraphStatement statement;
+
+				StatementBindingRow(GraphStatement statement) {
+					super(StatementBindingSet.this);
+					this.statement = statement;
+				}
+
+				public Value getValue(Variable variable) {
+					// Special case for the source
+					if (StatementBindingSet.this.query.includeSource
+							&& variable.equals(StreamedGraphConstraintLogic.CONTEXT_VARIABLE)) {
+						return this.statement.getGraphName();
+					}
+					// First get the index
+					int index = getIndex(variable);
+
+					int[] localFlags = StatementBindingSet.this.query.flags;
+					if (index == 2) {
+						// If the variable is in the last spot, it's got to be
+						// the object
+						return this.statement.getObject();
+					} else if (index == 1) {
+						// If the variable is the second one, it's either the
+						// pred or object
+						if (localFlags[1] != 0 && localFlags[0] != 0) {
+							// It's the predicate if the subject and predicate
+							// are variables
+							return this.statement.getPredicate();
+						} else {
+							return this.statement.getObject();
+						}
+					} else if (index == 0) {
+						// If the variable is the first, it could be any
+						if (localFlags[0] != 0) {
+							return this.statement.getSubject();
+						} else if (localFlags[1] != 0) {
+							return this.statement.getPredicate();
+						} else {
+							return this.statement.getObject();
+						}
+					}
+					return null;
+				}
+
+				private int getIndex(Variable variable) {
+					int index = 0;
+					for (Iterator vars = StatementBindingSet.this.query.variables.iterator(); vars.hasNext(); index++) {
+						Variable var = (Variable) vars.next();
+						if (variable.equals(var)) {
+							return index;
+						}
+					}
+					return -1;
+				}
+
+				public List getVariables() {
+					return StatementBindingSet.this.getVariables();
+				}
+
+			}
+		}
+
+		public String describeSet() {
+			return "FETCH TRIPLES FOR [" + StreamedTripleConstraintLogic.this.data.getSubjectExpression() + ","
+					+ StreamedTripleConstraintLogic.this.data.getPredicateExpression() + ","
+					+ StreamedTripleConstraintLogic.this.data.getObjectExpression() + "]";
+		}
+
+		public void accept(StreamedBindingSetVisitor setVisitor) {
+			setVisitor.visit(this);
+		}
+
+	}
+
+	private class StreamedTripleBindingSet extends VirtualRdfBindingSet {
+
+		private final TripleQueryOptions query;
+		
+		private final List statementIterators = new ArrayList();
+
+		public StreamedTripleBindingSet(TripleQueryOptions query) {
+			this.query = query;
+		}
+
+		public void setSource(RdfSource source) {
+			TripleQueryOptions q = query.clone();
+			q.source = source;
+			StatementBindingSet set = new StatementBindingSet(q);
+			for (Iterator statementIt = statementIterators.iterator(); statementIt.hasNext();) {
+				set.addIterator((GraphStatement) statementIt.next());
+			}
+			setSourcedSet(set);
+		}
+
+		public String describeSet() {
+			return "FETCH TRIPLES FOR [" + StreamedTripleConstraintLogic.this.data.getSubjectExpression() + ","
+					+ StreamedTripleConstraintLogic.this.data.getPredicateExpression() + ","
+					+ StreamedTripleConstraintLogic.this.data.getObjectExpression() + "]";
+		}
+
+		void addIterator(GraphStatement statement) {
+			this.statementIterators.add(statement);
+		}
+
+		public void accept(StreamedBindingSetVisitor setVisitor) {
+			setVisitor.visit(this);
+		}
+	}
+}
\ No newline at end of file
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/StreamedLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/StreamedLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/StreamedLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/StreamedLogic.java	2006-12-02 11:28:06.000000000 -0500
@@ -378,8 +378,8 @@
 	 *            direction
 	 * @return the logic handling the ordering of an expression
 	 */
-	public OrderExpressionLogic getOrderExpressionLogic(OrderExpressionData data) {
-		return new DefaultOrderExpressionLogic(data, getValueOrderingLogic());
+	public OrderExpressionLogic getOrderExpressionLogic(OrderExpressionData data, SPARQLValueFactory valueFactory) {
+		return new DefaultOrderExpressionLogic(data, getValueOrderingLogic(valueFactory));
 	}
 
 	/**
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/StreamedStrictLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/StreamedStrictLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/StreamedStrictLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/StreamedStrictLogic.java	2006-12-02 11:17:59.000000000 -0500
@@ -270,8 +270,8 @@
 	 *            direction
 	 * @return the logic handling the ordering of an expression
 	 */
-	public OrderExpressionLogic getOrderExpressionLogic(OrderExpressionData data) {
-		return new DefaultOrderExpressionLogic(data, getValueOrderingLogic());
+	public OrderExpressionLogic getOrderExpressionLogic(OrderExpressionData data, SPARQLValueFactory valueFactory) {
+		return new DefaultOrderExpressionLogic(data, getValueOrderingLogic(valueFactory));
 	}
 
 	/**
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/model/logic/ConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/model/logic/ConstraintLogic.java
--- upstream/src/main/name/levering/ryan/sparql/model/logic/ConstraintLogic.java	2006-08-20 20:00:59.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/model/logic/ConstraintLogic.java	2007-02-21 07:49:30.000000000 -0500
@@ -6,6 +6,7 @@
 package name.levering.ryan.sparql.model.logic;
 
 import java.util.Collection;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -27,16 +28,51 @@
      * Constrains the value bindings by either constraining the current value
      * bindings or returning a set that will be constrained via intersection
      * with the current set.
-     * 
-     * @param bindings the set of current bindings to evaluate against
-     * @param source the RDF source, which is dealt with by the triple
-     *            constraint
-     * @param defaultDatasets the datasets that are currently being used for
-     *            binding
-     * @param namedDatasets the datasets that are used in the GRAPH constraint
-     *            for unbound variables
      */
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source,
-            Collection defaultDatasets, Collection namedDatasets);
+    public RdfBindingSet constrain(CallParams p);
 
+	 public static class CallParams {
+		 /**
+		  * The set of current bindings to evaluate against, for
+		  * ConstraintLogics where it is used (like filters).
+		  */
+		 public RdfBindingSet bindings;
+		 
+		 /**
+		  * The RDF data source, which is dealt with by the triple constraint
+		  */
+		 public RdfSource source;
+       
+		 /**
+		  * The datasets that are currently being used for binding
+		  */
+		 public Collection defaultDatasets;
+		 
+		 /**
+		  * The datasets that are used in the GRAPH constraint for unbound variables
+		  */
+		 public Collection namedDatasets;
+		
+		 /**
+		  * A mapping from variables to Sets of values that the variable must be drawn from
+		  */
+		 public Map knownValues;
+		 
+		 /**
+		  * A mapping from variables to Lists of filters that the variable must satisfy.
+		  * A filter's type is determined by API implementors.
+		  */
+		 public Map knownFilters;
+		 
+		 public CallParams clone() {
+			 CallParams p = new CallParams();
+			 p.bindings = bindings;
+			 p.source = source;
+			 p.defaultDatasets = defaultDatasets == null ? null : new java.util.ArrayList(defaultDatasets);
+			 p.namedDatasets = namedDatasets == null ? null : new java.util.ArrayList(namedDatasets);
+			 p.knownValues = knownValues == null ? null : new java.util.HashMap(knownValues);
+			 p.knownFilters = knownFilters == null ? null : new java.util.HashMap(knownFilters);
+			 return p;
+		 }
+	 }
 }
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/model/logic/ConstraintLogic.java~ work-copy/src/main/name/levering/ryan/sparql/model/logic/ConstraintLogic.java~
--- upstream/src/main/name/levering/ryan/sparql/model/logic/ConstraintLogic.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/model/logic/ConstraintLogic.java~	2007-02-21 07:01:17.000000000 -0500
@@ -0,0 +1,67 @@
+/*
+ * SPARQL Engine
+ * Copyright (C) 2005 Ryan Levering, All rights reserved.
+ * See LICENSE for full license information
+ */
+package name.levering.ryan.sparql.model.logic;
+
+import java.util.Collection;
+import java.util.Map;
+
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfSource;
+
+/**
+ * The logic that every constraint satisfies. It currently can be used two ways.
+ * If the logic is dependent on current evaluated bindings (FILTER and
+ * OPTIONAL), it can use the passed in bindings as input. Otherwise, it can
+ * ignore the input and just return the value bindings that the constraint
+ * creates. This is then intersected with the current bindings in the group
+ * constraint.
+ * 
+ * @author Ryan Levering
+ * @version 1.0
+ */
+public interface ConstraintLogic {
+
+    /**
+     * Constrains the value bindings by either constraining the current value
+     * bindings or returning a set that will be constrained via intersection
+     * with the current set.
+     */
+    public RdfBindingSet constrain(CallParams p);
+
+	 public class CallParams {
+		 /**
+		  * The set of current bindings to evaluate against, for
+		  * ConstraintLogics where it is used (like filters).
+		  */
+		 RdfBindingSet bindings;
+		 
+		 /**
+		  * The RDF data source, which is dealt with by the triple constraint
+		  */
+		 RdfSource source;
+       
+		 /**
+		  * The datasets that are currently being used for binding
+		  */
+		 Collection defaultDatasets;
+		 
+		 /**
+		  * The datasets that are used in the GRAPH constraint for unbound variables
+		  */
+		 Collection namedDatasets;
+		
+		 /**
+		  * A mapping from variables to Sets of values that the variable must be drawn from
+		  */
+		 Map knownValues;
+		 
+		 /**
+		  * A mapping from variables to Lists of filters that the variable must satisfy.
+		  * A filter's type is determined by API implementors.
+		  */
+		 Map knownFilters;
+	 }
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/model/logic/LogicFactory.java work-copy/src/main/name/levering/ryan/sparql/model/logic/LogicFactory.java
--- upstream/src/main/name/levering/ryan/sparql/model/logic/LogicFactory.java	2006-08-20 20:00:59.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/model/logic/LogicFactory.java	2006-12-02 11:00:47.000000000 -0500
@@ -63,7 +63,7 @@
 
 	public ConstraintLogic getOptionalConstraintLogic(OptionalConstraintData data, SPARQLValueFactory valueFactory);
 
-	public OrderExpressionLogic getOrderExpressionLogic(OrderExpressionData data);
+	public OrderExpressionLogic getOrderExpressionLogic(OrderExpressionData data, SPARQLValueFactory valueFactory);
 
 	public ExpressionLogic getAdditionLogic(BinaryExpressionData data, SPARQLValueFactory valueFactory);
 
@@ -119,7 +119,7 @@
 
 	public ValueConversionLogic getValueConversionLogic(SPARQLValueFactory valueFactory);
 
-	public ValueOrderingLogic getValueOrderingLogic();
+	public ValueOrderingLogic getValueOrderingLogic(SPARQLValueFactory valueFactory);
 
 	public void registerExternalFunction(URI functionIRI, ExternalFunctionFactory functionFactory);
 
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/parser/model/ASTFilterConstraint.java work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTFilterConstraint.java
--- upstream/src/main/name/levering/ryan/sparql/parser/model/ASTFilterConstraint.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTFilterConstraint.java	2007-02-21 07:40:03.000000000 -0500
@@ -4,6 +4,7 @@
 
 import java.util.Collection;
 import java.util.Collections;
+import java.util.Map;
 import java.util.Set;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
@@ -24,8 +25,8 @@
         return (ExpressionLogic) this.jjtGetChild(0);
     }
 
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets, Collection namedDatasets) {
-        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+        return this.logic.constrain(p);
     }
 
     public Set getVariables() {
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/parser/model/ASTFilterConstraint.java~ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTFilterConstraint.java~
--- upstream/src/main/name/levering/ryan/sparql/parser/model/ASTFilterConstraint.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTFilterConstraint.java~	2007-02-21 07:05:58.000000000 -0500
@@ -0,0 +1,44 @@
+/* Generated By:JJTree: Do not edit this line. ASTFilterConstraint.java */
+
+package name.levering.ryan.sparql.parser.model;
+
+import java.util.Collection;
+import java.util.Collections;
+import java.util.Map;
+import java.util.Set;
+
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.model.FilterConstraint;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
+import name.levering.ryan.sparql.model.logic.ExpressionLogic;
+
+public class ASTFilterConstraint extends SimpleNode implements FilterConstraint {
+    
+    private ConstraintLogic logic;
+    
+    public ASTFilterConstraint(int id) {
+        super(id);
+    }
+
+    public ExpressionLogic getExpression() {
+        return (ExpressionLogic) this.jjtGetChild(0);
+    }
+
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
+    }
+
+    public Set getVariables() {
+        return Collections.EMPTY_SET;
+    }
+    
+    public String toString() {
+        return "FILTER " + getExpression();
+    }
+    
+    public void applyLogic(LogicBinder binder) {
+        this.logic = binder.getLogicFactory().getFilterConstraintLogic(this, binder.getValueFactory());
+    }
+
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/parser/model/ASTGraphConstraint.java work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTGraphConstraint.java
--- upstream/src/main/name/levering/ryan/sparql/parser/model/ASTGraphConstraint.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTGraphConstraint.java	2007-02-21 07:40:07.000000000 -0500
@@ -3,6 +3,7 @@
 package name.levering.ryan.sparql.parser.model;
 
 import java.util.Collection;
+import java.util.Map;
 import java.util.Set;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
@@ -40,8 +41,8 @@
         return null;
     }
 
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets, Collection namedDatasets) {
-        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+        return this.logic.constrain(p);
     }
 
     public Set getVariables() {
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/parser/model/ASTGraphConstraint.java~ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTGraphConstraint.java~
--- upstream/src/main/name/levering/ryan/sparql/parser/model/ASTGraphConstraint.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTGraphConstraint.java~	2007-02-21 07:05:57.000000000 -0500
@@ -0,0 +1,60 @@
+/* Generated By:JJTree: Do not edit this line. ASTGraphConstraint.java */
+
+package name.levering.ryan.sparql.parser.model;
+
+import java.util.Collection;
+import java.util.Map;
+import java.util.Set;
+
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.model.GraphConstraint;
+import name.levering.ryan.sparql.model.GroupConstraint;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
+import name.levering.ryan.sparql.model.logic.ExpressionLogic;
+
+public class ASTGraphConstraint extends SimpleNode implements GraphConstraint {
+    
+    private ConstraintLogic logic;
+    
+    public ASTGraphConstraint(int id) {
+        super(id);
+    }
+
+    public GroupConstraint getConstraint() {
+        for (int i = 0; i < this.jjtGetNumChildren(); i++) {
+            Node child = this.jjtGetChild(i); 
+            if (child instanceof GroupConstraint) {
+                return (GroupConstraint) child;
+            }
+        }
+        return null;
+    }
+
+    public ExpressionLogic getGraph() {
+        for (int i = 0; i < this.jjtGetNumChildren(); i++) {
+            Node child = this.jjtGetChild(i);
+            if (child instanceof ASTGraph) {
+                return (ExpressionLogic) child.jjtGetChild(0);
+            }
+        }
+        return null;
+    }
+
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
+    }
+
+    public Set getVariables() {
+        return getConstraint().getVariables();
+    }
+    
+    public String toString() {
+        return "GRAPH " + getGraph() + " " + getConstraint();
+    }
+    
+    public void applyLogic(LogicBinder binder) {
+        this.logic = binder.getLogicFactory().getGraphConstraintLogic(this);
+    }
+
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/parser/model/ASTGroupConstraint.java work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTGroupConstraint.java
--- upstream/src/main/name/levering/ryan/sparql/parser/model/ASTGroupConstraint.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTGroupConstraint.java	2007-02-21 07:40:11.000000000 -0500
@@ -6,6 +6,7 @@
 import java.util.Collection;
 import java.util.HashSet;
 import java.util.Iterator;
+import java.util.Map;
 import java.util.Set;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
@@ -39,9 +40,8 @@
         return constraints;
     }
 
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source,
-            Collection defaultDatasets, Collection namedDatasets) {
-        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+        return this.logic.constrain(p);
     }
 
     public Set getVariables() {
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/parser/model/ASTGroupConstraint.java~ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTGroupConstraint.java~
--- upstream/src/main/name/levering/ryan/sparql/parser/model/ASTGroupConstraint.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTGroupConstraint.java~	2007-02-21 07:05:59.000000000 -0500
@@ -0,0 +1,89 @@
+/* Generated By:JJTree: Do not edit this line. ASTGroupConstraint.java */
+
+package name.levering.ryan.sparql.parser.model;
+
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.Map;
+import java.util.Set;
+
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.model.GroupConstraint;
+import name.levering.ryan.sparql.model.data.ConstraintData;
+import name.levering.ryan.sparql.model.data.UnboundStatement;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
+import name.levering.ryan.sparql.model.logic.LogicFactory;
+
+public class ASTGroupConstraint extends SimpleNode implements GroupConstraint {
+
+    private ConstraintLogic logic;
+
+    private Collection expandedTriples;
+
+    public ASTGroupConstraint(int id) {
+        super(id);
+    }
+
+    public Collection getConstraints() {
+        // Put all the triples in
+        Collection constraints = new ArrayList(this.expandedTriples);
+
+        // Put the non-triple constraints (union, optional, filter, etc.)
+        for (int i = 0; i < this.jjtGetNumChildren(); i++) {
+            if (!(this.jjtGetChild(i) instanceof StatementAggregate)) {
+                constraints.add(this.jjtGetChild(i));
+            }
+        }
+        return constraints;
+    }
+
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
+    }
+
+    public Set getVariables() {
+        Set variableList = new HashSet();
+        for (Iterator cons = getConstraints().iterator(); cons.hasNext();) {
+            ConstraintData c = (ConstraintData) cons.next();
+            variableList.addAll(c.getVariables());
+        }
+        return variableList;
+    }
+
+    public String toString() {
+        StringBuffer output = new StringBuffer("{ ");
+        for (int i = 0; i < this.jjtGetNumChildren(); i++) {
+            output.append(this.jjtGetChild(i));
+            if (i + 1 < this.jjtGetNumChildren()) {
+                output.append("\n");
+            } else {
+                output.append(" ");
+            }
+        }
+        output.append('}');
+        return output.toString();
+    }
+
+    public void applyLogic(LogicBinder factoryToApply) {
+    	LogicFactory factory = factoryToApply.getLogicFactory();
+        this.expandedTriples = new ArrayList();
+        for (int i = 0; i < this.jjtGetNumChildren(); i++) {
+            if (this.jjtGetChild(i) instanceof StatementAggregate) {
+                StatementAccumulator accumulator = new StatementAccumulator();
+                this.jjtGetChild(i).jjtAccept(accumulator);
+                for (Iterator statements = accumulator.getUnboundStatements().iterator(); statements.hasNext();) {
+                    DelegatingTripleConstraint constraint = new DelegatingTripleConstraint(
+                            (UnboundStatement) statements.next());
+                    constraint.setLogic(factory.getTripleConstraintLogic(constraint));
+                    this.expandedTriples.add(constraint);
+                }
+            }
+        }
+
+        this.logic = factory.getGroupConstraintLogic(this);
+    }
+
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/parser/model/ASTLiteral.java work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTLiteral.java
--- upstream/src/main/name/levering/ryan/sparql/parser/model/ASTLiteral.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTLiteral.java	2006-12-02 11:00:47.000000000 -0500
@@ -61,4 +61,15 @@
         }
     }
     
+	public int hashCode() {
+		return label.hashCode();
+	}
+	
+	public boolean equals(Object other) {
+		if (!(other instanceof Literal)) return false;
+		Literal lit = (Literal)other;
+		return label.equals(lit.getLabel())
+			&& ((language == null && lit.getLanguage() == null) || (language != null && lit.getLanguage() != null && language.equals(lit.getLanguage())))
+			&& ((datatype == null && lit.getDatatype() == null) || (datatype != null && lit.getDatatype() != null && datatype.equals(lit.getDatatype()))); 
+	}
 }
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/parser/model/ASTOptionalConstraint.java work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTOptionalConstraint.java
--- upstream/src/main/name/levering/ryan/sparql/parser/model/ASTOptionalConstraint.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTOptionalConstraint.java	2007-02-21 07:40:17.000000000 -0500
@@ -3,6 +3,7 @@
 package name.levering.ryan.sparql.parser.model;
 
 import java.util.Collection;
+import java.util.Map;
 import java.util.Set;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
@@ -24,8 +25,8 @@
         return (GroupConstraint) this.jjtGetChild(0);
     }
 
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets, Collection namedDatasets) {
-        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+        return this.logic.constrain(p);
     }
 
     public Set getVariables() {
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/parser/model/ASTOptionalConstraint.java~ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTOptionalConstraint.java~
--- upstream/src/main/name/levering/ryan/sparql/parser/model/ASTOptionalConstraint.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTOptionalConstraint.java~	2007-02-21 07:06:00.000000000 -0500
@@ -0,0 +1,44 @@
+/* Generated By:JJTree: Do not edit this line. ASTOptionalConstraint.java */
+
+package name.levering.ryan.sparql.parser.model;
+
+import java.util.Collection;
+import java.util.Map;
+import java.util.Set;
+
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.model.GroupConstraint;
+import name.levering.ryan.sparql.model.OptionalConstraint;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
+
+public class ASTOptionalConstraint extends SimpleNode implements
+        OptionalConstraint {
+    
+    private ConstraintLogic logic;
+    
+    public ASTOptionalConstraint(int id) {
+        super(id);
+    }
+
+    public GroupConstraint getConstraint() {
+        return (GroupConstraint) this.jjtGetChild(0);
+    }
+
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
+    }
+
+    public Set getVariables() {
+        return getConstraint().getVariables();
+    }
+    
+    public String toString() {
+        return "OPTIONAL " + getConstraint();
+    }
+    
+    public void applyLogic(LogicBinder binder) {
+        this.logic = binder.getLogicFactory().getOptionalConstraintLogic(this, binder.getValueFactory());
+    }
+
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/parser/model/ASTUnionConstraint.java work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTUnionConstraint.java
--- upstream/src/main/name/levering/ryan/sparql/parser/model/ASTUnionConstraint.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTUnionConstraint.java	2007-02-21 07:40:21.000000000 -0500
@@ -6,6 +6,7 @@
 import java.util.Collection;
 import java.util.HashSet;
 import java.util.Iterator;
+import java.util.Map;
 import java.util.Set;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
@@ -31,8 +32,8 @@
         return constraints;
     }
 
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets, Collection namedDatasets) {
-        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+        return this.logic.constrain(p);
     }
 
     public Set getVariables() {
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/parser/model/ASTUnionConstraint.java~ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTUnionConstraint.java~
--- upstream/src/main/name/levering/ryan/sparql/parser/model/ASTUnionConstraint.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTUnionConstraint.java~	2007-02-21 07:06:01.000000000 -0500
@@ -0,0 +1,65 @@
+/* Generated By:JJTree: Do not edit this line. ASTUnionConstraint.java */
+
+package name.levering.ryan.sparql.parser.model;
+
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.Map;
+import java.util.Set;
+
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.model.UnionConstraint;
+import name.levering.ryan.sparql.model.data.ConstraintData;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
+
+public class ASTUnionConstraint extends SimpleNode implements
+        UnionConstraint {
+    
+    private ConstraintLogic logic;
+    
+    public ASTUnionConstraint(int id) {
+        super(id);
+    }
+
+    public Collection getConstraints() {
+        Collection constraints = new ArrayList();
+        for (int i = 0; i < this.jjtGetNumChildren(); i++) {
+            constraints.add(this.jjtGetChild(i));
+        }
+        return constraints;
+    }
+
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
+    }
+
+    public Set getVariables() {
+        Set variableList = new HashSet();
+        for (Iterator cons = getConstraints().iterator(); cons.hasNext();) {
+            ConstraintData c = (ConstraintData) cons.next();
+            variableList.addAll(c.getVariables());
+        }
+        return variableList;
+    }
+
+    
+    public String toString() {
+        StringBuffer output = new StringBuffer();
+        for (Iterator i = getConstraints().iterator(); i.hasNext(); ) {
+            output.append(i.next());
+            if (i.hasNext()) {
+                output.append(" UNION ");
+            }
+        }
+        output.append(" .");
+        return output.toString();
+    }
+    
+    public void applyLogic(LogicBinder binder) {
+        this.logic = binder.getLogicFactory().getUnionConstraintLogic(this);
+    }
+
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/parser/model/ASTWithExtension.java work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTWithExtension.java
--- upstream/src/main/name/levering/ryan/sparql/parser/model/ASTWithExtension.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTWithExtension.java	2007-02-21 07:40:25.000000000 -0500
@@ -6,6 +6,7 @@
 import java.util.Collections;
 import java.util.List;
 import java.util.Set;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.QueryException;
 import name.levering.ryan.sparql.common.RdfBindingSet;
@@ -25,8 +26,8 @@
         super(id);
     }
     
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets, Collection namedDatasets) {
-        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+        return this.logic.constrain(p);
     }
 
     public URI getName() {
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/parser/model/ASTWithExtension.java~ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTWithExtension.java~
--- upstream/src/main/name/levering/ryan/sparql/parser/model/ASTWithExtension.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTWithExtension.java~	2007-02-21 07:06:02.000000000 -0500
@@ -0,0 +1,54 @@
+/* Generated By:JJTree: Do not edit this line. ASTWithExtension.java */
+
+package name.levering.ryan.sparql.parser.model;
+
+import java.util.Collection;
+import java.util.Collections;
+import java.util.List;
+import java.util.Set;
+import java.util.Map;
+
+import name.levering.ryan.sparql.common.QueryException;
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.model.WithConstraint;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
+import name.levering.ryan.sparql.model.logic.ExtendedLogicFactory;
+import name.levering.ryan.sparql.model.logic.LogicFactory;
+
+import org.openrdf.model.URI;
+
+public class ASTWithExtension extends SimpleNode implements WithConstraint {
+    
+    private ConstraintLogic logic;
+    
+    public ASTWithExtension(int id) {
+        super(id);
+    }
+    
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
+    }
+
+    public URI getName() {
+        ASTFunctionCall withFunction = (ASTFunctionCall) this.jjtGetChild(0);
+        return withFunction.getName();
+    }
+
+    public List getArguments() {
+        ASTFunctionCall withFunction = (ASTFunctionCall) this.jjtGetChild(0);
+        return withFunction.getArguments();
+    }
+
+    public Set getVariables() {
+        return Collections.EMPTY_SET;
+    }
+    
+    public void applyLogic(LogicBinder binder) {
+    	LogicFactory logic = binder.getLogicFactory();
+    	if (!(logic instanceof ExtendedLogicFactory)) {
+    		throw new QueryException("Binding logic does not allow for WITH extensions");
+    	}
+        this.logic = ((ExtendedLogicFactory) binder.getLogicFactory()).getWithConstraintLogic(this);
+    }
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/parser/model/DelegatingTripleConstraint.java work-copy/src/main/name/levering/ryan/sparql/parser/model/DelegatingTripleConstraint.java
--- upstream/src/main/name/levering/ryan/sparql/parser/model/DelegatingTripleConstraint.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/DelegatingTripleConstraint.java	2007-02-21 07:40:30.000000000 -0500
@@ -7,6 +7,7 @@
 
 import java.util.Collection;
 import java.util.HashSet;
+import java.util.Map;
 import java.util.Set;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
@@ -39,8 +40,8 @@
         return this.statement.getObjectExpression();
     }
 
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets, Collection namedDatasets) {
-        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+        return this.logic.constrain(p);
     }
 
     public Set getVariables() {
@@ -64,5 +65,5 @@
     public void setLogic(ConstraintLogic logic) {
         this.logic = logic;
     }
-
+	
 }
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/parser/model/DelegatingTripleConstraint.java~ work-copy/src/main/name/levering/ryan/sparql/parser/model/DelegatingTripleConstraint.java~
--- upstream/src/main/name/levering/ryan/sparql/parser/model/DelegatingTripleConstraint.java~	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/DelegatingTripleConstraint.java~	2007-02-21 07:06:03.000000000 -0500
@@ -0,0 +1,69 @@
+/*
+ * SPARQL Engine
+ * Copyright (C) 2005 Ryan Levering, All rights reserved.
+ * See LICENSE for full license information
+ */
+package name.levering.ryan.sparql.parser.model;
+
+import java.util.Collection;
+import java.util.HashSet;
+import java.util.Map;
+import java.util.Set;
+
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.common.Variable;
+import name.levering.ryan.sparql.model.TripleConstraint;
+import name.levering.ryan.sparql.model.data.UnboundStatement;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
+import name.levering.ryan.sparql.model.logic.ExpressionLogic;
+
+public class DelegatingTripleConstraint implements TripleConstraint {
+    
+    private ConstraintLogic logic;
+    
+    private UnboundStatement statement;
+    
+    public DelegatingTripleConstraint(UnboundStatement statement) {
+        this.statement = statement;
+    }
+
+    public ExpressionLogic getSubjectExpression() {
+        return this.statement.getSubjectExpression();
+    }
+
+    public ExpressionLogic getPredicateExpression() {
+        return this.statement.getPredicateExpression();
+    }
+
+    public ExpressionLogic getObjectExpression() {
+        return this.statement.getObjectExpression();
+    }
+
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
+    }
+
+    public Set getVariables() {
+        Set variables = new HashSet();
+        if (getSubjectExpression() instanceof Variable) {
+            variables.add(getSubjectExpression());
+        }
+        if (getObjectExpression() instanceof Variable) {
+            variables.add(getObjectExpression());
+        }
+        if (getPredicateExpression() instanceof Variable) {
+            variables.add(getPredicateExpression());
+        }
+        return variables;
+    }
+    
+    public String toString() {
+        return getSubjectExpression() + " " + getPredicateExpression() + " " + getObjectExpression() + " .";
+    }
+    
+    public void setLogic(ConstraintLogic logic) {
+        this.logic = logic;
+    }
+	
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/parser/model/OrderExpressionNode.java work-copy/src/main/name/levering/ryan/sparql/parser/model/OrderExpressionNode.java
--- upstream/src/main/name/levering/ryan/sparql/parser/model/OrderExpressionNode.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/OrderExpressionNode.java	2006-12-02 11:00:47.000000000 -0500
@@ -31,6 +31,6 @@
     }
 
     public void applyLogic(LogicBinder binder) {
-        this.logic = binder.getLogicFactory().getOrderExpressionLogic(this);
+        this.logic = binder.getLogicFactory().getOrderExpressionLogic(this, binder.getValueFactory());
     }
 }
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/parser/model/SPARQLParserTreeConstants.java work-copy/src/main/name/levering/ryan/sparql/parser/model/SPARQLParserTreeConstants.java
--- upstream/src/main/name/levering/ryan/sparql/parser/model/SPARQLParserTreeConstants.java	2006-12-02 11:30:46.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/SPARQLParserTreeConstants.java	2006-12-02 10:52:04.000000000 -0500
@@ -1,4 +1,4 @@
-/* Generated By:JJTree: Do not edit this line. /home/tauberer/dev/semweb/sparql/upstream/src/main/name/levering/ryan/sparql/parser/model/SPARQLParserTreeConstants.java */
+/* Generated By:JJTree: Do not edit this line. /home/tauberer/dev/semweb/sparql/src/src/main/name/levering/ryan/sparql/parser/model/SPARQLParserTreeConstants.java */
 
 package name.levering.ryan.sparql.parser.model;
 
