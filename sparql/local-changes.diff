diff -urN --exclude=.svn sparql-0.8/1 work-copy/1
--- sparql-0.8/1	2006-08-01 11:35:14.000000000 -0400
+++ work-copy/1	2006-08-01 17:04:17.000000000 -0400
@@ -1,5 +1,5 @@
 
 BUILD FAILED
-/home/tauberer/dev/semweb/sparql/sparql-0.8/build.xml:130: Compile failed; see the compiler error output for details.
+/home/tauberer/dev/semweb/sparql/work-copy/build.xml:132: Compile failed; see the compiler error output for details.
 
-Total time: 12 seconds
+Total time: 9 seconds
diff -urN --exclude=.svn sparql-0.8/build.xml work-copy/build.xml
--- sparql-0.8/build.xml	2006-07-16 19:04:04.000000000 -0400
+++ work-copy/build.xml	2006-08-01 12:49:32.000000000 -0400
@@ -8,7 +8,7 @@
      Ryan Levering
      ====================================================================== -->
 <project name="SPARQL Parser" default="dist_from_grammar">
-	
+
 	<!-- STRUCTURE PROPERTIES -->
 	<property name="srcdir" value="src/main" />
 	<property name="testdir" value="src/tests" />
@@ -76,12 +76,12 @@
 		<jar basedir="${temp_dir}" destfile="${libdir}/${library}" />
 		<delete dir="${temp_dir}" />
 		<mkdir dir="${temp_dir}" />
-		<javac srcdir="${testdir}" destdir="${temp_dir}">
+		<!--<javac srcdir="${testdir}" destdir="${temp_dir}">
 			<classpath>
 				<path refid="test.classpath" />
 				<pathelement path="${libdir}/${library}" />
 			</classpath>
-		</javac>
+		</javac>-->
 		<copy todir="${temp_dir}" includeemptydirs="false">
 			<fileset dir="test_files">
 				<include name="**/*" />
@@ -92,6 +92,7 @@
 	</target>
 	
 	<!-- THIS WILL BUILD THE SOURCE AND TEST IT AGAINST THE GENERIC TEST CASES -->
+	<!--
 	<target name="test" depends="jar">
 		<junit printsummary="yes" fork="yes" haltonfailure="yes">
 			<classpath>
@@ -103,6 +104,7 @@
 			<formatter type="plain" usefile="false" />
 		</junit>
 	</target>
+	-->
 		
 	<!-- THIS WILL CREATE THE JAVADOCS IN THE DOCS FOLDER -->
 	<!-- THIS ISN'T USED FOR DISTRIBUTION, BUT CAN BE USED BY END USER -->
@@ -174,4 +176,4 @@
 	<!-- THIS WILL BUILD THE WHOLE DISTRIBUTION FROM GRAMMAR -->
 	<target name="dist_from_grammar" depends="grammar,dist" />
 
-</project>
\ No newline at end of file
+</project>
Binary files sparql-0.8/lib/sparql-core.jar and work-copy/lib/sparql-core.jar differ
Binary files sparql-0.8/lib/sparql-tests.jar and work-copy/lib/sparql-tests.jar differ
diff -urN --exclude=.svn sparql-0.8/.settings/org.eclipse.jdt.core.prefs work-copy/.settings/org.eclipse.jdt.core.prefs
--- sparql-0.8/.settings/org.eclipse.jdt.core.prefs	2006-07-16 19:04:02.000000000 -0400
+++ work-copy/.settings/org.eclipse.jdt.core.prefs	1969-12-31 19:00:00.000000000 -0500
@@ -1,300 +0,0 @@
-#Wed Jul 05 09:48:54 EDT 2006
-eclipse.preferences.version=1
-org.eclipse.jdt.core.compiler.doc.comment.support=enabled
-org.eclipse.jdt.core.compiler.problem.annotationSuperInterface=warning
-org.eclipse.jdt.core.compiler.problem.autoboxing=ignore
-org.eclipse.jdt.core.compiler.problem.deprecation=warning
-org.eclipse.jdt.core.compiler.problem.deprecationInDeprecatedCode=disabled
-org.eclipse.jdt.core.compiler.problem.deprecationWhenOverridingDeprecatedMethod=disabled
-org.eclipse.jdt.core.compiler.problem.discouragedReference=warning
-org.eclipse.jdt.core.compiler.problem.emptyStatement=warning
-org.eclipse.jdt.core.compiler.problem.fieldHiding=warning
-org.eclipse.jdt.core.compiler.problem.finalParameterBound=warning
-org.eclipse.jdt.core.compiler.problem.finallyBlockNotCompletingNormally=warning
-org.eclipse.jdt.core.compiler.problem.forbiddenReference=error
-org.eclipse.jdt.core.compiler.problem.hiddenCatchBlock=warning
-org.eclipse.jdt.core.compiler.problem.incompatibleNonInheritedInterfaceMethod=warning
-org.eclipse.jdt.core.compiler.problem.incompleteEnumSwitch=warning
-org.eclipse.jdt.core.compiler.problem.indirectStaticAccess=warning
-org.eclipse.jdt.core.compiler.problem.invalidJavadoc=warning
-org.eclipse.jdt.core.compiler.problem.invalidJavadocTags=enabled
-org.eclipse.jdt.core.compiler.problem.invalidJavadocTagsDeprecatedRef=enabled
-org.eclipse.jdt.core.compiler.problem.invalidJavadocTagsNotVisibleRef=enabled
-org.eclipse.jdt.core.compiler.problem.invalidJavadocTagsVisibility=private
-org.eclipse.jdt.core.compiler.problem.localVariableHiding=warning
-org.eclipse.jdt.core.compiler.problem.methodWithConstructorName=warning
-org.eclipse.jdt.core.compiler.problem.missingDeprecatedAnnotation=ignore
-org.eclipse.jdt.core.compiler.problem.missingJavadocComments=warning
-org.eclipse.jdt.core.compiler.problem.missingJavadocCommentsOverriding=enabled
-org.eclipse.jdt.core.compiler.problem.missingJavadocCommentsVisibility=public
-org.eclipse.jdt.core.compiler.problem.missingJavadocTags=warning
-org.eclipse.jdt.core.compiler.problem.missingJavadocTagsOverriding=enabled
-org.eclipse.jdt.core.compiler.problem.missingJavadocTagsVisibility=private
-org.eclipse.jdt.core.compiler.problem.missingOverrideAnnotation=ignore
-org.eclipse.jdt.core.compiler.problem.missingSerialVersion=warning
-org.eclipse.jdt.core.compiler.problem.noEffectAssignment=warning
-org.eclipse.jdt.core.compiler.problem.noImplicitStringConversion=warning
-org.eclipse.jdt.core.compiler.problem.nonExternalizedStringLiteral=ignore
-org.eclipse.jdt.core.compiler.problem.overridingPackageDefaultMethod=warning
-org.eclipse.jdt.core.compiler.problem.possibleAccidentalBooleanAssignment=warning
-org.eclipse.jdt.core.compiler.problem.specialParameterHidingField=disabled
-org.eclipse.jdt.core.compiler.problem.staticAccessReceiver=warning
-org.eclipse.jdt.core.compiler.problem.suppressWarnings=enabled
-org.eclipse.jdt.core.compiler.problem.syntheticAccessEmulation=warning
-org.eclipse.jdt.core.compiler.problem.typeParameterHiding=warning
-org.eclipse.jdt.core.compiler.problem.uncheckedTypeOperation=warning
-org.eclipse.jdt.core.compiler.problem.undocumentedEmptyBlock=warning
-org.eclipse.jdt.core.compiler.problem.unhandledWarningToken=warning
-org.eclipse.jdt.core.compiler.problem.unnecessaryElse=ignore
-org.eclipse.jdt.core.compiler.problem.unnecessaryTypeCheck=warning
-org.eclipse.jdt.core.compiler.problem.unqualifiedFieldAccess=warning
-org.eclipse.jdt.core.compiler.problem.unusedDeclaredThrownException=warning
-org.eclipse.jdt.core.compiler.problem.unusedDeclaredThrownExceptionWhenOverriding=disabled
-org.eclipse.jdt.core.compiler.problem.unusedImport=warning
-org.eclipse.jdt.core.compiler.problem.unusedLocal=warning
-org.eclipse.jdt.core.compiler.problem.unusedParameter=ignore
-org.eclipse.jdt.core.compiler.problem.unusedParameterWhenImplementingAbstract=disabled
-org.eclipse.jdt.core.compiler.problem.unusedParameterWhenOverridingConcrete=disabled
-org.eclipse.jdt.core.compiler.problem.unusedPrivateMember=warning
-org.eclipse.jdt.core.compiler.problem.varargsArgumentNeedCast=warning
-org.eclipse.jdt.core.formatter.align_type_members_on_columns=false
-org.eclipse.jdt.core.formatter.alignment_for_arguments_in_allocation_expression=16
-org.eclipse.jdt.core.formatter.alignment_for_arguments_in_enum_constant=16
-org.eclipse.jdt.core.formatter.alignment_for_arguments_in_explicit_constructor_call=16
-org.eclipse.jdt.core.formatter.alignment_for_arguments_in_method_invocation=16
-org.eclipse.jdt.core.formatter.alignment_for_arguments_in_qualified_allocation_expression=16
-org.eclipse.jdt.core.formatter.alignment_for_binary_expression=16
-org.eclipse.jdt.core.formatter.alignment_for_compact_if=16
-org.eclipse.jdt.core.formatter.alignment_for_conditional_expression=80
-org.eclipse.jdt.core.formatter.alignment_for_enum_constants=0
-org.eclipse.jdt.core.formatter.alignment_for_expressions_in_array_initializer=16
-org.eclipse.jdt.core.formatter.alignment_for_multiple_fields=16
-org.eclipse.jdt.core.formatter.alignment_for_parameters_in_constructor_declaration=16
-org.eclipse.jdt.core.formatter.alignment_for_parameters_in_method_declaration=16
-org.eclipse.jdt.core.formatter.alignment_for_selector_in_method_invocation=16
-org.eclipse.jdt.core.formatter.alignment_for_superclass_in_type_declaration=16
-org.eclipse.jdt.core.formatter.alignment_for_superinterfaces_in_enum_declaration=16
-org.eclipse.jdt.core.formatter.alignment_for_superinterfaces_in_type_declaration=16
-org.eclipse.jdt.core.formatter.alignment_for_throws_clause_in_constructor_declaration=16
-org.eclipse.jdt.core.formatter.alignment_for_throws_clause_in_method_declaration=16
-org.eclipse.jdt.core.formatter.blank_lines_after_imports=1
-org.eclipse.jdt.core.formatter.blank_lines_after_package=1
-org.eclipse.jdt.core.formatter.blank_lines_before_field=1
-org.eclipse.jdt.core.formatter.blank_lines_before_first_class_body_declaration=0
-org.eclipse.jdt.core.formatter.blank_lines_before_imports=1
-org.eclipse.jdt.core.formatter.blank_lines_before_member_type=1
-org.eclipse.jdt.core.formatter.blank_lines_before_method=1
-org.eclipse.jdt.core.formatter.blank_lines_before_new_chunk=1
-org.eclipse.jdt.core.formatter.blank_lines_before_package=0
-org.eclipse.jdt.core.formatter.blank_lines_between_type_declarations=1
-org.eclipse.jdt.core.formatter.brace_position_for_annotation_type_declaration=end_of_line
-org.eclipse.jdt.core.formatter.brace_position_for_anonymous_type_declaration=end_of_line
-org.eclipse.jdt.core.formatter.brace_position_for_array_initializer=end_of_line
-org.eclipse.jdt.core.formatter.brace_position_for_block=end_of_line
-org.eclipse.jdt.core.formatter.brace_position_for_block_in_case=end_of_line
-org.eclipse.jdt.core.formatter.brace_position_for_constructor_declaration=end_of_line
-org.eclipse.jdt.core.formatter.brace_position_for_enum_constant=end_of_line
-org.eclipse.jdt.core.formatter.brace_position_for_enum_declaration=end_of_line
-org.eclipse.jdt.core.formatter.brace_position_for_method_declaration=end_of_line
-org.eclipse.jdt.core.formatter.brace_position_for_switch=end_of_line
-org.eclipse.jdt.core.formatter.brace_position_for_type_declaration=end_of_line
-org.eclipse.jdt.core.formatter.comment.clear_blank_lines=true
-org.eclipse.jdt.core.formatter.comment.format_comments=true
-org.eclipse.jdt.core.formatter.comment.format_header=false
-org.eclipse.jdt.core.formatter.comment.format_html=true
-org.eclipse.jdt.core.formatter.comment.format_source_code=true
-org.eclipse.jdt.core.formatter.comment.indent_parameter_description=true
-org.eclipse.jdt.core.formatter.comment.indent_root_tags=true
-org.eclipse.jdt.core.formatter.comment.insert_new_line_before_root_tags=insert
-org.eclipse.jdt.core.formatter.comment.insert_new_line_for_parameter=do not insert
-org.eclipse.jdt.core.formatter.comment.line_length=80
-org.eclipse.jdt.core.formatter.compact_else_if=true
-org.eclipse.jdt.core.formatter.continuation_indentation=2
-org.eclipse.jdt.core.formatter.continuation_indentation_for_array_initializer=2
-org.eclipse.jdt.core.formatter.format_guardian_clause_on_one_line=false
-org.eclipse.jdt.core.formatter.indent_body_declarations_compare_to_enum_constant_header=true
-org.eclipse.jdt.core.formatter.indent_body_declarations_compare_to_enum_declaration_header=true
-org.eclipse.jdt.core.formatter.indent_body_declarations_compare_to_type_header=true
-org.eclipse.jdt.core.formatter.indent_breaks_compare_to_cases=true
-org.eclipse.jdt.core.formatter.indent_statements_compare_to_block=true
-org.eclipse.jdt.core.formatter.indent_statements_compare_to_body=true
-org.eclipse.jdt.core.formatter.indent_switchstatements_compare_to_cases=true
-org.eclipse.jdt.core.formatter.indent_switchstatements_compare_to_switch=false
-org.eclipse.jdt.core.formatter.indentation.size=4
-org.eclipse.jdt.core.formatter.insert_new_line_after_annotation=insert
-org.eclipse.jdt.core.formatter.insert_new_line_after_opening_brace_in_array_initializer=do not insert
-org.eclipse.jdt.core.formatter.insert_new_line_at_end_of_file_if_missing=do not insert
-org.eclipse.jdt.core.formatter.insert_new_line_before_catch_in_try_statement=do not insert
-org.eclipse.jdt.core.formatter.insert_new_line_before_closing_brace_in_array_initializer=do not insert
-org.eclipse.jdt.core.formatter.insert_new_line_before_else_in_if_statement=do not insert
-org.eclipse.jdt.core.formatter.insert_new_line_before_finally_in_try_statement=do not insert
-org.eclipse.jdt.core.formatter.insert_new_line_before_while_in_do_statement=do not insert
-org.eclipse.jdt.core.formatter.insert_new_line_in_empty_anonymous_type_declaration=insert
-org.eclipse.jdt.core.formatter.insert_new_line_in_empty_block=insert
-org.eclipse.jdt.core.formatter.insert_new_line_in_empty_enum_constant=insert
-org.eclipse.jdt.core.formatter.insert_new_line_in_empty_enum_declaration=insert
-org.eclipse.jdt.core.formatter.insert_new_line_in_empty_method_body=insert
-org.eclipse.jdt.core.formatter.insert_new_line_in_empty_type_declaration=insert
-org.eclipse.jdt.core.formatter.insert_space_after_and_in_type_parameter=insert
-org.eclipse.jdt.core.formatter.insert_space_after_assignment_operator=insert
-org.eclipse.jdt.core.formatter.insert_space_after_at_in_annotation=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_at_in_annotation_type_declaration=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_binary_operator=insert
-org.eclipse.jdt.core.formatter.insert_space_after_closing_angle_bracket_in_type_arguments=insert
-org.eclipse.jdt.core.formatter.insert_space_after_closing_angle_bracket_in_type_parameters=insert
-org.eclipse.jdt.core.formatter.insert_space_after_closing_brace_in_block=insert
-org.eclipse.jdt.core.formatter.insert_space_after_closing_paren_in_cast=insert
-org.eclipse.jdt.core.formatter.insert_space_after_colon_in_assert=insert
-org.eclipse.jdt.core.formatter.insert_space_after_colon_in_case=insert
-org.eclipse.jdt.core.formatter.insert_space_after_colon_in_conditional=insert
-org.eclipse.jdt.core.formatter.insert_space_after_colon_in_for=insert
-org.eclipse.jdt.core.formatter.insert_space_after_colon_in_labeled_statement=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_allocation_expression=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_annotation=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_array_initializer=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_constructor_declaration_parameters=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_constructor_declaration_throws=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_enum_constant_arguments=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_enum_declarations=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_explicitconstructorcall_arguments=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_for_increments=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_for_inits=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_method_declaration_parameters=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_method_declaration_throws=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_method_invocation_arguments=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_multiple_field_declarations=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_multiple_local_declarations=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_parameterized_type_reference=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_superinterfaces=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_type_arguments=insert
-org.eclipse.jdt.core.formatter.insert_space_after_comma_in_type_parameters=insert
-org.eclipse.jdt.core.formatter.insert_space_after_ellipsis=insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_angle_bracket_in_parameterized_type_reference=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_angle_bracket_in_type_arguments=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_angle_bracket_in_type_parameters=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_brace_in_array_initializer=insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_bracket_in_array_allocation_expression=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_bracket_in_array_reference=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_paren_in_annotation=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_paren_in_cast=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_paren_in_catch=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_paren_in_constructor_declaration=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_paren_in_enum_constant=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_paren_in_for=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_paren_in_if=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_paren_in_method_declaration=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_paren_in_method_invocation=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_paren_in_parenthesized_expression=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_paren_in_switch=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_paren_in_synchronized=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_opening_paren_in_while=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_postfix_operator=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_prefix_operator=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_question_in_conditional=insert
-org.eclipse.jdt.core.formatter.insert_space_after_question_in_wildcard=do not insert
-org.eclipse.jdt.core.formatter.insert_space_after_semicolon_in_for=insert
-org.eclipse.jdt.core.formatter.insert_space_after_unary_operator=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_and_in_type_parameter=insert
-org.eclipse.jdt.core.formatter.insert_space_before_assignment_operator=insert
-org.eclipse.jdt.core.formatter.insert_space_before_at_in_annotation_type_declaration=insert
-org.eclipse.jdt.core.formatter.insert_space_before_binary_operator=insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_angle_bracket_in_parameterized_type_reference=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_angle_bracket_in_type_arguments=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_angle_bracket_in_type_parameters=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_brace_in_array_initializer=insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_bracket_in_array_allocation_expression=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_bracket_in_array_reference=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_paren_in_annotation=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_paren_in_cast=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_paren_in_catch=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_paren_in_constructor_declaration=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_paren_in_enum_constant=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_paren_in_for=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_paren_in_if=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_paren_in_method_declaration=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_paren_in_method_invocation=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_paren_in_parenthesized_expression=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_paren_in_switch=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_paren_in_synchronized=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_closing_paren_in_while=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_colon_in_assert=insert
-org.eclipse.jdt.core.formatter.insert_space_before_colon_in_case=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_colon_in_conditional=insert
-org.eclipse.jdt.core.formatter.insert_space_before_colon_in_default=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_colon_in_for=insert
-org.eclipse.jdt.core.formatter.insert_space_before_colon_in_labeled_statement=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_allocation_expression=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_annotation=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_array_initializer=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_constructor_declaration_parameters=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_constructor_declaration_throws=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_enum_constant_arguments=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_enum_declarations=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_explicitconstructorcall_arguments=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_for_increments=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_for_inits=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_method_declaration_parameters=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_method_declaration_throws=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_method_invocation_arguments=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_multiple_field_declarations=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_multiple_local_declarations=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_parameterized_type_reference=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_superinterfaces=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_type_arguments=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_comma_in_type_parameters=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_ellipsis=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_angle_bracket_in_parameterized_type_reference=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_angle_bracket_in_type_arguments=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_angle_bracket_in_type_parameters=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_brace_in_annotation_type_declaration=insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_brace_in_anonymous_type_declaration=insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_brace_in_array_initializer=insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_brace_in_block=insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_brace_in_constructor_declaration=insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_brace_in_enum_constant=insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_brace_in_enum_declaration=insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_brace_in_method_declaration=insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_brace_in_switch=insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_brace_in_type_declaration=insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_bracket_in_array_allocation_expression=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_bracket_in_array_reference=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_bracket_in_array_type_reference=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_paren_in_annotation=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_paren_in_annotation_type_member_declaration=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_paren_in_catch=insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_paren_in_constructor_declaration=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_paren_in_enum_constant=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_paren_in_for=insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_paren_in_if=insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_paren_in_method_declaration=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_paren_in_method_invocation=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_paren_in_parenthesized_expression=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_paren_in_switch=insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_paren_in_synchronized=insert
-org.eclipse.jdt.core.formatter.insert_space_before_opening_paren_in_while=insert
-org.eclipse.jdt.core.formatter.insert_space_before_postfix_operator=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_prefix_operator=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_question_in_conditional=insert
-org.eclipse.jdt.core.formatter.insert_space_before_question_in_wildcard=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_semicolon=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_semicolon_in_for=do not insert
-org.eclipse.jdt.core.formatter.insert_space_before_unary_operator=do not insert
-org.eclipse.jdt.core.formatter.insert_space_between_brackets_in_array_type_reference=do not insert
-org.eclipse.jdt.core.formatter.insert_space_between_empty_braces_in_array_initializer=do not insert
-org.eclipse.jdt.core.formatter.insert_space_between_empty_brackets_in_array_allocation_expression=do not insert
-org.eclipse.jdt.core.formatter.insert_space_between_empty_parens_in_annotation_type_member_declaration=do not insert
-org.eclipse.jdt.core.formatter.insert_space_between_empty_parens_in_constructor_declaration=do not insert
-org.eclipse.jdt.core.formatter.insert_space_between_empty_parens_in_enum_constant=do not insert
-org.eclipse.jdt.core.formatter.insert_space_between_empty_parens_in_method_declaration=do not insert
-org.eclipse.jdt.core.formatter.insert_space_between_empty_parens_in_method_invocation=do not insert
-org.eclipse.jdt.core.formatter.keep_else_statement_on_same_line=false
-org.eclipse.jdt.core.formatter.keep_empty_array_initializer_on_one_line=false
-org.eclipse.jdt.core.formatter.keep_imple_if_on_one_line=false
-org.eclipse.jdt.core.formatter.keep_then_statement_on_same_line=false
-org.eclipse.jdt.core.formatter.lineSplit=120
-org.eclipse.jdt.core.formatter.number_of_blank_lines_at_beginning_of_method_body=0
-org.eclipse.jdt.core.formatter.number_of_empty_lines_to_preserve=1
-org.eclipse.jdt.core.formatter.put_empty_statement_on_new_line=true
-org.eclipse.jdt.core.formatter.tabulation.char=tab
-org.eclipse.jdt.core.formatter.tabulation.size=4
-org.eclipse.jdt.core.formatter.use_tabs_only_for_leading_indentations=false
diff -urN --exclude=.svn sparql-0.8/.settings/org.eclipse.jdt.ui.prefs work-copy/.settings/org.eclipse.jdt.ui.prefs
--- sparql-0.8/.settings/org.eclipse.jdt.ui.prefs	2006-07-16 19:04:06.000000000 -0400
+++ work-copy/.settings/org.eclipse.jdt.ui.prefs	1969-12-31 19:00:00.000000000 -0500
@@ -1,3 +0,0 @@
-#Tue Jul 04 22:15:55 EDT 2006
-eclipse.preferences.version=1
-formatter_settings_version=8
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/common/AdvancedRdfSource.java work-copy/src/main/name/levering/ryan/sparql/common/AdvancedRdfSource.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/common/AdvancedRdfSource.java	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/common/AdvancedRdfSource.java	2006-08-01 16:32:54.000000000 -0400
@@ -0,0 +1,26 @@
+/*
+ * SPARQL Engine
+ * Copyright (C) 2005 Ryan Levering, All rights reserved.
+ * See LICENSE for full license information
+ */
+package name.levering.ryan.sparql.common;
+
+import java.util.Iterator;
+import java.util.List;
+
+import org.openrdf.model.URI;
+import org.openrdf.model.Value;
+import org.openrdf.model.ValueFactory;
+
+/**
+ * Description...
+ * 
+ * @author Joshua Tauberer
+ * @version 1.0
+ */
+public interface AdvancedRdfSource extends RdfSource {
+    public Iterator getStatements(Value[] subj, Value[] pred, Value[] obj, URI[] graph, Object[] litFilters);
+    public Iterator getDefaultStatements(Value[] subj, Value[] pred, Value[] obj, Object[] litFilters);
+    public Iterator getStatements(Value[] subj, Value[] pred, Value[] obj, Object[] litFilters);
+}
+
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/common/impl/RdfBindingSetImpl.java work-copy/src/main/name/levering/ryan/sparql/common/impl/RdfBindingSetImpl.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/common/impl/RdfBindingSetImpl.java	2006-07-16 19:04:04.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/common/impl/RdfBindingSetImpl.java	2006-08-21 22:52:29.000000000 -0400
@@ -98,6 +98,8 @@
 		for (Iterator oldRows = oldSet.iterator(); oldRows.hasNext();) {
 			this.addRow((RdfBindingRow) oldRows.next());
 		}
+		setDistinct(oldSet.isDistinct());
+		setOrdered(oldSet.isOrdered());
 	}
 
 	/**
@@ -371,7 +373,7 @@
 
 			int columnIndex = RdfBindingSetImpl.this.getIndex(variable);
 			if (columnIndex == -1) {
-				throw new IllegalArgumentException("Variable " + variable + " is not bound in this row");
+				throw new IllegalArgumentException("Variable " + variable + " is not bound in this row (available variables are " + RdfBindingSetImpl.this.variables + ")");
 			}
 			Value[] rowValues = ((Value[]) RdfBindingSetImpl.this.values.get(this.row));
 			return rowValues[columnIndex];
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/extensions/fpredicates/FunctionalPredicateLogic.java work-copy/src/main/name/levering/ryan/sparql/extensions/fpredicates/FunctionalPredicateLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/extensions/fpredicates/FunctionalPredicateLogic.java	2006-07-16 19:04:04.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/extensions/fpredicates/FunctionalPredicateLogic.java	2006-08-01 12:50:18.000000000 -0400
@@ -1,6 +1,7 @@
 package name.levering.ryan.sparql.extensions.fpredicates;
 
 import java.util.Collection;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -42,7 +43,7 @@
 	 * @return a binding set according to the function
 	 */
 	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
+			Collection namedDatasets, Map knownValues, Map knownFilters) {
 		
 		return this.function.getBindingSet(this.data.getSubjectExpression(), this.data.getObjectExpression(), source);
 	}
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/extensions/with/DefaultWithConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/extensions/with/DefaultWithConstraintLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/extensions/with/DefaultWithConstraintLogic.java	2006-07-16 19:04:04.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/extensions/with/DefaultWithConstraintLogic.java	2006-08-01 12:51:40.000000000 -0400
@@ -1,6 +1,7 @@
 package name.levering.ryan.sparql.extensions.with;
 
 import java.util.Collection;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -44,7 +45,7 @@
 	 * @return the binding set created by the extension
 	 */
 	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
+			Collection namedDatasets, Map knownValues, Map knownFilters) {
 		return this.extension.getBindingSet((ExpressionLogic[]) this.data.getArguments().toArray(
 				new ExpressionLogic[] {}), source);
 	}
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/BNodeRenamingConstructQueryLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/BNodeRenamingConstructQueryLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/BNodeRenamingConstructQueryLogic.java	2006-07-16 19:04:04.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/BNodeRenamingConstructQueryLogic.java	2006-08-01 12:27:53.000000000 -0400
@@ -94,7 +94,7 @@
 		int offset = this.data.getOffset();
 
 		// First bind the result table
-		RdfBindingSet results = constraint.constrain(new RdfBindingSetImpl(), source, defaultDatasets, namedDatasets);
+		RdfBindingSet results = constraint.constrain(new RdfBindingSetImpl(), source, defaultDatasets, namedDatasets, null, null);
 
 		// Now apply ordering in reverse order to give priority to the first
 		// variable
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/debug/FilterConstraintDebug.java work-copy/src/main/name/levering/ryan/sparql/logic/debug/FilterConstraintDebug.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/debug/FilterConstraintDebug.java	2006-07-16 19:04:02.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/debug/FilterConstraintDebug.java	2006-08-01 12:34:06.000000000 -0400
@@ -1,6 +1,7 @@
 package name.levering.ryan.sparql.logic.debug;
 
 import java.util.Collection;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -20,10 +21,10 @@
 	}
 	
 	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
+			Collection namedDatasets, Map knownValues, Map knownFilters) {
         this.out.filterConstraintPreExecute(this.data, bindings);
         long start = System.currentTimeMillis();
-        RdfBindingSet returnSet = this.filterLogic.constrain(bindings, source, defaultDatasets, namedDatasets);
+        RdfBindingSet returnSet = this.filterLogic.constrain(bindings, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
         long end = System.currentTimeMillis();
         this.out.filterConstraintPostExecute(end-start, returnSet);
         return returnSet;
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/debug/GraphConstraintDebug.java work-copy/src/main/name/levering/ryan/sparql/logic/debug/GraphConstraintDebug.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/debug/GraphConstraintDebug.java	2006-07-16 19:04:04.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/debug/GraphConstraintDebug.java	2006-08-01 12:34:34.000000000 -0400
@@ -1,6 +1,7 @@
 package name.levering.ryan.sparql.logic.debug;
 
 import java.util.Collection;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -17,10 +18,10 @@
 	}
 
 	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
+			Collection namedDatasets, Map knownValues, Map knownFilters) {
         this.out.graphConstraintPreExecute();
         long start = System.currentTimeMillis();
-        RdfBindingSet returnSet = this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+        RdfBindingSet returnSet = this.logic.constrain(bindings, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
         long end = System.currentTimeMillis();
         this.out.graphConstraintPostExecute(end-start, returnSet);
         return returnSet;
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/debug/GroupConstraintDebug.java work-copy/src/main/name/levering/ryan/sparql/logic/debug/GroupConstraintDebug.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/debug/GroupConstraintDebug.java	2006-07-16 19:04:06.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/debug/GroupConstraintDebug.java	2006-08-01 12:34:25.000000000 -0400
@@ -1,6 +1,7 @@
 package name.levering.ryan.sparql.logic.debug;
 
 import java.util.Collection;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -17,10 +18,10 @@
 	}
 
 	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
+			Collection namedDatasets, Map knownValues, Map knownFilters) {
         this.out.groupConstraintPreExecute();
         long start = System.currentTimeMillis();
-        RdfBindingSet returnSet = this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+        RdfBindingSet returnSet = this.logic.constrain(bindings, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
         long end = System.currentTimeMillis();
         this.out.groupConstraintPostExecute(end-start, returnSet);
         return returnSet;
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/debug/OptionalConstraintDebug.java work-copy/src/main/name/levering/ryan/sparql/logic/debug/OptionalConstraintDebug.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/debug/OptionalConstraintDebug.java	2006-07-16 19:04:04.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/debug/OptionalConstraintDebug.java	2006-08-01 12:34:54.000000000 -0400
@@ -1,6 +1,7 @@
 package name.levering.ryan.sparql.logic.debug;
 
 import java.util.Collection;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -17,10 +18,10 @@
 	}
 
 	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
+			Collection namedDatasets, Map knownValues, Map knownFilters) {
         this.out.optionalConstraintPreExecute();
         long start = System.currentTimeMillis();
-        RdfBindingSet returnSet = this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+        RdfBindingSet returnSet = this.logic.constrain(bindings, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
         long end = System.currentTimeMillis();
         this.out.optionalConstraintPostExecute(end-start, returnSet);
         return returnSet;
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/debug/TripleConstraintDebug.java work-copy/src/main/name/levering/ryan/sparql/logic/debug/TripleConstraintDebug.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/debug/TripleConstraintDebug.java	2006-07-16 19:04:02.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/debug/TripleConstraintDebug.java	2006-08-01 12:35:29.000000000 -0400
@@ -6,6 +6,7 @@
 package name.levering.ryan.sparql.logic.debug;
 
 import java.util.Collection;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -25,10 +26,10 @@
     }
 
     public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source,
-            Collection defaultDatasets, Collection namedDatasets) {
+            Collection defaultDatasets, Collection namedDatasets, Map knownValues, Map knownFilters) {
         this.out.tripleFetchPreExecute(this.data);
         long start = System.currentTimeMillis();
-        RdfBindingSet returnSet = this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+        RdfBindingSet returnSet = this.logic.constrain(bindings, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
         long end = System.currentTimeMillis();
         this.out.tripleFetchPostExecute(end-start, returnSet);
         return returnSet;
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/debug/UnionConstraintDebug.java work-copy/src/main/name/levering/ryan/sparql/logic/debug/UnionConstraintDebug.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/debug/UnionConstraintDebug.java	2006-07-16 19:04:02.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/debug/UnionConstraintDebug.java	2006-08-01 12:35:45.000000000 -0400
@@ -1,6 +1,7 @@
 package name.levering.ryan.sparql.logic.debug;
 
 import java.util.Collection;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -17,10 +18,10 @@
 	}
 
 	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
+			Collection namedDatasets, Map knownValues, Map knownFilters) {
         this.out.unionConstrainPreExecute();
         long start = System.currentTimeMillis();
-        RdfBindingSet returnSet = this.unionLogic.constrain(bindings, source, defaultDatasets, namedDatasets);
+        RdfBindingSet returnSet = this.unionLogic.constrain(bindings, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
         long end = System.currentTimeMillis();
         this.out.unionConstraintPostExecute(end-start, returnSet);
         return returnSet;
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/DefaultAskQueryLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/DefaultAskQueryLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/DefaultAskQueryLogic.java	2006-07-16 19:04:06.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/DefaultAskQueryLogic.java	2006-08-01 12:26:33.000000000 -0400
@@ -55,7 +55,7 @@
 
         // First bind the result table
         RdfBindingSet results = constraint.constrain(new RdfBindingSetImpl(),
-                source, defaultDatasets, namedDatasets);
+                source, defaultDatasets, namedDatasets, null, null);
 
         // Return whether or not the iterator returns any rows
         return results.iterator().hasNext();
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/DefaultConstructQueryLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/DefaultConstructQueryLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/DefaultConstructQueryLogic.java	2006-07-16 19:04:06.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/DefaultConstructQueryLogic.java	2006-08-01 12:28:15.000000000 -0400
@@ -29,6 +29,7 @@
 import org.openrdf.model.BNode;
 import org.openrdf.model.URI;
 import org.openrdf.model.Value;
+import org.openrdf.model.BNode;
 
 /**
  * This query logic constructs an RDF graph by applying an RDF template to a set
@@ -88,7 +89,7 @@
 
         // First bind the result table
         RdfBindingSet results = constraint.constrain(new RdfBindingSetImpl(),
-                source, defaultDatasets, namedDatasets);
+                source, defaultDatasets, namedDatasets, null, null);
 
         // Now apply ordering in reverse order to give priority to the first
         // variable
@@ -104,10 +105,27 @@
         if (offset >= 0) {
             results = this.rangeLogic.offset(results, offset);
         }
-
+		
+		// Each solution gets its own binding for bnodes.  Collect a list of the bnodes
+		// in the construct graph.
+		HashMap bnodeMap = new HashMap();
+		for (Iterator i = data.getTriples().iterator(); i.hasNext();) {
+			TripleConstraint triple = (TripleConstraint) i.next();
+			Object subject = triple.getSubjectExpression();
+			Object verb = triple.getPredicateExpression();
+			Object object = triple.getObjectExpression();
+			if (subject instanceof BNode) bnodeMap.put(subject, null);
+			if (verb instanceof BNode) bnodeMap.put(verb, null);
+			if (object instanceof BNode) bnodeMap.put(object, null);
+		}
+	
         // Now apply the solutions to the template
         RdfGraphImpl graph = new RdfGraphImpl();
         for (Iterator solutions = results.iterator(); solutions.hasNext();) {
+			// Set up new bnode instances for bnodes in the construct graph.
+			for (Iterator bnodes = bnodeMap.keySet().iterator(); bnodes.hasNext(); )
+				bnodeMap.put(bnodes.next(), source.getValueFactory().createBNode());
+			
             RdfBindingRow row = (RdfBindingRow) solutions.next();
             Map blankNodeMap = new HashMap();
             for (Iterator i = this.data.getTriples().iterator(); i.hasNext();) {
@@ -156,6 +174,10 @@
                     continue;
                 }
 
+				if (bnodeMap.containsKey(subject)) subject = (Value)bnodeMap.get(subject);
+				//if (bnodeMap.containsKey(verb)) verb = (Value)bnodeMap.get(verb);
+				if (bnodeMap.containsKey(object)) object = (Value)bnodeMap.get(object);
+				
                 graph.addTriple(new StatementImpl(subject, verb, object));
             }
         }
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/DefaultDescribeQueryLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/DefaultDescribeQueryLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/DefaultDescribeQueryLogic.java	2006-07-16 19:04:04.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/DefaultDescribeQueryLogic.java	2006-08-02 07:14:52.000000000 -0400
@@ -93,7 +93,7 @@
 		int offset = this.data.getOffset();
 
 		// First bind the result table
-		RdfBindingSet results = constraint.constrain(new RdfBindingSetImpl(), source, defaultDatasets, namedDatasets);
+		RdfBindingSet results = constraint.constrain(new RdfBindingSetImpl(), source, defaultDatasets, namedDatasets, null, null);
 
 		// Now project to the solution set
 		List variables = new ArrayList();
@@ -106,7 +106,7 @@
 		results = this.logic.project(results, variables);
 
 		// Now apply ordering in reverse order
-		for (int i = orderExpressions.size(); i >= 0; i--) {
+		for (int i = orderExpressions.size()-1; i >= 0; i--) {
 			OrderExpressionLogic orderer = (OrderExpressionLogic) orderExpressions.get(i);
 			orderer.order(results);
 		}
@@ -182,7 +182,7 @@
 					descriptions.addAll(describe(statement.getObject(), source, alreadyDescribed));
 				}
 			}
-			descriptions.add(statements.next());
+			descriptions.add(statement);
 		}
 		return descriptions;
 	}
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/DefaultSelectQueryLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/DefaultSelectQueryLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/DefaultSelectQueryLogic.java	2006-07-16 19:04:06.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/DefaultSelectQueryLogic.java	2006-08-01 12:30:05.000000000 -0400
@@ -86,7 +86,7 @@
 
         // First bind the result table
         RdfBindingSet results = constraint.constrain(null,
-                source, defaultDatasets, namedDatasets);
+                source, defaultDatasets, namedDatasets, null, null);
 
         // Now project to the solution set
         if (queryExpressions != null) {
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/expression/GreaterThanEqualsLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/expression/GreaterThanEqualsLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/expression/GreaterThanEqualsLogic.java	2006-07-16 19:04:02.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/expression/GreaterThanEqualsLogic.java	2006-07-30 09:08:08.000000000 -0400
@@ -96,11 +96,10 @@
      * 
      * @param string1 the first String to compare
      * @param string2 the second String to compare
-     * @return never
-     * @throws UnsupportedOperationException always
+     * @return true if the first string is greater than or equal to the second
      */
     public boolean evaluateString(String string1, String string2) {
-        throw new UnsupportedOperationException("Strings cannot be compared using a >= operation");
+        return string1.compareTo(string2) >= 0;
     }
 
     /**
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/expression/GreaterThanLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/expression/GreaterThanLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/expression/GreaterThanLogic.java	2006-07-16 19:04:06.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/expression/GreaterThanLogic.java	2006-07-30 09:08:08.000000000 -0400
@@ -96,11 +96,10 @@
      * 
      * @param string1 the first String to compare
      * @param string2 the second String to compare
-     * @return never
-     * @throws UnsupportedOperationException always
+     * @return true if the first string is greater than the second
      */
     public boolean evaluateString(String string1, String string2) {
-        throw new UnsupportedOperationException("Strings cannot be compared using a > operation");
+        return string1.compareTo(string2) > 0;
     }
 
     /**
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/expression/LessThanEqualsLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/expression/LessThanEqualsLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/expression/LessThanEqualsLogic.java	2006-07-16 19:04:04.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/expression/LessThanEqualsLogic.java	2006-07-30 09:08:08.000000000 -0400
@@ -96,11 +96,10 @@
      * 
      * @param string1 the first String to compare
      * @param string2 the second String to compare
-     * @return never
-     * @throws UnsupportedOperationException always
+     * @return true if the first string is less than or equal to the second
      */
     public boolean evaluateString(String string1, String string2) {
-        throw new UnsupportedOperationException("Strings cannot be compared using a <= operation");
+        return string1.compareTo(string2) <= 0;
     }
 
     /**
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/expression/LessThanLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/expression/LessThanLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/expression/LessThanLogic.java	2006-07-16 19:04:04.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/expression/LessThanLogic.java	2006-07-30 09:08:08.000000000 -0400
@@ -96,11 +96,10 @@
      * 
      * @param string1 the first String to compare
      * @param string2 the second String to compare
-     * @return never
-     * @throws UnsupportedOperationException always
+     * @return true if the first string is less than the second
      */
     public boolean evaluateString(String string1, String string2) {
-        throw new UnsupportedOperationException("Fix this");
+        return string1.compareTo(string2) < 0;
     }
     
     /**
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/function/BoundLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/BoundLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/function/BoundLogic.java	2006-07-16 19:04:04.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/BoundLogic.java	2006-08-01 10:43:33.000000000 -0400
@@ -23,12 +23,7 @@
  * @author Ryan Levering
  * @version 1.0
  */
-public class BoundLogic implements ExpressionLogic {
-
-    /**
-     * The data holding the arguments of the bound function.
-     */
-    private final CallExpressionData data;
+public class BoundLogic extends FunctionLogic {
 
     /**
      * The logic to return the correct boolean value.
@@ -43,7 +38,7 @@
      */
     public BoundLogic(CallExpressionData data, ValueConversionLogic converter) {
         //TODO Check for whether the argument is a variable
-        this.data = data;
+        super(data);
         this.converter = converter;
     }
 
@@ -58,5 +53,5 @@
         boolean result = (bindings.getValue(variable) != null);
         return this.converter.convertBoolean(result);
     }
-
+ 
 }
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/function/DataTypeLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/DataTypeLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/function/DataTypeLogic.java	2006-07-16 19:04:04.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/DataTypeLogic.java	2006-08-01 10:44:08.000000000 -0400
@@ -21,22 +21,17 @@
  * @author Ryan Levering
  * @version 1.0
  */
-public class DataTypeLogic implements ExpressionLogic {
+public class DataTypeLogic extends FunctionLogic {
 
-	/**
-	 * The data holding the argument to evaluate.
-	 */
-	private final CallExpressionData data;
-
-	/**
-	 * Creates a new logic object that returns the IRI of the datatype of a
-	 * particular typed literal.
-	 * 
-	 * @param data the argument data
-	 */
-	public DataTypeLogic(CallExpressionData data) {
-		this.data = data;
-	}
+    /**
+     * Creates a new logic object that returns the IRI of the datatype of a
+     * particular typed literal.
+     * 
+     * @param data the argument data
+     */
+    public DataTypeLogic(CallExpressionData data) {
+        super(data);
+    }
 
 	/**
 	 * Evaluates the datatype of a typed literal that is an argument.
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/function/DecimalCastFunction.java work-copy/src/main/name/levering/ryan/sparql/logic/function/DecimalCastFunction.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/function/DecimalCastFunction.java	2006-07-16 19:04:06.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/DecimalCastFunction.java	2006-07-30 09:13:49.000000000 -0400
@@ -144,11 +144,11 @@
      */
     public Value castLiteral(Literal literal) throws IllegalCastException {
         try {
-            Long.parseLong(literal.getLabel());
+            Double.parseDouble(literal.getLabel());
             return this.factory.createLiteral(literal.getLabel(),
                     SPARQLConstants.DECIMAL_TYPE);
         } catch (NumberFormatException e) {
-            throw new IllegalCastException("Unable to cast string to integer");
+            throw new IllegalCastException("Unable to cast string to double");
         }
     }
     
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/function/ExternalFunctionLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/ExternalFunctionLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/function/ExternalFunctionLogic.java	2006-07-16 19:04:06.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/ExternalFunctionLogic.java	2006-08-01 10:57:49.000000000 -0400
@@ -23,34 +23,29 @@
  * @author Ryan Levering
  * @version 1.1
  */
-public class ExternalFunctionLogic implements ExpressionLogic {
+public class ExternalFunctionLogic extends FunctionLogic {
 
-	/**
-	 * The data containing the argument expressions to evaluate
-	 */
-	private final CallExpressionData data;
-
-	/**
-	 * The function to delegate the logic to.
-	 */
-	private final ExternalFunction function;
-
-	/**
-	 * The factory that's used to convert returns into SPARQL values.
-	 */
-	private final SPARQLValueFactory factory;
-
-	/**
-	 * Creates a new external function logic that evaluates a function call to
-	 * produce a Value.
-	 * 
-	 * @param data the data containing the function arguments and it's name
-	 */
-	public ExternalFunctionLogic(CallExpressionData data, ExternalFunction function, SPARQLValueFactory factory) {
-		this.data = data;
-		this.function = function;
-		this.factory = factory;
-	}
+    /**
+     * The function to delegate the logic to.
+     */
+    private final ExternalFunction function;
+
+    /**
+     * The factory that's used to convert returns into SPARQL values.
+     */
+    private SPARQLValueFactory factory;
+    
+    /**
+     * Creates a new external function logic that evaluates a function call to
+     * produce a Value.
+     * 
+     * @param data the data containing the function arguments and it's name
+     */
+    public ExternalFunctionLogic(CallExpressionData data, ExternalFunction function, SPARQLValueFactory factory) {
+        super(data);
+        this.function = function;
+        this.factory = factory;
+    }
 
 	/**
 	 * Evaluates the function by evaluating the arguments and passing them to
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/function/FunctionLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/FunctionLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/function/FunctionLogic.java	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/FunctionLogic.java	2006-08-02 07:51:15.000000000 -0400
@@ -0,0 +1,41 @@
+/*
+ * SPARQL Engine
+ * Copyright (C) 2005 Ryan Levering, All rights reserved.
+ * See LICENSE for full license information
+ */
+package name.levering.ryan.sparql.logic.function;
+
+import java.util.Iterator;
+import java.util.Set;
+
+import name.levering.ryan.sparql.common.RdfBindingRow;
+import name.levering.ryan.sparql.common.Variable;
+import name.levering.ryan.sparql.model.data.CallExpressionData;
+import name.levering.ryan.sparql.model.logic.ExpressionLogic;
+import name.levering.ryan.sparql.model.logic.ValueConversionLogic;
+
+import org.openrdf.model.Value;
+
+/**
+ * The base class of function-type logics.
+ * 
+ * @author Ryan Levering
+ * @version 1.0
+ */
+public abstract class FunctionLogic implements ExpressionLogic {
+
+    /**
+     * The data holding the arguments of the bound function.
+     */
+    protected CallExpressionData data;
+
+    /**
+     * Creates a new logic object that handles sop:bound function calls.
+     * 
+     * @param data the data holding the expression arguments to evaluate
+     * @param converter
+     */
+    public FunctionLogic(CallExpressionData data) {
+        this.data = data;
+    }
+}
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/function/IsBlankLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/IsBlankLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/function/IsBlankLogic.java	2006-07-16 19:04:06.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/IsBlankLogic.java	2006-08-01 10:41:22.000000000 -0400
@@ -21,30 +21,23 @@
  * @author Ryan Levering
  * @version 1.0
  */
-public class IsBlankLogic implements ExpressionLogic {
-
-	/**
-	 * The data that holds the argument to evaluate for blank node.
-	 */
-	private final CallExpressionData data;
-
+public class IsBlankLogic extends FunctionLogic {
 	/**
 	 * The converter used to return the true or false value.
 	 */
 	private final ValueConversionLogic converter;
 
-	/**
-	 * Creates a new logic object that can evaluate whether a bound variable or
-	 * value is a blank node.
-	 * 
-	 * @param data the data holding the argument for evaluation
-	 * @param converter the value conversion logic to convert the boolean to a
-	 *            literal
-	 */
-	public IsBlankLogic(CallExpressionData data, ValueConversionLogic converter) {
-		this.data = data;
-		this.converter = converter;
-	}
+    /**
+     * Creates a new logic object that can evaluate whether a bound variable or
+     * value is a blank node.
+     * 
+     * @param data the data holding the argument for evaluation
+     * @param converter the value conversion logic to convert the boolean to a literal
+     */
+    public IsBlankLogic(CallExpressionData data, ValueConversionLogic converter) {
+        super(data);
+        this.converter = converter;
+    }
 
 	/**
 	 * Evaluates whether the value returned by an expression is a blank node.
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/function/IsIRILogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/IsIRILogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/function/IsIRILogic.java	2006-07-16 19:04:02.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/IsIRILogic.java	2006-08-01 10:42:44.000000000 -0400
@@ -21,38 +21,30 @@
  * @author Ryan Levering
  * @version 1.0
  */
-public class IsIRILogic implements ExpressionLogic {
-
-	/**
-	 * The data that holds the argument to evaluate for IRI.
-	 */
-	private final CallExpressionData data;
-
-	/**
-	 * The converter used to return the true or false value.
-	 */
-	private final ValueConversionLogic converter;
-
-	/**
-	 * Creates a new logic object that can evaluate whether a bound variable or
-	 * value is an IRI.
-	 * 
-	 * @param data the data holding the argument for evaluation
-	 * @param converter the value conversion logic to convert the boolean to a
-	 *            literal
-	 */
-	public IsIRILogic(CallExpressionData data, ValueConversionLogic converter) {
-		this.data = data;
-		this.converter = converter;
-	}
-
-	/**
-	 * Evaluates whether the value returned by an expression is an IRI.
-	 * 
-	 * @param bindings the value bindings to use in argument evaluation
-	 * @return true or false literals representing whether the argument is an
-	 *         IRI
-	 */
+public class IsIRILogic extends FunctionLogic {
+    /**
+     * The converter used to return the true or false value.
+     */
+    private final ValueConversionLogic converter;
+    
+    /**
+     * Creates a new logic object that can evaluate whether a bound variable or
+     * value is an IRI.
+     * 
+     * @param data the data holding the argument for evaluation
+     * @param converter the value conversion logic to convert the boolean to a literal
+     */
+    public IsIRILogic(CallExpressionData data, ValueConversionLogic converter) {
+        super(data);
+        this.converter = converter;
+    }
+    
+    /**
+     * Evaluates whether the value returned by an expression is an IRI.
+     * 
+     * @param bindings the value bindings to use in argument evaluation
+     * @return true or false literals representing whether the argument is an IRI
+     */
 	public Value evaluate(RdfBindingRow bindings) {
 		ExpressionLogic expression = (ExpressionLogic) this.data.getArguments().get(0);
 		Object value = expression.evaluate(bindings);
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/function/IsLiteralLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/IsLiteralLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/function/IsLiteralLogic.java	2006-07-16 19:04:04.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/IsLiteralLogic.java	2006-08-01 10:42:16.000000000 -0400
@@ -21,38 +21,31 @@
  * @author Ryan Levering
  * @version 1.0
  */
-public class IsLiteralLogic implements ExpressionLogic {
-
-	/**
-	 * The data that holds the argument to evaluate for literal.
-	 */
-	private final CallExpressionData data;
-
-	/**
-	 * The converter used to return the true or false value.
-	 */
-	private final ValueConversionLogic converter;
-
-	/**
-	 * Creates a new logic object that can evaluate whether a bound variable or
-	 * value is a literal.
-	 * 
-	 * @param data the data holding the argument for evaluation
-	 * @param converter the value conversion logic to convert the boolean to a
-	 *            literal
-	 */
-	public IsLiteralLogic(CallExpressionData data, ValueConversionLogic converter) {
-		this.data = data;
-		this.converter = converter;
-	}
-
-	/**
-	 * Evaluates whether the value returned by an expression is a literal.
-	 * 
-	 * @param bindings the value bindings to use in argument evaluation
-	 * @return true or false literals representing whether the argument is an
-	 *         literal
-	 */
+public class IsLiteralLogic extends FunctionLogic {
+   
+    /**
+     * The converter used to return the true or false value.
+     */
+    private final ValueConversionLogic converter;
+    
+    /**
+     * Creates a new logic object that can evaluate whether a bound variable or
+     * value is a literal.
+     * 
+     * @param data the data holding the argument for evaluation
+     * @param converter the value conversion logic to convert the boolean to a literal
+     */
+    public IsLiteralLogic(CallExpressionData data, ValueConversionLogic converter) {
+        super(data);
+        this.converter = converter;
+    }
+    
+    /**
+     * Evaluates whether the value returned by an expression is a literal.
+     * 
+     * @param bindings the value bindings to use in argument evaluation
+     * @return true or false literals representing whether the argument is an literal
+     */
 	public Value evaluate(RdfBindingRow bindings) {
 		ExpressionLogic expression = (ExpressionLogic) this.data.getArguments().get(0);
 		Object value = expression.evaluate(bindings);
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/function/LangLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/LangLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/function/LangLogic.java	2006-07-16 19:04:04.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/LangLogic.java	2006-08-01 10:40:50.000000000 -0400
@@ -21,30 +21,22 @@
  * @author Ryan Levering
  * @version 1.0
  */
-public class LangLogic implements ExpressionLogic {
-
-	/**
-	 * The data that holds the argument to evaluate for literal language.
-	 */
-	private final CallExpressionData data;
-
+public class LangLogic extends FunctionLogic {
 	/**
 	 * The converter used to return the string value.
 	 */
 	private final ValueConversionLogic converter;
 
-	/**
-	 * Creates a new logic object that can return the language of a given
-	 * literal.
-	 * 
-	 * @param data the data holding the argument for evaluation
-	 * @param converter the value conversion logic to convert the string to a
-	 *            literal
-	 */
-	public LangLogic(CallExpressionData data, ValueConversionLogic converter) {
-		this.data = data;
-		this.converter = converter;
-	}
+   /**
+    * Creates a new logic object that can return the language of a given literal.
+    * 
+    * @param data the data holding the argument for evaluation
+    * @param converter the value conversion logic to convert the string to a literal
+    */
+    public LangLogic(CallExpressionData data, ValueConversionLogic converter) {
+        super(data);
+        this.converter = converter;
+    }
 
 	/**
 	 * Returns the language of a language tagged literal.
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/function/LangMatchesLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/LangMatchesLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/function/LangMatchesLogic.java	2006-07-16 19:04:02.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/LangMatchesLogic.java	2006-08-01 12:40:37.000000000 -0400
@@ -21,14 +21,7 @@
  * @author Ryan Levering
  * @version 1.0
  */
-public class LangMatchesLogic implements ExpressionLogic {
-
-	/**
-	 * The data that holds the arguments to evaluate for language range and
-	 * literal to match.
-	 */
-	private final CallExpressionData data;
-
+public class LangMatchesLogic extends FunctionLogic {
 	/**
 	 * The converter used to return the boolean value.
 	 */
@@ -43,7 +36,7 @@
 	 *            literal
 	 */
 	public LangMatchesLogic(CallExpressionData data, ValueConversionLogic converter) {
-		this.data = data;
+		super(data);
 		this.converter = converter;
 	}
 
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/function/RegexLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/RegexLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/function/RegexLogic.java	2006-07-16 19:04:02.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/RegexLogic.java	2006-08-01 10:45:58.000000000 -0400
@@ -25,31 +25,25 @@
  * @author Ryan Levering
  * @version 1.1
  */
-public class RegexLogic implements ExpressionLogic {
-
-	/**
-	 * The data that holds the argument to evaluate for string matching.
-	 */
-	private final CallExpressionData data;
-
-	/**
-	 * The converter used to return the boolean literal and convert the string
-	 * value.
-	 */
-	private final ValueConversionLogic converter;
-
-	/**
-	 * Creates a new logic object that can evaluate whether one string occurs in
-	 * another.
-	 * 
-	 * @param data the data holding the argument for evaluation
-	 * @param converter the value conversion logic to convert the result to a
-	 *            literal and the strings to Java strings
-	 */
-	public RegexLogic(CallExpressionData data, ValueConversionLogic converter) {
-		this.data = data;
-		this.converter = converter;
-	}
+public class RegexLogic extends FunctionLogic {
+    /**
+     * The converter used to return the boolean literal and convert the string
+     * value.
+     */
+    private final ValueConversionLogic converter;
+
+    /**
+     * Creates a new logic object that can evaluate whether one string occurs in
+     * another.
+     * 
+     * @param data the data holding the argument for evaluation
+     * @param converter the value conversion logic to convert the result to a
+     *            literal and the strings to Java strings
+     */
+    public RegexLogic(CallExpressionData data, ValueConversionLogic converter) {
+        super(data);
+        this.converter = converter;
+    }
 
 	/**
 	 * Converts the evaluated arguments to strings and uses Java string matching
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/function/StrLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/StrLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/function/StrLogic.java	2006-07-16 19:04:04.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/StrLogic.java	2006-08-01 11:20:00.000000000 -0400
@@ -23,28 +23,22 @@
  * @author Ryan Levering
  * @version 1.2
  */
-public class StrLogic implements ExpressionLogic {
-
-	/**
-	 * The data that holds the argument to evaluate for string conversion.
-	 */
-	private final CallExpressionData data;
-
-	/**
-	 * The factory used to create new string literals.
-	 */
-	private final SPARQLValueFactory factory;
-
-	/**
-	 * Creates a new logic object that can evaluate the string representation of
-	 * a IRI or literal.
-	 * 
-	 * @param data the data holding the argument for evaluation
-	 */
-	public StrLogic(CallExpressionData data, SPARQLValueFactory factory) {
-		this.data = data;
-		this.factory = factory;
-	}
+public class StrLogic extends FunctionLogic {
+    /**
+     * The factory used to create new string literals.
+     */
+    private final SPARQLValueFactory factory;
+
+    /**
+     * Creates a new logic object that can evaluate the string representation of
+     * a IRI or literal.
+     * 
+     * @param data the data holding the argument for evaluation
+     */
+    public StrLogic(CallExpressionData data, SPARQLValueFactory factory) {
+        super(data);
+        this.factory = factory;
+    }
 
 	/**
 	 * Evaluates the argument to the function and does simplistic conversion to
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/naive/DefaultFilterConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultFilterConstraintLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/naive/DefaultFilterConstraintLogic.java	2006-07-16 19:04:02.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultFilterConstraintLogic.java	2006-08-01 12:41:27.000000000 -0400
@@ -8,6 +8,7 @@
 import java.util.Collection;
 import java.util.Collections;
 import java.util.Iterator;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingRow;
 import name.levering.ryan.sparql.common.RdfBindingSet;
@@ -75,7 +76,7 @@
      * @return a binding set with values that pass through the filter expression
      */
     public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source,
-            Collection defaultDatasets, Collection namedDatasets) {
+            Collection defaultDatasets, Collection namedDatasets, Map knownValues, Map knownFilters) {
         // Grab the necessary fields from the data
         ExpressionLogic filterExpression = this.data.getExpression();
 
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/naive/DefaultGroupConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultGroupConstraintLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/naive/DefaultGroupConstraintLogic.java	2006-07-16 19:04:06.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultGroupConstraintLogic.java	2006-08-01 12:47:14.000000000 -0400
@@ -9,6 +9,7 @@
 import java.util.Iterator;
 import java.util.LinkedList;
 import java.util.List;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -74,12 +75,12 @@
 	 *            query, passed on to subconstraints
 	 */
 	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
-		return this.constrain(bindings, source, defaultDatasets, namedDatasets, true);
+			Collection namedDatasets, Map knownValues, Map knownFilters) {
+		return this.constrain(bindings, source, defaultDatasets, namedDatasets, knownValues, knownFilters, true);
 	}
 
 	private RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets, boolean withFilter) {
+			Collection namedDatasets, Map knownValues, Map knownFilters, boolean withFilter) {
 
 		List filterQueue = new LinkedList();
 		List optionalQueue = new LinkedList();
@@ -99,7 +100,7 @@
 			} else if (c instanceof GraphConstraintData) {
 				graphQueue.add(c);
 			} else {
-				this.orderLogic.addBindingSet(c.constrain(null, source, defaultDatasets, namedDatasets));
+				this.orderLogic.addBindingSet(c.constrain(null, source, defaultDatasets, namedDatasets, knownValues, knownFilters));
 			}
 
 		}
@@ -109,9 +110,9 @@
 		for (Iterator graphs = graphQueue.iterator(); graphs.hasNext();) {
 			ConstraintLogic c = (ConstraintLogic) graphs.next();
 			if (current == null) {
-				current = c.constrain(null, source, defaultDatasets, namedDatasets);
+				current = c.constrain(null, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
 			} else {
-				current = this.logic.intersect(current, c.constrain(current, source, defaultDatasets, namedDatasets));
+				current = this.logic.intersect(current, c.constrain(current, source, defaultDatasets, namedDatasets, knownValues, knownFilters));
 			}
 		}
 
@@ -123,11 +124,11 @@
 
 		for (Iterator optionals = optionalQueue.iterator(); optionals.hasNext();) {
 			ConstraintLogic c = (ConstraintLogic) optionals.next();
-			current = c.constrain(current, source, defaultDatasets, namedDatasets);
+			current = c.constrain(current, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
 		}
 		for (Iterator filters = filterQueue.iterator(); filters.hasNext();) {
 			ConstraintLogic c = (ConstraintLogic) filters.next();
-			current = c.constrain(current, source, defaultDatasets, namedDatasets);
+			current = c.constrain(current, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
 		}
 		return current;
 	}
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/naive/DefaultOptionalConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultOptionalConstraintLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/naive/DefaultOptionalConstraintLogic.java	2006-07-16 19:04:02.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultOptionalConstraintLogic.java	2006-08-01 12:44:17.000000000 -0400
@@ -9,6 +9,7 @@
 import java.util.Iterator;
 import java.util.LinkedList;
 import java.util.List;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -75,7 +76,7 @@
 	 *            the grouped constraint
 	 */
 	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
+			Collection namedDatasets, Map knownValues, Map knownFilters) {
 		List filterQueue = new LinkedList();
 		List optionalQueue = new LinkedList();
 		List graphQueue = new LinkedList();
@@ -94,7 +95,7 @@
 			} else if (c instanceof GraphConstraint) {
 				graphQueue.add(c);
 			} else {
-				this.orderLogic.addBindingSet(c.constrain(null, source, defaultDatasets, namedDatasets));
+				this.orderLogic.addBindingSet(c.constrain(null, source, defaultDatasets, namedDatasets, knownValues, knownFilters));
 			}
 
 		}
@@ -104,10 +105,10 @@
 		for (Iterator graphs = graphQueue.iterator(); graphs.hasNext();) {
 			ConstraintLogic c = (ConstraintLogic) graphs.next();
 			if (current == null) {
-				current = c.constrain(null, source, defaultDatasets, namedDatasets);
+				current = c.constrain(null, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
 			} else {
 				current = this.intersectLogic.intersect(current, c.constrain(current, source, defaultDatasets,
-						namedDatasets));
+						namedDatasets, knownValues, knownFilters));
 			}
 		}
 
@@ -119,7 +120,7 @@
 
 		for (Iterator optionals = optionalQueue.iterator(); optionals.hasNext();) {
 			ConstraintLogic c = (ConstraintLogic) optionals.next();
-			current = c.constrain(current, source, defaultDatasets, namedDatasets);
+			current = c.constrain(current, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
 		}
 		
 		return this.logic.join(bindings, current, filterQueue);
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/naive/DefaultTripleConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultTripleConstraintLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/naive/DefaultTripleConstraintLogic.java	2006-07-16 19:04:02.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultTripleConstraintLogic.java	2006-08-01 12:44:58.000000000 -0400
@@ -9,6 +9,7 @@
 import java.util.Collection;
 import java.util.Iterator;
 import java.util.List;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.GraphStatement;
 import name.levering.ryan.sparql.common.LenientStatement;
@@ -64,7 +65,7 @@
      * 
      */
     public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source,
-            Collection defaultDatasets, Collection namedDatasets) {
+            Collection defaultDatasets, Collection namedDatasets, Map knownValues, Map knownFilters) {
 
         ExpressionLogic subExpr = this.data.getSubjectExpression();
         ExpressionLogic predExpr = this.data.getPredicateExpression();
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/naive/DefaultUnionConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultUnionConstraintLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/naive/DefaultUnionConstraintLogic.java	2006-07-16 19:04:06.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultUnionConstraintLogic.java	2006-08-01 12:47:41.000000000 -0400
@@ -7,6 +7,7 @@
 
 import java.util.Collection;
 import java.util.Iterator;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -63,14 +64,14 @@
 	 *         constraints
 	 */
 	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
+			Collection namedDatasets, Map knownValues, Map knownFilters) {
 		RdfBindingSet current = null;
 		for (Iterator groupOrUnions = this.data.getConstraints().iterator(); groupOrUnions.hasNext();) {
 			ConstraintLogic group = (ConstraintLogic) groupOrUnions.next();
 			if (current == null) {
-				current = group.constrain(current, source, defaultDatasets, namedDatasets);
+				current = group.constrain(current, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
 			} else {
-				current = this.logic.union(current, group.constrain(current, source, defaultDatasets, namedDatasets));
+				current = this.logic.union(current, group.constrain(current, source, defaultDatasets, namedDatasets, knownValues, knownFilters));
 			}
 		}
 
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/streamed/AdvancedGroupConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/streamed/AdvancedGroupConstraintLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/streamed/AdvancedGroupConstraintLogic.java	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/streamed/AdvancedGroupConstraintLogic.java	2006-08-21 22:49:00.000000000 -0400
@@ -0,0 +1,530 @@
+/*
+ * SPARQL Engine
+ * Copyright (C) 2005 Ryan Levering, All rights reserved.
+ * See LICENSE for full license information
+ */
+package name.levering.ryan.sparql.logic;
+
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+
+import org.openrdf.model.URI;
+import org.openrdf.model.BNode;
+import org.openrdf.model.Literal;
+import org.openrdf.model.Value;
+
+import name.levering.ryan.sparql.common.impl.AbstractRdfBindingRow;
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfBindingRow;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.common.Variable;
+import name.levering.ryan.sparql.common.impl.RdfBindingSetImpl;
+import name.levering.ryan.sparql.logic.function.ExternalFunctionLogic;
+import name.levering.ryan.sparql.model.TripleConstraint;
+import name.levering.ryan.sparql.model.data.FilterConstraintData;
+import name.levering.ryan.sparql.model.data.GroupConstraintData;
+import name.levering.ryan.sparql.model.data.OptionalConstraintData;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
+import name.levering.ryan.sparql.model.logic.ExpressionLogic;
+import name.levering.ryan.sparql.model.logic.SetIntersectLogic;
+import name.levering.ryan.sparql.parser.model.ASTAndNode;
+import name.levering.ryan.sparql.parser.model.ASTEqualsNode;
+import name.levering.ryan.sparql.parser.model.ASTOrNode;
+import name.levering.ryan.sparql.parser.model.ASTVar;
+import name.levering.ryan.sparql.parser.model.BinaryExpressionNode;
+import name.levering.ryan.sparql.parser.model.DelegatingTripleConstraint;
+import name.levering.ryan.sparql.parser.model.EmptyVisitor;
+import name.levering.ryan.sparql.parser.model.SimpleNode;
+
+/**
+ * This logic is the default logic for the main constraint that is used as an
+ * aggregate of other constraints. TripleConstraints, UnionConstraints, and
+ * GraphConstraints all are intersected with the running binding set. After
+ * that, OptionalConstraints and FilterConstraints modify the set themselves.
+ * 
+ * @author Ryan Levering
+ * @version 1.0
+ */
+public class AdvancedGroupConstraintLogic implements ConstraintLogic {
+
+    /**
+     * The data that holds the constraints that this group constraint
+     * aggregates.
+     */
+    private final GroupConstraintData data;
+
+    /**
+     * This logic that intersects the parts of the graph pattern.
+     */
+    private final SetIntersectLogic logic;
+    
+    private static final Map
+		isFunctional = new HashMap(),
+    	isInverseFunctional = new HashMap();
+    
+    /**
+     * Creates a new default group logic, with the given subconstraints found in
+     * the data.
+     * 
+     * @param data the data holding the subconstraints to bind
+     */
+    public AdvancedGroupConstraintLogic(GroupConstraintData data, SetIntersectLogic logic) {
+        this.logic = logic;
+        this.data = data;
+    }
+
+    /**
+     * Applies each subconstraint in turn, saving filter and optional
+     * constraints for last, as according to specification.
+     * 
+     * @param bindings the current running bindings, ignored here
+     * @param source the source to query RDF triples, passed on to
+     *            subconstraints
+     * @param defaultDatasets the datasets to query by default, passed on to
+     *            subconstraints
+     * @param namedDatasets the named datasets to query in an unbound graph
+     *            query, passed on to subconstraints
+     */
+    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source,
+            Collection defaultDatasets, Collection namedDatasets, Map knownValues, Map knownFilters) {
+	
+		// Build separate lists for the different constraints that this group may contain.
+
+		List tripleConstraints = new LinkedList();
+        List filterQueue = new LinkedList();
+        List optionalQueue = new LinkedList();
+		List otherQueue = new LinkedList();
+
+		// Clone knownValues and knownFilters so we can freely modify it without affecting the caller.
+		
+		if (knownValues == null)
+			knownValues = new HashMap();
+		else
+			knownValues = new HashMap(knownValues);
+			
+		if (knownFilters == null)
+			knownFilters = new HashMap();
+		else
+			knownFilters = new HashMap(knownFilters);
+		
+		// Get a list of variables that have known values, and of those the ones that are really cheap
+		// (i.e. have just a few values).
+		// We'll build these sets in the course of reordering the statements to query most efficiently.
+
+		Set knownVars = new HashSet();
+		Set cheapVars = new HashSet();
+		
+		// Any variables known by groups on top of us are known here, and cheap (I guess).
+		knownVars.addAll(knownValues.keySet());
+		cheapVars.addAll(knownValues.keySet());
+		
+		// Split out the types of constraints and look for filters that tell us interesting things.
+		
+        for (Iterator cons = data.getConstraints().iterator(); cons.hasNext();) {
+            ConstraintLogic c = (ConstraintLogic) cons.next();
+            if (c instanceof OptionalConstraintData) {
+				optionalQueue.add(c);
+            } else if (c instanceof FilterConstraintData) {
+				filterQueue.add(c);
+				
+				FilterConstraintData f = (FilterConstraintData)c;
+				if (f.getExpression() instanceof BinaryExpressionNode) {
+					// If this filter is of the form FILTER(?var = <uri> || ?var = <uri> || ...)
+					// then this is giving us some known values for the variable.
+					BinaryExpressionNode b = (BinaryExpressionNode)f.getExpression();
+					Variable v = getFilterPrimaryVariable(b);
+					if (v != null) {
+						Set values = new HashSet();
+						getFilterValues(b, values);
+						if (!knownValues.containsKey(v)) {
+							knownValues.put(v, values);
+							knownVars.add(v);
+							cheapVars.add(v);
+						} else {
+							Set othervalues = (Set)knownValues.get(v);
+							othervalues.retainAll(values);
+						}
+					}
+				}
+				
+				// This by default does nothing, but subclassors may decide to do things here.
+				extractLiteralFilters(f.getExpression(), knownFilters);
+				
+			} else if (c instanceof TripleConstraint) {
+				tripleConstraints.add(c);
+			} else {
+				otherQueue.add(c);
+			}
+		}
+		
+		// Reorder the triple constraints so that complex constraints are done
+		// after some of their variables have already been evaluated.  This is
+		// a bit N^2-ish in the number of triple constraints, but it can be improved.
+		List constraintOrder = new LinkedList();
+		Set selectedVars = new HashSet();
+		while (tripleConstraints.size() > 0) {
+			TripleConstraint leastConstraint = null;
+			int leastComplexity = -1;
+			
+			if (tripleConstraints.size() == 1) {
+				leastConstraint = (TripleConstraint)tripleConstraints.get(0);
+			} else {
+				for (Iterator cons = tripleConstraints.iterator(); cons.hasNext();) {
+					TripleConstraint c = (TripleConstraint) cons.next();
+					int complexity = getComplexity(c, knownVars, cheapVars, knownFilters, source);
+					if (leastConstraint == null || complexity < leastComplexity) {
+						leastComplexity = complexity;
+						leastConstraint = c;
+					}
+				}
+			}
+			
+			tripleConstraints.remove(leastConstraint);
+			constraintOrder.add(leastConstraint);
+			
+			// Get the variables mentioned in this triple constraint
+			Set constraintVars = new HashSet();
+			getVariables(leastConstraint, constraintVars);
+			
+			// Keep a list of variables that have been selected on so far
+			selectedVars.addAll(constraintVars);
+			
+			// And all of these variables are now considered 'known' for the purposes of
+			// selecting which statement goes next.  But they're not considered 'cheap'.
+			knownVars.addAll(constraintVars);
+			
+			// Well, if this triple was functional or inverse functional, we *can*
+			// consider the variables mentioned in the triple cheap.
+			if (leastComplexity <= 1)
+				cheapVars.addAll(constraintVars);
+			
+			// Perform any filters that are such that all of the
+			// variables mentioned in the filter have already been selected
+			// on.  The earlier we filter the better.  (We have to know not just
+			// which variables are known so far, because ones that are known from
+			// filters may not yet be actually bound in the binding set.  Rather,
+			// we have to know which ones have actually been selected on in a
+			// triple.  Here, we only know what's been selected on in this group,
+			// and not at a higher level.)
+	        for (Iterator filters = filterQueue.iterator(); filters.hasNext();) {
+	        	/*
+	            FilterConstraintData c = (FilterConstraintData) filters.next();
+	            boolean allvarsknown = true;
+	            Set filterVars = getFilterVariables((SimpleNode)c);
+	            for (Iterator vars = filterVars.iterator(); vars.hasNext(); ) {
+	            	if (!selectedVars.contains(vars.next())) {
+	            		allvarsknown = false;
+	            		break;
+	            	}
+	            }
+	            if (allvarsknown) {
+	            	constraintOrder.add(c);
+	            	filters.remove();
+	            }*/
+	        }
+        }
+		
+		// Add the otherQueue back in.
+		constraintOrder.addAll(otherQueue);
+
+		// Run the constraints in the new order.
+        RdfBindingSet current = null;
+		for (Iterator cons = constraintOrder.iterator(); cons.hasNext();) {
+			ConstraintLogic c = (ConstraintLogic) cons.next();
+			if (current == null) {
+				current = c.constrain(current, source,
+						defaultDatasets, namedDatasets, knownValues, knownFilters);
+			} else if (c instanceof FilterConstraintData) {
+	            current = c.constrain(current, source, defaultDatasets,
+	                    namedDatasets, knownValues, knownFilters);
+	            filterQueue.remove(c);
+			} else {
+				current = logic.intersect(current, c.constrain(current, source,
+						defaultDatasets, namedDatasets, knownValues, knownFilters));
+			}
+
+			if (cons.hasNext() || optionalQueue.size() > 0) {
+				// If there are more things happening later, update our knownValue
+				// mapping based on what has currently been queried.  We have to
+				// loop through all of the bindings found so far, so we'll put
+				// those bindings into a new set to cache them.
+				
+				current = new RdfBindingSetImpl(current);
+				List variables = current.getVariables();
+				
+				Set hadNewValues = new HashSet();
+				for (Iterator biter = current.iterator(); biter.hasNext(); ) {
+					RdfBindingRow row = (RdfBindingRow)biter.next();
+					List rowvalues = row.getValues();
+					
+					for (int i = 0; i < variables.size(); i++) {
+						Variable var = (Variable) variables.get(i);
+						Value val = (Value) rowvalues.get(i);
+						
+						if (val == null) continue;
+						
+						Set values = (Set)knownValues.get(var);
+						
+						// If knownValues has no mapping for this variable yet,
+						// or if knownValues had a mapping, we want to clear
+						// the mapping and start fresh with the values actually
+						// found.
+						if (values == null || !hadNewValues.contains(var)) { 
+							values = new HashSet();
+							knownValues.put(var, values);
+							hadNewValues.add(var);
+						}
+							
+						values.add(val);
+					}
+				}
+				
+				extractVariableFunctions(knownValues);
+			}
+        }
+        
+        // At this point, we're operating on the set, so let's make it an empty one
+        if (current == null) {
+            current = new RdfBindingSetImpl();
+        }
+
+		// Any optionals...
+        for (Iterator optionals = optionalQueue.iterator(); optionals.hasNext();) {
+            ConstraintLogic c = (ConstraintLogic) optionals.next();
+            current = c.constrain(current, source, defaultDatasets,
+                    namedDatasets, knownValues, knownFilters);
+        }
+		
+		// Any filters that were not moved up in the logic to process them as early as possible.
+        for (Iterator filters = filterQueue.iterator(); filters.hasNext();) {
+            ConstraintLogic c = (ConstraintLogic) filters.next();
+            current = c.constrain(current, source, defaultDatasets,
+                    namedDatasets, knownValues, knownFilters);
+        }
+        return current;
+    }
+
+    /**
+     * Creates a mapping from variables to a List of filters based on
+	 * the expression.
+     * 
+     * @param node the expression to extract filters from
+	 * @param literalFilters a map from variables to a List of filters (of any type
+	 *                       supported by the underlying AdvancedRdfSource).
+     */
+	protected void extractLiteralFilters(ExpressionLogic node, Map literalFilters) {
+		if (node instanceof ASTAndNode) {
+			extractLiteralFilters(((ASTAndNode)node).getLeftExpression(), literalFilters);
+			extractLiteralFilters(((ASTAndNode)node).getRightExpression(), literalFilters);
+		}
+	}
+	
+	protected void addLiteralFilter(Variable variable, Object filter, Map literalFilters) {
+		List list = (List)literalFilters.get(variable);
+		if (list == null) {
+			list = new java.util.ArrayList();
+			literalFilters.put(variable, list);
+		}
+		list.add(filter);
+	}
+	
+	private void extractVariableFunctions(Map knownValues) {
+        for (Iterator cons = data.getConstraints().iterator(); cons.hasNext();) {
+            ConstraintLogic c = (ConstraintLogic) cons.next();
+            if (c instanceof FilterConstraintData) {
+				FilterConstraintData f = (FilterConstraintData)c;
+				extractVariableFunctions(f.getExpression(), knownValues);
+			}
+		}
+	}
+	
+	private void extractVariableFunctions(ExpressionLogic node, Map knownValues) {
+		if (node instanceof ASTAndNode) {
+			extractVariableFunctions(((ASTAndNode)node).getLeftExpression(), knownValues);
+			extractVariableFunctions(((ASTAndNode)node).getRightExpression(), knownValues);
+		}
+		if (node instanceof ASTOrNode) {
+			Map a = new HashMap();
+			Map b = new HashMap();
+			extractVariableFunctions(((ASTOrNode)node).getLeftExpression(), a);
+			extractVariableFunctions(((ASTOrNode)node).getRightExpression(), b);
+			for (Iterator i = a.keySet().iterator(); i.hasNext(); ) {
+				Variable v = (Variable)i.next();
+				if (b.containsKey(v)) {
+					Set av = (Set)a.get(v);
+					Set bv = (Set)b.get(v);
+					av.addAll(bv);
+					if (knownValues.containsKey(v)) {
+						((Set)knownValues.get(v)).retainAll(av);
+					} else {
+						knownValues.put(v, av);
+					}
+				}
+			}
+		}
+		if (node instanceof ASTEqualsNode) {
+			extractVariableFunctions(((ASTEqualsNode)node).getLeftExpression(), ((ASTEqualsNode)node).getRightExpression(), knownValues);
+			extractVariableFunctions(((ASTEqualsNode)node).getRightExpression(), ((ASTEqualsNode)node).getLeftExpression(), knownValues);
+		}
+	}
+	
+	private void extractVariableFunctions(ExpressionLogic a, ExpressionLogic b, Map knownValues) {
+		if (!(a instanceof Variable)) return;
+		if (knownValues.containsKey(a)) return; // we could intersect with existing values, but be sure not to do this for values we just inserted into the hash
+		
+		if (b instanceof Variable && knownValues.containsKey(b)) {
+			knownValues.put(a, knownValues.get(b));
+		
+		} else if (b instanceof ExternalFunctionLogic) {
+			// if this is a function of one variable, get the values by applying the function
+			// to all of the variables values.  (if it's of more than one variable, we could
+			// permute through the variables...)
+			ExternalFunctionLogic f = (ExternalFunctionLogic)b;
+			Set varargs =  getFilterVariables((SimpleNode)b);
+			
+			if (varargs.size() == 0) { // a constant, ok
+				Value v = f.evaluate(new MyBindingRow(new HashMap()));
+				HashSet vs = new HashSet();
+				vs.add(v);
+				knownValues.put(a, vs);
+				return;
+			}
+			
+			if (varargs.size() > 1) return;
+			
+			for (Iterator i = varargs.iterator(); i.hasNext(); ) {
+				Variable var = (Variable)i.next();
+				if (!knownValues.containsKey(var))
+					return;
+				
+				Set varvalues = (Set)knownValues.get(var);
+				Set newvalues = new HashSet();
+				Map bindings = new HashMap();
+				for (Iterator j = varvalues.iterator(); j.hasNext(); ) {
+					bindings.put(var, j.next());
+					newvalues.add( f.evaluate(new MyBindingRow(bindings)) );
+				}
+				
+				knownValues.put(a, newvalues);
+			}
+		}
+		
+		
+		// TODO: if b is a function whose arguments are all constants or known values, evaluate the function
+	}
+	
+	private class MyBindingRow extends AbstractRdfBindingRow {
+		Map values;
+		public MyBindingRow(Map values) { super(null); this.values = values; }
+		public List getVariables() { return new java.util.ArrayList(values.keySet()); }
+		public Value getValue(Variable v) { return (Value)values.get(v); }
+	}
+	
+    /**
+     * Returns the complexity of the triple constraint, given a set of
+	 * variables that already have known values.  The return value is the
+	 * number of variable slots in the triple constraint plus the number
+	 * of variable slots whose variable is not in the variablesKnown set.
+	 * (That is, a variable used twice is counted twice.)
+     * 
+     * @param variablesKnown a set of variables whose values are known
+     */
+	private int getComplexity(TripleConstraint triple, Set variablesKnown, Set cheapVariables, Map knownFilters, RdfSource source) {
+		// Properties in RDF tend to be many-to-few.  That is, lots of people
+		// may have a particular foaf:name, and one person has very few foaf:names.
+		// Thus, we give a penalty when a new variable occurs in subject position.
+		Object subject = triple.getSubjectExpression();
+		Object predicate = triple.getPredicateExpression();
+		Object object = triple.getObjectExpression();
+		return
+			getComplexity2(subject, variablesKnown, cheapVariables, knownFilters, 6, predicate instanceof URI && isFunctional((URI)predicate, source, false)) +
+			getComplexity2(predicate, variablesKnown, cheapVariables, knownFilters, 2, false) +
+			getComplexity2(object, variablesKnown, cheapVariables, knownFilters, 2, predicate instanceof URI && isFunctional((URI)predicate, source, true));
+	}
+	
+	private int getComplexity2(Object thing, Set variablesKnown, Set cheapVariables, Map knownFilters, int penalty, boolean functional) {
+		int ret = 0;
+		if (thing instanceof Variable) {
+			if (!cheapVariables.contains(thing)) ret++;
+			if (!functional && !variablesKnown.contains(thing) && !knownFilters.containsKey(thing)) {
+				ret += penalty;
+			}
+		}
+		return ret;
+	}
+	
+	private boolean isFunctional(URI predicate, RdfSource source, boolean forward) {
+		Map map = forward ? isFunctional : isInverseFunctional;
+		if (map.containsKey(predicate)) return ((Boolean)map.get(predicate)).booleanValue();
+	
+		URI rdftype = new org.openrdf.model.impl.URIImpl("http://www.w3.org/1999/02/22-rdf-syntax-ns#type");
+		String typeuri = "http://www.w3.org/2002/07/owl#" +
+			( forward ? "FunctionalProperty" : "InverseFunctionalProperty");
+		boolean ret = source.hasDefaultStatement(predicate, rdftype, new org.openrdf.model.impl.URIImpl(typeuri));
+		map.put(predicate, new Boolean(ret));
+		return ret;
+	}
+
+	
+    /**
+     * Adds the variables in the constraint into the set.
+     * 
+     * @param variablesKnown a set of variables whose values are known
+     */
+	private void getVariables(TripleConstraint triple, Set variablesKnown) {
+		if (triple.getSubjectExpression() instanceof Variable) variablesKnown.add(triple.getSubjectExpression());
+		if (triple.getPredicateExpression() instanceof Variable) variablesKnown.add(triple.getPredicateExpression());
+		if (triple.getObjectExpression() instanceof Variable) variablesKnown.add(triple.getObjectExpression());
+	}
+	
+   /**
+     * Gets a variable for the filter.  If the filter is a ASTEqualsNode,
+	 * return the variable on the left hand side.  If the filter is a
+	 * ASTOrNode, return the variable if its the same on both sides,
+	 * or else null.
+     */
+	private Variable getFilterPrimaryVariable(BinaryExpressionNode expr) {
+		if (expr instanceof ASTOrNode
+			&& expr.getLeftExpression() instanceof BinaryExpressionNode
+			&& expr.getRightExpression() instanceof BinaryExpressionNode) {
+			Variable left = getFilterPrimaryVariable((BinaryExpressionNode)expr.getLeftExpression());
+			Variable right = getFilterPrimaryVariable((BinaryExpressionNode)expr.getRightExpression());
+			if (left != null && right != null && left.equals(right)) return left;
+		} else if (expr instanceof ASTEqualsNode
+			&& expr.getLeftExpression() instanceof Variable && (expr.getRightExpression() instanceof URI || expr.getRightExpression() instanceof BNode || expr.getRightExpression() instanceof Literal)) {
+			return (Variable)expr.getLeftExpression(); 
+		}
+		return null;
+	}
+	
+   /**
+     * Gets the values for a filter.  For an ASTEqualsNode, returns
+	 * the right hand side.  For an ASTOrNode, returns the values of its parts.
+     */
+	private void getFilterValues(BinaryExpressionNode expr, Set set) {
+		if (expr instanceof ASTOrNode) {
+			getFilterValues((BinaryExpressionNode)expr.getLeftExpression(), set);
+			getFilterValues((BinaryExpressionNode)expr.getRightExpression(), set);
+		} else if (expr instanceof ASTEqualsNode && (expr.getRightExpression() instanceof URI || expr.getRightExpression() instanceof BNode || expr.getRightExpression() instanceof Literal)) {
+			set.add(expr.getRightExpression());
+		}
+	}
+
+	private Set getFilterVariables(SimpleNode filter) {
+		final HashSet ret = new HashSet();
+		filter.jjtAccept(
+			new EmptyVisitor() {
+				public void visit(ASTVar node) {
+					ret.add(node);
+				}
+			}
+			);
+		return ret;
+	}
+}
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/streamed/IndexedSetIntersectLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/streamed/IndexedSetIntersectLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/streamed/IndexedSetIntersectLogic.java	2006-07-16 19:04:06.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/streamed/IndexedSetIntersectLogic.java	2006-08-01 19:27:55.000000000 -0400
@@ -64,7 +64,7 @@
         final List variables;
 
         final List commonVariables;
-
+		
         RdfBindingIntersect(RdfBindingSet set1, RdfBindingSet set2) {
             this.set1 = set1;
             this.set2 = set2;
@@ -259,10 +259,11 @@
             }
 
             public Value getValue(Variable variable) {
-                Value returnValue = this.row1.getValue(variable);
-                if (returnValue == null) {
+				Value returnValue = null;
+				if (set1.getVariables().contains(variable))
+					returnValue = this.row1.getValue(variable);
+                if (returnValue == null && set2.getVariables().contains(variable))
                     returnValue = this.row2.getValue(variable);
-                }
                 return returnValue;
             }
 
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/streamed/IndexedSetJoinLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/streamed/IndexedSetJoinLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/streamed/IndexedSetJoinLogic.java	2006-07-16 19:04:04.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/streamed/IndexedSetJoinLogic.java	2006-08-01 19:28:44.000000000 -0400
@@ -81,7 +81,7 @@
 		final List variables;
 
 		final List commonVariables;
-
+		
 		RdfBindingJoin(RdfBindingSet set1, RdfBindingSet set2, Collection filters) {
 			this.set1 = set1;
 			this.set2 = set2;
@@ -293,14 +293,11 @@
 			}
 
 			public Value getValue(Variable variable) {
-				Value returnValue = this.row1.getValue(variable);
-				if (returnValue == null) {
-					if (this.row2 == null) {
-						returnValue = null;
-					} else {
-						returnValue = this.row2.getValue(variable);
-					}
-				}
+				Value returnValue = null;
+				if (set1.getVariables().contains(variable))
+					returnValue = this.row1.getValue(variable);
+				if (returnValue == null && this.row2 != null && set2.getVariables().contains(variable))
+					returnValue = this.row2.getValue(variable);
 				return returnValue;
 			}
 
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/streamed/StreamedFilterConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/streamed/StreamedFilterConstraintLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/streamed/StreamedFilterConstraintLogic.java	2006-07-16 19:04:02.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/streamed/StreamedFilterConstraintLogic.java	2006-08-01 12:36:00.000000000 -0400
@@ -10,6 +10,7 @@
 import java.util.Iterator;
 import java.util.LinkedList;
 import java.util.List;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingRow;
 import name.levering.ryan.sparql.common.RdfBindingSet;
@@ -77,7 +78,7 @@
 	 * @return a binding set with values that pass through the filter expression
 	 */
 	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
+			Collection namedDatasets, Map knownValues, Map knownFilters) {
 		return new FilterBindingSet(bindings, this.data.getExpression());
 	}
 
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/streamed/StreamedGraphConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/streamed/StreamedGraphConstraintLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/streamed/StreamedGraphConstraintLogic.java	2006-07-16 19:04:04.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/streamed/StreamedGraphConstraintLogic.java	2006-08-01 12:36:32.000000000 -0400
@@ -10,6 +10,7 @@
 import java.util.Collection;
 import java.util.Iterator;
 import java.util.List;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingRow;
 import name.levering.ryan.sparql.common.RdfBindingSet;
@@ -86,7 +87,7 @@
      *         with a bound graph variable
      */
     public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source,
-            Collection defaultDatasets, Collection namedDatasets) {
+            Collection defaultDatasets, Collection namedDatasets, Map knownValues, Map knownFilters) {
 
         RdfBindingSet fullSet = new RdfBindingSetImpl();
         if (bindings != null && bindings.iterator().hasNext()) {
@@ -99,7 +100,7 @@
                     if (namedDatasets.isEmpty()) {
                         // Here we want to use any named dataset in the data
                         RdfBindingSet namedResults = this.data.getConstraint().constrain(
-                                bindings, source, null, namedDatasets);
+                                bindings, source, null, namedDatasets, knownValues, knownFilters);
 
                         RdfBindingSet sourcedSet = changeSource(
                                 (Variable) evaluation, namedResults);
@@ -112,7 +113,7 @@
                             Collection datasets = Arrays.asList(new Object[] { namedSet });
 
                             RdfBindingSet namedResults = this.data.getConstraint().constrain(
-                                    bindings, source, datasets, namedDatasets);
+                                    bindings, source, datasets, namedDatasets, knownValues, knownFilters);
 
                             RdfBindingSet sourcedSet = addSource(
                                     (Variable) evaluation, namedSet,
@@ -124,7 +125,7 @@
                 } else if (this.data.getGraph() instanceof Variable) {
                     Collection datasets = Arrays.asList(new Object[] { evaluation });
                     RdfBindingSet namedResults = this.data.getConstraint().constrain(
-                            bindings, source, datasets, namedDatasets);
+                            bindings, source, datasets, namedDatasets, knownValues, knownFilters);
                     fullSet = this.unionLogic.union(fullSet, addSource(
                             (Variable) this.data.getGraph(), (URI) evaluation,
                             namedResults));
@@ -132,7 +133,7 @@
                     Collection datasets = Arrays.asList(new Object[] { evaluation });
                     fullSet = this.unionLogic.union(fullSet,
                             this.data.getConstraint().constrain(bindings,
-                                    source, datasets, namedDatasets));
+                                    source, datasets, namedDatasets, knownValues, knownFilters));
                 }
             }
         } else {
@@ -140,7 +141,7 @@
                 if (namedDatasets.isEmpty()) {
                     // Here we want to use any named dataset in the data
                     RdfBindingSet namedResults = this.data.getConstraint().constrain(
-                            bindings, source, null, namedDatasets);
+                            bindings, source, null, namedDatasets, knownValues, knownFilters);
 
                     RdfBindingSet sourcedSet = changeSource(
                             (Variable) this.data.getGraph(), namedResults);
@@ -153,7 +154,7 @@
                         Collection datasets = Arrays.asList(new Object[] { namedSet });
 
                         RdfBindingSet namedResults = this.data.getConstraint().constrain(
-                                bindings, source, datasets, namedDatasets);
+                                bindings, source, datasets, namedDatasets, knownValues, knownFilters);
 
                         RdfBindingSet sourcedSet = addSource(
                                 (Variable) this.data.getGraph(), namedSet,
@@ -166,7 +167,7 @@
                 Collection datasets = Arrays.asList(new Object[] { this.data.getGraph() });
                 fullSet = this.unionLogic.union(fullSet,
                         this.data.getConstraint().constrain(bindings, source,
-                                datasets, namedDatasets));
+                                datasets, namedDatasets, knownValues, knownFilters));
             }
         }
         return fullSet;
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/streamed/StreamedTripleConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/streamed/StreamedTripleConstraintLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/streamed/StreamedTripleConstraintLogic.java	2006-07-16 19:04:02.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/streamed/StreamedTripleConstraintLogic.java	2006-08-01 17:59:58.000000000 -0400
@@ -10,11 +10,14 @@
 import java.util.Iterator;
 import java.util.List;
 import java.util.NoSuchElementException;
+import java.util.Map;
+import java.util.Set;
 
 import name.levering.ryan.sparql.common.GraphStatement;
 import name.levering.ryan.sparql.common.RdfBindingRow;
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.common.AdvancedRdfSource;
 import name.levering.ryan.sparql.common.Variable;
 import name.levering.ryan.sparql.common.impl.AbstractRdfBindingRow;
 import name.levering.ryan.sparql.common.impl.AbstractRdfBindingSet;
@@ -64,7 +67,7 @@
 	 *            used in this constraint
 	 */
 	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
+			Collection namedDatasets, Map knownValues, Map knownFilters) {
 
 		ExpressionLogic subExpr = this.data.getSubjectExpression();
 		ExpressionLogic predExpr = this.data.getPredicateExpression();
@@ -75,12 +78,12 @@
 		Value subject = null;
 		if (subExpr instanceof Variable) {
 			variables.add(subExpr);
-			flags[0] = 1;
+			flags[0] = variables.size();
 			if (subExpr.equals(predExpr)) {
-				flags[1] = 1;
+				flags[1] = flags[0];
 			}
 			if (subExpr.equals(objExpr)) {
-				flags[2] = 1;
+				flags[2] = flags[0];
 			}
 		} else {
 			subject = (Value) subExpr;
@@ -89,10 +92,10 @@
 		URI verb = null;
 		if (predExpr instanceof Variable && flags[1] == 0) {
 			variables.add(predExpr);
-			flags[1] = 2;
+			flags[1] = variables.size();
 			if (predExpr.equals(objExpr)) {
-				flags[2] = 2;
-			}
+				flags[2] = flags[2];
+			}                               
 		} else {
 			verb = (URI) predExpr;
 		}
@@ -100,26 +103,37 @@
 		Value object = null;
 		if (objExpr instanceof Variable && flags[2] == 0) {
 			variables.add(objExpr);
-			flags[2] = 3;
+			flags[2] = variables.size();
 		} else if (flags[2] == 0) {
 			object = (Value) objExpr;
 		}
+		
+		TripleQueryOptions query = new TripleQueryOptions();
+		query.source = source;
+		query.variables = variables;
+		query.flags = flags;
+		query.knownValues = knownValues;
+		query.knownFilters = knownFilters;
 
 		if (defaultDatasets == null) {
+			query.includeSource = true;
+
 			// This adds an extra column to the returned set for the GRAPH
 			// constraint to process
 			if (source != null) {
-				StatementBindingSet bindingSet = new StatementBindingSet(source, variables, flags, true);
+				StatementBindingSet bindingSet = new StatementBindingSet(query);
 				bindingSet.addIterator(new StatementImpl(subject, verb, object));
 				return bindingSet;
 			} else {
-				StreamedTripleBindingSet bindingSet = new StreamedTripleBindingSet(variables, flags, true);
+				StreamedTripleBindingSet bindingSet = new StreamedTripleBindingSet(query);
 				bindingSet.addIterator(new StatementImpl(subject, verb, object));
 				return bindingSet;
 			}
 		} else {
+			query.includeSource = false;
+			
 			if (source != null) {
-				StatementBindingSet bindingSet = new StatementBindingSet(source, variables, flags, false);
+				StatementBindingSet bindingSet = new StatementBindingSet(query);
 				if (defaultDatasets.isEmpty()) {
 					// This is if no FROM graphs are specified
 					bindingSet.addIterator(new StatementImpl(subject, verb, object));
@@ -132,7 +146,7 @@
 				}
 				return bindingSet;
 			} else {
-				StreamedTripleBindingSet bindingSet = new StreamedTripleBindingSet(variables, flags, false);
+				StreamedTripleBindingSet bindingSet = new StreamedTripleBindingSet(query);
 				if (defaultDatasets.isEmpty()) {
 					// This is if no FROM graphs are specified
 					bindingSet.addIterator(new StatementImpl(subject, verb, object));
@@ -147,43 +161,67 @@
 			}
 		}
 	}
-
-	/**
-	 * This set is the lowest level binding set that wraps a request to an
-	 * RdfSource. It returns an iterator that uses the row iterators from the
-	 * RdfSource getStatement call to check if returned rows match the equality
-	 * criteria in the passed in flags.
-	 * 
-	 * @author Ryan Levering
-	 * @version 1.1
-	 */
-	private class StatementBindingSet extends AbstractRdfBindingSet {
-
+	
+	private class TripleQueryOptions implements Cloneable {
 		/**
 		 * The RDF source that's being queried.
 		 */
-		final RdfSource source;
+		RdfSource source;
 
 		/**
 		 * The variables that are being bound to values in the RDF source.
 		 */
-		final List variables;
+		List variables;
 
 		/**
 		 * Flags that allow a shortcut to checking for the equality of two
 		 * equivalent variables.
 		 */
-		final int[] flags;
+		int[] flags;
+		
+		/**
+		 * Whether or not to include the graph name in the returned bindings.
+		 */
+		boolean includeSource;
 
 		/**
-		 * The statements that are matched against the RDF source.
+		 * A mapping from variables to Lists of Values that the bindings
+		 * must be drawn from.  (Possibly null if not applicable.)
 		 */
-		final List statementIterators = new ArrayList();
+		Map knownValues;
 
 		/**
-		 * Whether or not to include the graph name in the returned bindings.
+		 * A mapping from variables to Lists of filters (objects) that the bindings
+		 * must satisfy.  (Possibly null if not applicable.)
 		 */
-		final boolean includeSource;
+		Map knownFilters;
+		
+		public TripleQueryOptions clone() {
+			try {
+				return (TripleQueryOptions)super.clone();
+			} catch (CloneNotSupportedException e) {
+				// lame
+				throw new RuntimeException(e);
+			}
+		}
+	}
+
+	/**
+	 * This set is the lowest level binding set that wraps a request to an
+	 * RdfSource. It returns an iterator that uses the row iterators from the
+	 * RdfSource getStatement call to check if returned rows match the equality
+	 * criteria in the passed in flags.
+	 * 
+	 * @author Ryan Levering
+	 * @version 1.1
+	 */
+	private class StatementBindingSet extends AbstractRdfBindingSet {
+		final TripleQueryOptions query;
+		
+		/**
+		 * The statements that are matched against the RDF source.
+		 */
+		final List statementIterators = new ArrayList();
 
 		/**
 		 * Creates a new binding set that queries a particular RdfSource,
@@ -195,11 +233,8 @@
 		 * @param flags indicates the presence of variable equivalency
 		 * @param includeSource whether to bind the graph name as well
 		 */
-		private StatementBindingSet(RdfSource source, List variables, int[] flags, boolean includeSource) {
-			this.source = source;
-			this.variables = variables;
-			this.flags = flags;
-			this.includeSource = includeSource;
+		private StatementBindingSet(TripleQueryOptions query) {
+			this.query = query;
 		}
 
 		void addIterator(GraphStatement statementIterator) {
@@ -211,8 +246,8 @@
 		}
 
 		public List getVariables() {
-			List extVariables = new ArrayList(this.variables);
-			if (this.includeSource) {
+			List extVariables = new ArrayList(this.query.variables);
+			if (this.query.includeSource) {
 				extVariables.add(StreamedGraphConstraintLogic.CONTEXT_VARIABLE);
 			}
 			return extVariables;
@@ -273,24 +308,70 @@
 				// We should only get here if there was never a chance
 				return null;
 			}
-
+			
 			private Iterator getStatements(GraphStatement statement) {
+				if (StatementBindingSet.this.query.source instanceof AdvancedRdfSource)
+					return getStatementsAdvanced(statement);
+				else
+					return getStatementsSimple(statement);
+			}
+			
+			private Iterator getStatementsSimple(GraphStatement statement) {
+				Value s = statement.getSubject();
+				URI p = statement.getPredicate();
+				Value o = statement.getObject();
+				
+				if (statement.getGraphName() == null) {
+					if (StatementBindingSet.this.query.includeSource) {
+						return StatementBindingSet.this.query.source.getStatements(s, p, o);
+					} else {
+						return StatementBindingSet.this.query.source.getDefaultStatements(s, p, o);
+					}
+				} else {
+					return StatementBindingSet.this.query.source.getStatements(s, p, o, statement.getGraphName());
+				}
+			}
+			
+			private Iterator getStatementsAdvanced(GraphStatement statement) {
+				AdvancedRdfSource source = (AdvancedRdfSource)StatementBindingSet.this.query.source;
+				
+				Value[] s = getValues(statement.getSubject(), 0);
+				Value[] p = getValues(statement.getPredicate(), 1);
+				Value[] o = getValues(statement.getObject(), 2);
+				Object[] litFilters = getFilters(statement.getObject());
+				
 				if (statement.getGraphName() == null) {
-					if (StatementBindingSet.this.includeSource) {
-						return StatementBindingSet.this.source.getStatements(statement.getSubject(), statement
-								.getPredicate(), statement.getObject());
+					if (StatementBindingSet.this.query.includeSource) {
+						return source.getStatements(s, p, o, litFilters);
 					} else {
-						return StatementBindingSet.this.source.getDefaultStatements(statement.getSubject(), statement
-								.getPredicate(), statement.getObject());
+						return source.getDefaultStatements(s, p, o, litFilters);
 					}
 				} else {
-					return StatementBindingSet.this.source.getStatements(statement.getSubject(), statement
-							.getPredicate(), statement.getObject(), statement.getGraphName());
+					return source.getStatements(s, p, o, new URI[] { statement.getGraphName() }, litFilters);
 				}
 			}
+			
+			private Value[] getValues(Value value, int index) {
+				if (value != null) return new Value[] { value };
+				if (StatementBindingSet.this.query.knownValues == null) return null;
+				int varIndex = StatementBindingSet.this.query.flags[index]-1;
+				Variable variable = (Variable)StatementBindingSet.this.query.variables.get(varIndex); 
+				Set values = (Set)StatementBindingSet.this.query.knownValues.get(variable);
+				if (values == null) return null;
+				return (Value[])values.toArray(new Value[0]);
+			}
+			private Object[] getFilters(Value value) {
+				if (value != null) return null;
+				if (StatementBindingSet.this.query.knownFilters == null) return null;
+				int varIndex = StatementBindingSet.this.query.flags[2]-1;
+				Variable variable = (Variable)StatementBindingSet.this.query.variables.get(varIndex);
+				List filters = (List)StatementBindingSet.this.query.knownFilters.get(variable);
+				if (filters == null) return null;
+				return filters.toArray();
+			}
 
 			private boolean checkStatement(GraphStatement statement) {
-				int[] localFlags = StatementBindingSet.this.flags;
+				int[] localFlags = StatementBindingSet.this.query.flags;
 
 				if (localFlags[0] != 0 && localFlags[0] == localFlags[2]) {
 					if (!statement.getSubject().equals(statement.getObject())) {
@@ -338,14 +419,14 @@
 
 				public Value getValue(Variable variable) {
 					// Special case for the source
-					if (StatementBindingSet.this.includeSource
+					if (StatementBindingSet.this.query.includeSource
 							&& variable.equals(StreamedGraphConstraintLogic.CONTEXT_VARIABLE)) {
 						return this.statement.getGraphName();
 					}
 					// First get the index
 					int index = getIndex(variable);
 
-					int[] localFlags = StatementBindingSet.this.flags;
+					int[] localFlags = StatementBindingSet.this.query.flags;
 					if (index == 2) {
 						// If the variable is in the last spot, it's got to be
 						// the object
@@ -375,7 +456,7 @@
 
 				private int getIndex(Variable variable) {
 					int index = 0;
-					for (Iterator vars = StatementBindingSet.this.variables.iterator(); vars.hasNext(); index++) {
+					for (Iterator vars = StatementBindingSet.this.query.variables.iterator(); vars.hasNext(); index++) {
 						Variable var = (Variable) vars.next();
 						if (variable.equals(var)) {
 							return index;
@@ -405,22 +486,18 @@
 
 	private class StreamedTripleBindingSet extends VirtualRdfBindingSet {
 
-		private final List variables;
-
-		private final int[] flags;
-
-		private final boolean includeSource;
-
+		private final TripleQueryOptions query;
+		
 		private final List statementIterators = new ArrayList();
 
-		public StreamedTripleBindingSet(List variables, int[] flags, boolean includeSource) {
-			this.variables = variables;
-			this.flags = flags;
-			this.includeSource = includeSource;
+		public StreamedTripleBindingSet(TripleQueryOptions query) {
+			this.query = query;
 		}
 
 		public void setSource(RdfSource source) {
-			StatementBindingSet set = new StatementBindingSet(source, this.variables, this.flags, this.includeSource);
+			TripleQueryOptions q = query.clone();
+			q.source = source;
+			StatementBindingSet set = new StatementBindingSet(q);
 			for (Iterator statementIt = statementIterators.iterator(); statementIt.hasNext();) {
 				set.addIterator((GraphStatement) statementIt.next());
 			}
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/logic/StreamedStrictLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/StreamedStrictLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/logic/StreamedStrictLogic.java	2006-07-16 19:04:02.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/StreamedStrictLogic.java	1969-12-31 19:00:00.000000000 -0500
@@ -1,288 +0,0 @@
-/*
- * SPARQL Engine
- * Copyright (C) 2005 Ryan Levering, All rights reserved.
- * See LICENSE for full license information
- */
-package name.levering.ryan.sparql.logic;
-
-import java.util.Collection;
-import java.util.HashMap;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
-
-import name.levering.ryan.sparql.common.QueryException;
-import name.levering.ryan.sparql.common.SPARQLConstants;
-import name.levering.ryan.sparql.common.Variable;
-import name.levering.ryan.sparql.common.impl.SPARQLValueFactory;
-import name.levering.ryan.sparql.logic.function.BooleanCastFunction;
-import name.levering.ryan.sparql.logic.function.DateTimeCastFunction;
-import name.levering.ryan.sparql.logic.function.DecimalCastFunction;
-import name.levering.ryan.sparql.logic.function.DoubleCastFunction;
-import name.levering.ryan.sparql.logic.function.ExternalFunction;
-import name.levering.ryan.sparql.logic.function.ExternalFunctionFactory;
-import name.levering.ryan.sparql.logic.function.ExternalFunctionLogic;
-import name.levering.ryan.sparql.logic.function.FloatCastFunction;
-import name.levering.ryan.sparql.logic.function.IRICastFunction;
-import name.levering.ryan.sparql.logic.function.IntegerCastFunction;
-import name.levering.ryan.sparql.logic.function.LiteralCastFunction;
-import name.levering.ryan.sparql.logic.function.StringCastFunction;
-import name.levering.ryan.sparql.logic.naive.DefaultGroupConstraintLogic;
-import name.levering.ryan.sparql.logic.naive.DefaultOptionalConstraintLogic;
-import name.levering.ryan.sparql.logic.naive.DefaultUnionConstraintLogic;
-import name.levering.ryan.sparql.logic.streamed.IndexedSetDistinctionLogic;
-import name.levering.ryan.sparql.logic.streamed.IndexedSetIntersectLogic;
-import name.levering.ryan.sparql.logic.streamed.IndexedSetJoinLogic;
-import name.levering.ryan.sparql.logic.streamed.StreamedFilterConstraintLogic;
-import name.levering.ryan.sparql.logic.streamed.StreamedGraphConstraintLogic;
-import name.levering.ryan.sparql.logic.streamed.StreamedSetProjectionLogic;
-import name.levering.ryan.sparql.logic.streamed.StreamedSetRangeLogic;
-import name.levering.ryan.sparql.logic.streamed.StreamedSetUnionLogic;
-import name.levering.ryan.sparql.logic.streamed.StreamedTripleConstraintLogic;
-import name.levering.ryan.sparql.model.data.AskQueryData;
-import name.levering.ryan.sparql.model.data.CallExpressionData;
-import name.levering.ryan.sparql.model.data.ConstructQueryData;
-import name.levering.ryan.sparql.model.data.DescribeQueryData;
-import name.levering.ryan.sparql.model.data.FilterConstraintData;
-import name.levering.ryan.sparql.model.data.GraphConstraintData;
-import name.levering.ryan.sparql.model.data.GroupConstraintData;
-import name.levering.ryan.sparql.model.data.OptionalConstraintData;
-import name.levering.ryan.sparql.model.data.OrderExpressionData;
-import name.levering.ryan.sparql.model.data.SelectQueryData;
-import name.levering.ryan.sparql.model.data.TripleConstraintData;
-import name.levering.ryan.sparql.model.data.UnboundStatement;
-import name.levering.ryan.sparql.model.data.UnionConstraintData;
-import name.levering.ryan.sparql.model.logic.AskQueryLogic;
-import name.levering.ryan.sparql.model.logic.ConstraintLogic;
-import name.levering.ryan.sparql.model.logic.ConstructQueryLogic;
-import name.levering.ryan.sparql.model.logic.DescribeQueryLogic;
-import name.levering.ryan.sparql.model.logic.ExpressionLogic;
-import name.levering.ryan.sparql.model.logic.OrderExpressionLogic;
-import name.levering.ryan.sparql.model.logic.SelectQueryLogic;
-
-import org.openrdf.model.URI;
-import org.openrdf.model.Value;
-
-/**
- * This factory implements all the default logic for the SPARQL library
- * implementation. The logic is streamed, which means that the end result should
- * be used with iterator() and will be evaluated as next() is called. This can
- * result in some inefficiencies if the set is used multiple times, but it means
- * that the memory use is incredibly small.
- * <p>
- * Developers wishing to tap into more efficient/specific logic should extend
- * this class and specify their own logic implementations in place of the logic
- * they want to replace.
- * 
- * @author Ryan Levering
- * @version 1.1
- */
-public class StreamedStrictLogic extends BaseLogic {
-
-	/**
-	 * Used to map function IRIs to external functions.
-	 */
-	private final Map functionMap = new HashMap();
-
-	/**
-	 * Creates a new default logic factory with the cast constructors registered
-	 * as external functions.
-	 */
-	public StreamedStrictLogic() {
-		registerCastFunctions();
-	}
-
-	/**
-	 * Intialize the function map with the standard SPARQL casting functions.
-	 */
-	protected void registerCastFunctions() {
-		registerExternalFunction(SPARQLConstants.STRING_TYPE, StringCastFunction.getFactory());
-		registerExternalFunction(SPARQLConstants.FLOAT_TYPE, FloatCastFunction.getFactory());
-		registerExternalFunction(SPARQLConstants.DOUBLE_TYPE, DoubleCastFunction.getFactory());
-		registerExternalFunction(SPARQLConstants.DECIMAL_TYPE, DecimalCastFunction.getFactory());
-		registerExternalFunction(SPARQLConstants.INTEGER_TYPE, IntegerCastFunction.getFactory());
-		registerExternalFunction(SPARQLConstants.DATE_TYPE, DateTimeCastFunction.getFactory());
-		registerExternalFunction(SPARQLConstants.BOOLEAN_TYPE, BooleanCastFunction.getFactory());
-		registerExternalFunction(SPARQLConstants.IRI_TYPE, IRICastFunction.getFactory());
-		registerExternalFunction(SPARQLConstants.LITERAL_TYPE, LiteralCastFunction.getFactory());
-	}
-
-	/**
-	 * Gets the default construct query logic.
-	 * 
-	 * @param data the data containing the query constraint, template, and
-	 *            transformations
-	 * @param valueFactory the value factory used to make new blank nodes
-	 * @return the logic handling the construct query
-	 */
-	public ConstructQueryLogic getConstructQueryLogic(ConstructQueryData data, SPARQLValueFactory valueFactory) {
-		// Check to make sure there are no function calls in the construct
-		// template
-		Collection triples = data.getTriples();
-		for (Iterator constructStatements = triples.iterator(); constructStatements.hasNext();) {
-			UnboundStatement statement = (UnboundStatement) constructStatements.next();
-			if (!(statement.getSubjectExpression() instanceof Value || statement.getSubjectExpression() instanceof Variable)) {
-				throw new QueryException("Logic does not support function calls in construct templates");
-			}
-			if (!(statement.getPredicateExpression() instanceof Value || statement.getPredicateExpression() instanceof Variable)) {
-				throw new QueryException("Logic does not support function calls in construct templates");
-			}
-			if (!(statement.getObjectExpression() instanceof Value || statement.getObjectExpression() instanceof Variable)) {
-				throw new QueryException("Logic does not support function calls in construct templates");
-			}
-		}
-		return new DefaultConstructQueryLogic(data, new StreamedSetRangeLogic(), valueFactory);
-	}
-
-	/**
-	 * Gets the default ask query logic.
-	 * 
-	 * @param data the data containing the query constraint
-	 * @return the logic handling the ask query
-	 */
-	public AskQueryLogic getAskQueryLogic(AskQueryData data) {
-		return new DefaultAskQueryLogic(data);
-	}
-
-	/**
-	 * Gets the default describe query logic.
-	 * 
-	 * @param data the data containing the query constraint and transformations
-	 * @return the logic handling the describe query
-	 */
-	public DescribeQueryLogic getDescribeQueryLogic(DescribeQueryData data) {
-		return new DefaultDescribeQueryLogic(data, new StreamedSetProjectionLogic(), new StreamedSetRangeLogic());
-	}
-
-	/**
-	 * Gets the default select query logic.
-	 * 
-	 * @param data the data containing the query constraint and transformations
-	 * @param logic the logic used to do the set projection
-	 * @return the logic handling the select query
-	 */
-	public SelectQueryLogic getSelectQueryLogic(SelectQueryData data) {
-		List variables = data.getQueryVariables();
-		for (Iterator vars = variables.iterator(); vars.hasNext();) {
-			if (!(vars.next() instanceof Variable)) {
-				throw new QueryException("Logic does not support expressions in select projection");
-			}
-		}
-		return new DefaultSelectQueryLogic(data, new StreamedSetProjectionLogic(), new IndexedSetDistinctionLogic(),
-				new StreamedSetRangeLogic());
-	}
-
-	/**
-	 * Gets the default FILTER constraint logic.
-	 * 
-	 * @param data the data containing the expression to evaluate per row
-	 * @return the logic handling the FILTER constraint
-	 */
-	public ConstraintLogic getFilterConstraintLogic(FilterConstraintData data, SPARQLValueFactory valueFactory) {
-		return new StreamedFilterConstraintLogic(data, getEffectiveBooleanLogic(valueFactory),
-				getValueConversionLogic(valueFactory));
-	}
-
-	/**
-	 * Gets the default GRAPH constraint logic.
-	 * 
-	 * @param data the data containing the group constraint and graph binding
-	 * @return the logic handling the GRAPH constraint
-	 */
-	public ConstraintLogic getGraphConstraintLogic(GraphConstraintData data) {
-		return new StreamedGraphConstraintLogic(data, new StreamedSetUnionLogic());
-	}
-
-	/**
-	 * Gets the default group constraint logic.
-	 * 
-	 * @param data the data containing the sub constraints
-	 * @return the logic handling the group constraint
-	 */
-	public ConstraintLogic getGroupConstraintLogic(GroupConstraintData data) {
-		return new DefaultGroupConstraintLogic(data, new IndexedSetIntersectLogic(), new DefaultIntersectOrderLogic(
-				new IndexedSetIntersectLogic()));
-	}
-
-	/**
-	 * Gets the default triple constraint logic.
-	 * 
-	 * @param data the data containing the unbound statement to match from the
-	 *            source
-	 * @return the logic handling the triple constraint
-	 */
-	public ConstraintLogic getTripleConstraintLogic(TripleConstraintData data) {
-		return new StreamedTripleConstraintLogic(data);
-	}
-
-	/**
-	 * Gets the default UNION constraint logic.
-	 * 
-	 * @param data the data containing the sub group constraints
-	 * @return the logic handling the UNION constraint
-	 */
-	public ConstraintLogic getUnionConstraintLogic(UnionConstraintData data) {
-		return new DefaultUnionConstraintLogic(data, new StreamedSetUnionLogic());
-	}
-
-	/**
-	 * Gets the default OPTIONAL constraint logic.
-	 * 
-	 * @param data the data containing the group constraint
-	 * @return the logic handling the OPTIONAL constraint
-	 */
-	public ConstraintLogic getOptionalConstraintLogic(OptionalConstraintData data, SPARQLValueFactory valueFactory) {
-		return new DefaultOptionalConstraintLogic(data, new IndexedSetIntersectLogic(), new DefaultIntersectOrderLogic(
-				new IndexedSetIntersectLogic()), new IndexedSetJoinLogic(getValueConversionLogic(valueFactory),
-				getEffectiveBooleanLogic(valueFactory)));
-	}
-
-	/**
-	 * Gets the logic dealing with any external function calls, including cast
-	 * constructors.
-	 * 
-	 * @param data the function data containing arguments passed to the external
-	 *            function
-	 * @return the logic handling the external function processing
-	 * @throws IllegalArgumentException if data or the name of the function is
-	 *             null
-	 * @throws QueryException if the function map doesn't contain the called
-	 *             function
-	 */
-	public ExpressionLogic getExternalFunctionLogic(CallExpressionData data, SPARQLValueFactory valueFactory) {
-		URI functionName = data.getName();
-		if (functionName == null) {
-			throw new IllegalArgumentException("External function name cannot be null");
-		}
-		if (!this.functionMap.containsKey(functionName)) {
-			throw new QueryException("Could not find loaded external function '" + functionName + "'");
-		}
-		ExternalFunctionFactory functionFactory = (ExternalFunctionFactory) this.functionMap.get(functionName);
-		ExternalFunction function = functionFactory.create(this, valueFactory);
-
-		return new ExternalFunctionLogic(data, function, valueFactory);
-	}
-
-	/**
-	 * Gets the logic for dealing with ordering data.
-	 * 
-	 * @param data the data containing the expression to order on and the
-	 *            direction
-	 * @return the logic handling the ordering of an expression
-	 */
-	public OrderExpressionLogic getOrderExpressionLogic(OrderExpressionData data) {
-		return new DefaultOrderExpressionLogic(data, getValueOrderingLogic());
-	}
-
-	/**
-	 * Allows subclasses or implementations to register implementation specific
-	 * functions to be recognized in queries.
-	 * 
-	 * @param functionIRI the IRI that uniquely identifies the function
-	 * @param functionFactory the logic that handles the function evaluation
-	 */
-	public void registerExternalFunction(URI functionIRI, ExternalFunctionFactory functionFactory) {
-		this.functionMap.put(functionIRI, functionFactory);
-	}
-
-}
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/model/logic/ConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/model/logic/ConstraintLogic.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/model/logic/ConstraintLogic.java	2006-07-16 19:04:02.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/model/logic/ConstraintLogic.java	2006-08-01 16:54:54.000000000 -0400
@@ -6,6 +6,7 @@
 package name.levering.ryan.sparql.model.logic;
 
 import java.util.Collection;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -35,8 +36,14 @@
      *            binding
      * @param namedDatasets the datasets that are used in the GRAPH constraint
      *            for unbound variables
+	 * @param knownValues a mapping from variables to Sets of values that
+	 *            the variable must be drawn from
+	 * @param knownFilters a mapping from variables to Lists of filters that
+	 *            the variable must satisfy.  a filter's type is determined
+	 *            by API implementors.
      */
     public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source,
-            Collection defaultDatasets, Collection namedDatasets);
+            Collection defaultDatasets, Collection namedDatasets,
+			Map knownValues, Map knownFilters);
 
 }
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/parser/JavaCharStream.java work-copy/src/main/name/levering/ryan/sparql/parser/JavaCharStream.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/parser/JavaCharStream.java	2006-07-16 19:04:04.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/JavaCharStream.java	2006-08-02 07:50:24.000000000 -0400
@@ -1,547 +1,584 @@
-/* Generated By:JavaCC: Do not edit this line. JavaCharStream.java Version 3.0 */
-package name.levering.ryan.sparql.parser;
-
-/**
- * An implementation of interface CharStream, where the stream is assumed to
- * contain only ASCII characters (with java-like unicode escape processing).
- */
-
-public class JavaCharStream
-{
-  public static final boolean staticFlag = false;
-  static final int hexval(char c) throws java.io.IOException {
-    switch(c)
-    {
-       case '0' :
-          return 0;
-       case '1' :
-          return 1;
-       case '2' :
-          return 2;
-       case '3' :
-          return 3;
-       case '4' :
-          return 4;
-       case '5' :
-          return 5;
-       case '6' :
-          return 6;
-       case '7' :
-          return 7;
-       case '8' :
-          return 8;
-       case '9' :
-          return 9;
-
-       case 'a' :
-       case 'A' :
-          return 10;
-       case 'b' :
-       case 'B' :
-          return 11;
-       case 'c' :
-       case 'C' :
-          return 12;
-       case 'd' :
-       case 'D' :
-          return 13;
-       case 'e' :
-       case 'E' :
-          return 14;
-       case 'f' :
-       case 'F' :
-          return 15;
-    }
-
-    throw new java.io.IOException(); // Should never come here
-  }
-
-  public int bufpos = -1;
-  int bufsize;
-  int available;
-  int tokenBegin;
-  protected int bufline[];
-  protected int bufcolumn[];
-
-  protected int column = 0;
-  protected int line = 1;
-
-  protected boolean prevCharIsCR = false;
-  protected boolean prevCharIsLF = false;
-
-  protected java.io.Reader inputStream;
-
-  protected char[] nextCharBuf;
-  protected char[] buffer;
-  protected int maxNextCharInd = 0;
-  protected int nextCharInd = -1;
-  protected int inBuf = 0;
-
-  protected void ExpandBuff(boolean wrapAround)
-  {
-     char[] newbuffer = new char[bufsize + 2048];
-     int newbufline[] = new int[bufsize + 2048];
-     int newbufcolumn[] = new int[bufsize + 2048];
-
-     try
-     {
-        if (wrapAround)
-        {
-           System.arraycopy(buffer, tokenBegin, newbuffer, 0, bufsize - tokenBegin);
-           System.arraycopy(buffer, 0, newbuffer,
-                                             bufsize - tokenBegin, bufpos);
-           buffer = newbuffer;
-
-           System.arraycopy(bufline, tokenBegin, newbufline, 0, bufsize - tokenBegin);
-           System.arraycopy(bufline, 0, newbufline, bufsize - tokenBegin, bufpos);
-           bufline = newbufline;
-
-           System.arraycopy(bufcolumn, tokenBegin, newbufcolumn, 0, bufsize - tokenBegin);
-           System.arraycopy(bufcolumn, 0, newbufcolumn, bufsize - tokenBegin, bufpos);
-           bufcolumn = newbufcolumn;
-
-           bufpos += (bufsize - tokenBegin);
-        }
-        else
-        {
-           System.arraycopy(buffer, tokenBegin, newbuffer, 0, bufsize - tokenBegin);
-           buffer = newbuffer;
-
-           System.arraycopy(bufline, tokenBegin, newbufline, 0, bufsize - tokenBegin);
-           bufline = newbufline;
-
-           System.arraycopy(bufcolumn, tokenBegin, newbufcolumn, 0, bufsize - tokenBegin);
-           bufcolumn = newbufcolumn;
-
-           bufpos -= tokenBegin;
-        }
-     }
-     catch (Throwable t)
-     {
-        throw new Error(t.getMessage());
-     }
-
-     available = (bufsize += 2048);
-     tokenBegin = 0;
-  }
-
-  protected void FillBuff() throws java.io.IOException
-  {
-     int i;
-     if (maxNextCharInd == 4096)
-        maxNextCharInd = nextCharInd = 0;
-
-     try {
-        if ((i = inputStream.read(nextCharBuf, maxNextCharInd,
-                                            4096 - maxNextCharInd)) == -1)
-        {
-           inputStream.close();
-           throw new java.io.IOException();
-        }
-        else
-           maxNextCharInd += i;
-        return;
-     }
-     catch(java.io.IOException e) {
-        if (bufpos != 0)
-        {
-           --bufpos;
-           backup(0);
-        }
-        else
-        {
-           bufline[bufpos] = line;
-           bufcolumn[bufpos] = column;
-        }
-        throw e;
-     }
-  }
-
-  protected char ReadByte() throws java.io.IOException
-  {
-     if (++nextCharInd >= maxNextCharInd)
-        FillBuff();
-
-     return nextCharBuf[nextCharInd];
-  }
-
-  public char BeginToken() throws java.io.IOException
-  {     
-     if (inBuf > 0)
-     {
-        --inBuf;
-
-        if (++bufpos == bufsize)
-           bufpos = 0;
-
-        tokenBegin = bufpos;
-        return buffer[bufpos];
-     }
-
-     tokenBegin = 0;
-     bufpos = -1;
-
-     return readChar();
-  }     
-
-  protected void AdjustBuffSize()
-  {
-     if (available == bufsize)
-     {
-        if (tokenBegin > 2048)
-        {
-           bufpos = 0;
-           available = tokenBegin;
-        }
-        else
-           ExpandBuff(false);
-     }
-     else if (available > tokenBegin)
-        available = bufsize;
-     else if ((tokenBegin - available) < 2048)
-        ExpandBuff(true);
-     else
-        available = tokenBegin;
-  }
-
-  protected void UpdateLineColumn(char c)
-  {
-     column++;
-
-     if (prevCharIsLF)
-     {
-        prevCharIsLF = false;
-        line += (column = 1);
-     }
-     else if (prevCharIsCR)
-     {
-        prevCharIsCR = false;
-        if (c == '\n')
-        {
-           prevCharIsLF = true;
-        }
-        else
-           line += (column = 1);
-     }
-
-     switch (c)
-     {
-        case '\r' :
-           prevCharIsCR = true;
-           break;
-        case '\n' :
-           prevCharIsLF = true;
-           break;
-        case '\t' :
-           column--;
-           column += (8 - (column & 07));
-           break;
-        default :
-           break;
-     }
-
-     bufline[bufpos] = line;
-     bufcolumn[bufpos] = column;
-  }
-
-  public char readChar() throws java.io.IOException
-  {
-     if (inBuf > 0)
-     {
-        --inBuf;
-
-        if (++bufpos == bufsize)
-           bufpos = 0;
-
-        return buffer[bufpos];
-     }
-
-     char c;
-
-     if (++bufpos == available)
-        AdjustBuffSize();
-
-     if ((buffer[bufpos] = c = ReadByte()) == '\\')
-     {
-        UpdateLineColumn(c);
-
-        int backSlashCnt = 1;
-
-        for (;;) // Read all the backslashes
-        {
-           if (++bufpos == available)
-              AdjustBuffSize();
-
-           try
-           {
-              if ((buffer[bufpos] = c = ReadByte()) != '\\')
-              {
-                 UpdateLineColumn(c);
-                 // found a non-backslash char.
-                 if ((c == 'u') && ((backSlashCnt & 1) == 1))
-                 {
-                    if (--bufpos < 0)
-                       bufpos = bufsize - 1;
-
-                    break;
-                 }
-
-                 backup(backSlashCnt);
-                 return '\\';
-              }
-           }
-           catch(java.io.IOException e)
-           {
-              if (backSlashCnt > 1)
-                 backup(backSlashCnt);
-
-              return '\\';
-           }
-
-           UpdateLineColumn(c);
-           backSlashCnt++;
-        }
-
-        // Here, we have seen an odd number of backslash's followed by a 'u'
-        try
-        {
-           while ((c = ReadByte()) == 'u')
-              ++column;
-
-           buffer[bufpos] = c = (char)(hexval(c) << 12 |
-                                       hexval(ReadByte()) << 8 |
-                                       hexval(ReadByte()) << 4 |
-                                       hexval(ReadByte()));
-
-           column += 4;
-        }
-        catch(java.io.IOException e)
-        {
-           throw new Error("Invalid escape character at line " + line +
-                                         " column " + column + ".");
-        }
-
-        if (backSlashCnt == 1)
-           return c;
-        else
-        {
-           backup(backSlashCnt - 1);
-           return '\\';
-        }
-     }
-     else
-     {
-        UpdateLineColumn(c);
-        return (c);
-     }
-  }
-
-  /**
-   * @deprecated 
-   * @see #getEndColumn
-   */
-
-  public int getColumn() {
-     return bufcolumn[bufpos];
-  }
-
-  /**
-   * @deprecated 
-   * @see #getEndLine
-   */
-
-  public int getLine() {
-     return bufline[bufpos];
-  }
-
-  public int getEndColumn() {
-     return bufcolumn[bufpos];
-  }
-
-  public int getEndLine() {
-     return bufline[bufpos];
-  }
-
-  public int getBeginColumn() {
-     return bufcolumn[tokenBegin];
-  }
-
-  public int getBeginLine() {
-     return bufline[tokenBegin];
-  }
-
-  public void backup(int amount) {
-
-    inBuf += amount;
-    if ((bufpos -= amount) < 0)
-       bufpos += bufsize;
-  }
-
-  public JavaCharStream(java.io.Reader dstream,
-                 int startline, int startcolumn, int buffersize)
-  {
-    inputStream = dstream;
-    line = startline;
-    column = startcolumn - 1;
-
-    available = bufsize = buffersize;
-    buffer = new char[buffersize];
-    bufline = new int[buffersize];
-    bufcolumn = new int[buffersize];
-    nextCharBuf = new char[4096];
-  }
-
-  public JavaCharStream(java.io.Reader dstream,
-                                        int startline, int startcolumn)
-  {
-     this(dstream, startline, startcolumn, 4096);
-  }
-
-  public JavaCharStream(java.io.Reader dstream)
-  {
-     this(dstream, 1, 1, 4096);
-  }
-  public void ReInit(java.io.Reader dstream,
-                 int startline, int startcolumn, int buffersize)
-  {
-    inputStream = dstream;
-    line = startline;
-    column = startcolumn - 1;
-
-    if (buffer == null || buffersize != buffer.length)
-    {
-      available = bufsize = buffersize;
-      buffer = new char[buffersize];
-      bufline = new int[buffersize];
-      bufcolumn = new int[buffersize];
-      nextCharBuf = new char[4096];
-    }
-    prevCharIsLF = prevCharIsCR = false;
-    tokenBegin = inBuf = maxNextCharInd = 0;
-    nextCharInd = bufpos = -1;
-  }
-
-  public void ReInit(java.io.Reader dstream,
-                                        int startline, int startcolumn)
-  {
-     ReInit(dstream, startline, startcolumn, 4096);
-  }
-
-  public void ReInit(java.io.Reader dstream)
-  {
-     ReInit(dstream, 1, 1, 4096);
-  }
-  public JavaCharStream(java.io.InputStream dstream, int startline,
-  int startcolumn, int buffersize)
-  {
-     this(new java.io.InputStreamReader(dstream), startline, startcolumn, 4096);
-  }
-
-  public JavaCharStream(java.io.InputStream dstream, int startline,
-                                                           int startcolumn)
-  {
-     this(dstream, startline, startcolumn, 4096);
-  }
-
-  public JavaCharStream(java.io.InputStream dstream)
-  {
-     this(dstream, 1, 1, 4096);
-  }
-
-  public void ReInit(java.io.InputStream dstream, int startline,
-  int startcolumn, int buffersize)
-  {
-     ReInit(new java.io.InputStreamReader(dstream), startline, startcolumn, 4096);
-  }
-  public void ReInit(java.io.InputStream dstream, int startline,
-                                                           int startcolumn)
-  {
-     ReInit(dstream, startline, startcolumn, 4096);
-  }
-  public void ReInit(java.io.InputStream dstream)
-  {
-     ReInit(dstream, 1, 1, 4096);
-  }
-
-  public String GetImage()
-  {
-     if (bufpos >= tokenBegin)
-        return new String(buffer, tokenBegin, bufpos - tokenBegin + 1);
-     else
-        return new String(buffer, tokenBegin, bufsize - tokenBegin) +
-                              new String(buffer, 0, bufpos + 1);
-  }
-
-  public char[] GetSuffix(int len)
-  {
-     char[] ret = new char[len];
-
-     if ((bufpos + 1) >= len)
-        System.arraycopy(buffer, bufpos - len + 1, ret, 0, len);
-     else
-     {
-        System.arraycopy(buffer, bufsize - (len - bufpos - 1), ret, 0,
-                                                          len - bufpos - 1);
-        System.arraycopy(buffer, 0, ret, len - bufpos - 1, bufpos + 1);
-     }
-
-     return ret;
-  }
-
-  public void Done()
-  {
-     nextCharBuf = null;
-     buffer = null;
-     bufline = null;
-     bufcolumn = null;
-  }
-
-  /**
-   * Method to adjust line and column numbers for the start of a token.
-   */
-  public void adjustBeginLineColumn(int newLine, int newCol)
-  {
-     int start = tokenBegin;
-     int len;
-
-     if (bufpos >= tokenBegin)
-     {
-        len = bufpos - tokenBegin + inBuf + 1;
-     }
-     else
-     {
-        len = bufsize - tokenBegin + bufpos + 1 + inBuf;
-     }
-
-     int i = 0, j = 0, k = 0;
-     int nextColDiff = 0, columnDiff = 0;
-
-     while (i < len &&
-            bufline[j = start % bufsize] == bufline[k = ++start % bufsize])
-     {
-        bufline[j] = newLine;
-        nextColDiff = columnDiff + bufcolumn[k] - bufcolumn[j];
-        bufcolumn[j] = newCol + columnDiff;
-        columnDiff = nextColDiff;
-        i++;
-     } 
-
-     if (i < len)
-     {
-        bufline[j] = newLine++;
-        bufcolumn[j] = newCol + columnDiff;
-
-        while (i++ < len)
-        {
-           if (bufline[j = start % bufsize] != bufline[++start % bufsize])
-              bufline[j] = newLine++;
-           else
-              bufline[j] = newLine;
-        }
-     }
-
-     line = bufline[j];
-     column = bufcolumn[j];
-  }
-
-}
+/* Generated By:JavaCC: Do not edit this line. JavaCharStream.java Version 4.0 */
+package name.levering.ryan.sparql.parser;
+
+/**
+ * An implementation of interface CharStream, where the stream is assumed to
+ * contain only ASCII characters (with java-like unicode escape processing).
+ */
+
+public class JavaCharStream
+{
+  public static final boolean staticFlag = false;
+  static final int hexval(char c) throws java.io.IOException {
+    switch(c)
+    {
+       case '0' :
+          return 0;
+       case '1' :
+          return 1;
+       case '2' :
+          return 2;
+       case '3' :
+          return 3;
+       case '4' :
+          return 4;
+       case '5' :
+          return 5;
+       case '6' :
+          return 6;
+       case '7' :
+          return 7;
+       case '8' :
+          return 8;
+       case '9' :
+          return 9;
+
+       case 'a' :
+       case 'A' :
+          return 10;
+       case 'b' :
+       case 'B' :
+          return 11;
+       case 'c' :
+       case 'C' :
+          return 12;
+       case 'd' :
+       case 'D' :
+          return 13;
+       case 'e' :
+       case 'E' :
+          return 14;
+       case 'f' :
+       case 'F' :
+          return 15;
+    }
+
+    throw new java.io.IOException(); // Should never come here
+  }
+
+  public int bufpos = -1;
+  int bufsize;
+  int available;
+  int tokenBegin;
+  protected int bufline[];
+  protected int bufcolumn[];
+
+  protected int column = 0;
+  protected int line = 1;
+
+  protected boolean prevCharIsCR = false;
+  protected boolean prevCharIsLF = false;
+
+  protected java.io.Reader inputStream;
+
+  protected char[] nextCharBuf;
+  protected char[] buffer;
+  protected int maxNextCharInd = 0;
+  protected int nextCharInd = -1;
+  protected int inBuf = 0;
+  protected int tabSize = 8;
+
+  protected void setTabSize(int i) { tabSize = i; }
+  protected int getTabSize(int i) { return tabSize; }
+
+  protected void ExpandBuff(boolean wrapAround)
+  {
+     char[] newbuffer = new char[bufsize + 2048];
+     int newbufline[] = new int[bufsize + 2048];
+     int newbufcolumn[] = new int[bufsize + 2048];
+
+     try
+     {
+        if (wrapAround)
+        {
+           System.arraycopy(buffer, tokenBegin, newbuffer, 0, bufsize - tokenBegin);
+           System.arraycopy(buffer, 0, newbuffer,
+                                             bufsize - tokenBegin, bufpos);
+           buffer = newbuffer;
+
+           System.arraycopy(bufline, tokenBegin, newbufline, 0, bufsize - tokenBegin);
+           System.arraycopy(bufline, 0, newbufline, bufsize - tokenBegin, bufpos);
+           bufline = newbufline;
+
+           System.arraycopy(bufcolumn, tokenBegin, newbufcolumn, 0, bufsize - tokenBegin);
+           System.arraycopy(bufcolumn, 0, newbufcolumn, bufsize - tokenBegin, bufpos);
+           bufcolumn = newbufcolumn;
+
+           bufpos += (bufsize - tokenBegin);
+        }
+        else
+        {
+           System.arraycopy(buffer, tokenBegin, newbuffer, 0, bufsize - tokenBegin);
+           buffer = newbuffer;
+
+           System.arraycopy(bufline, tokenBegin, newbufline, 0, bufsize - tokenBegin);
+           bufline = newbufline;
+
+           System.arraycopy(bufcolumn, tokenBegin, newbufcolumn, 0, bufsize - tokenBegin);
+           bufcolumn = newbufcolumn;
+
+           bufpos -= tokenBegin;
+        }
+     }
+     catch (Throwable t)
+     {
+        throw new Error(t.getMessage());
+     }
+
+     available = (bufsize += 2048);
+     tokenBegin = 0;
+  }
+
+  protected void FillBuff() throws java.io.IOException
+  {
+     int i;
+     if (maxNextCharInd == 4096)
+        maxNextCharInd = nextCharInd = 0;
+
+     try {
+        if ((i = inputStream.read(nextCharBuf, maxNextCharInd,
+                                            4096 - maxNextCharInd)) == -1)
+        {
+           inputStream.close();
+           throw new java.io.IOException();
+        }
+        else
+           maxNextCharInd += i;
+        return;
+     }
+     catch(java.io.IOException e) {
+        if (bufpos != 0)
+        {
+           --bufpos;
+           backup(0);
+        }
+        else
+        {
+           bufline[bufpos] = line;
+           bufcolumn[bufpos] = column;
+        }
+        throw e;
+     }
+  }
+
+  protected char ReadByte() throws java.io.IOException
+  {
+     if (++nextCharInd >= maxNextCharInd)
+        FillBuff();
+
+     return nextCharBuf[nextCharInd];
+  }
+
+  public char BeginToken() throws java.io.IOException
+  {     
+     if (inBuf > 0)
+     {
+        --inBuf;
+
+        if (++bufpos == bufsize)
+           bufpos = 0;
+
+        tokenBegin = bufpos;
+        return buffer[bufpos];
+     }
+
+     tokenBegin = 0;
+     bufpos = -1;
+
+     return readChar();
+  }     
+
+  protected void AdjustBuffSize()
+  {
+     if (available == bufsize)
+     {
+        if (tokenBegin > 2048)
+        {
+           bufpos = 0;
+           available = tokenBegin;
+        }
+        else
+           ExpandBuff(false);
+     }
+     else if (available > tokenBegin)
+        available = bufsize;
+     else if ((tokenBegin - available) < 2048)
+        ExpandBuff(true);
+     else
+        available = tokenBegin;
+  }
+
+  protected void UpdateLineColumn(char c)
+  {
+     column++;
+
+     if (prevCharIsLF)
+     {
+        prevCharIsLF = false;
+        line += (column = 1);
+     }
+     else if (prevCharIsCR)
+     {
+        prevCharIsCR = false;
+        if (c == '\n')
+        {
+           prevCharIsLF = true;
+        }
+        else
+           line += (column = 1);
+     }
+
+     switch (c)
+     {
+        case '\r' :
+           prevCharIsCR = true;
+           break;
+        case '\n' :
+           prevCharIsLF = true;
+           break;
+        case '\t' :
+           column--;
+           column += (tabSize - (column % tabSize));
+           break;
+        default :
+           break;
+     }
+
+     bufline[bufpos] = line;
+     bufcolumn[bufpos] = column;
+  }
+
+  public char readChar() throws java.io.IOException
+  {
+     if (inBuf > 0)
+     {
+        --inBuf;
+
+        if (++bufpos == bufsize)
+           bufpos = 0;
+
+        return buffer[bufpos];
+     }
+
+     char c;
+
+     if (++bufpos == available)
+        AdjustBuffSize();
+
+     if ((buffer[bufpos] = c = ReadByte()) == '\\')
+     {
+        UpdateLineColumn(c);
+
+        int backSlashCnt = 1;
+
+        for (;;) // Read all the backslashes
+        {
+           if (++bufpos == available)
+              AdjustBuffSize();
+
+           try
+           {
+              if ((buffer[bufpos] = c = ReadByte()) != '\\')
+              {
+                 UpdateLineColumn(c);
+                 // found a non-backslash char.
+                 if ((c == 'u') && ((backSlashCnt & 1) == 1))
+                 {
+                    if (--bufpos < 0)
+                       bufpos = bufsize - 1;
+
+                    break;
+                 }
+
+                 backup(backSlashCnt);
+                 return '\\';
+              }
+           }
+           catch(java.io.IOException e)
+           {
+              if (backSlashCnt > 1)
+                 backup(backSlashCnt);
+
+              return '\\';
+           }
+
+           UpdateLineColumn(c);
+           backSlashCnt++;
+        }
+
+        // Here, we have seen an odd number of backslash's followed by a 'u'
+        try
+        {
+           while ((c = ReadByte()) == 'u')
+              ++column;
+
+           buffer[bufpos] = c = (char)(hexval(c) << 12 |
+                                       hexval(ReadByte()) << 8 |
+                                       hexval(ReadByte()) << 4 |
+                                       hexval(ReadByte()));
+
+           column += 4;
+        }
+        catch(java.io.IOException e)
+        {
+           throw new Error("Invalid escape character at line " + line +
+                                         " column " + column + ".");
+        }
+
+        if (backSlashCnt == 1)
+           return c;
+        else
+        {
+           backup(backSlashCnt - 1);
+           return '\\';
+        }
+     }
+     else
+     {
+        UpdateLineColumn(c);
+        return (c);
+     }
+  }
+
+  /**
+   * @deprecated 
+   * @see #getEndColumn
+   */
+
+  public int getColumn() {
+     return bufcolumn[bufpos];
+  }
+
+  /**
+   * @deprecated 
+   * @see #getEndLine
+   */
+
+  public int getLine() {
+     return bufline[bufpos];
+  }
+
+  public int getEndColumn() {
+     return bufcolumn[bufpos];
+  }
+
+  public int getEndLine() {
+     return bufline[bufpos];
+  }
+
+  public int getBeginColumn() {
+     return bufcolumn[tokenBegin];
+  }
+
+  public int getBeginLine() {
+     return bufline[tokenBegin];
+  }
+
+  public void backup(int amount) {
+
+    inBuf += amount;
+    if ((bufpos -= amount) < 0)
+       bufpos += bufsize;
+  }
+
+  public JavaCharStream(java.io.Reader dstream,
+                 int startline, int startcolumn, int buffersize)
+  {
+    inputStream = dstream;
+    line = startline;
+    column = startcolumn - 1;
+
+    available = bufsize = buffersize;
+    buffer = new char[buffersize];
+    bufline = new int[buffersize];
+    bufcolumn = new int[buffersize];
+    nextCharBuf = new char[4096];
+  }
+
+  public JavaCharStream(java.io.Reader dstream,
+                                        int startline, int startcolumn)
+  {
+     this(dstream, startline, startcolumn, 4096);
+  }
+
+  public JavaCharStream(java.io.Reader dstream)
+  {
+     this(dstream, 1, 1, 4096);
+  }
+  public void ReInit(java.io.Reader dstream,
+                 int startline, int startcolumn, int buffersize)
+  {
+    inputStream = dstream;
+    line = startline;
+    column = startcolumn - 1;
+
+    if (buffer == null || buffersize != buffer.length)
+    {
+      available = bufsize = buffersize;
+      buffer = new char[buffersize];
+      bufline = new int[buffersize];
+      bufcolumn = new int[buffersize];
+      nextCharBuf = new char[4096];
+    }
+    prevCharIsLF = prevCharIsCR = false;
+    tokenBegin = inBuf = maxNextCharInd = 0;
+    nextCharInd = bufpos = -1;
+  }
+
+  public void ReInit(java.io.Reader dstream,
+                                        int startline, int startcolumn)
+  {
+     ReInit(dstream, startline, startcolumn, 4096);
+  }
+
+  public void ReInit(java.io.Reader dstream)
+  {
+     ReInit(dstream, 1, 1, 4096);
+  }
+  public JavaCharStream(java.io.InputStream dstream, String encoding, int startline,
+  int startcolumn, int buffersize) throws java.io.UnsupportedEncodingException
+  {
+     this(encoding == null ? new java.io.InputStreamReader(dstream) : new java.io.InputStreamReader(dstream, encoding), startline, startcolumn, buffersize);
+  }
+
+  public JavaCharStream(java.io.InputStream dstream, int startline,
+  int startcolumn, int buffersize)
+  {
+     this(new java.io.InputStreamReader(dstream), startline, startcolumn, 4096);
+  }
+
+  public JavaCharStream(java.io.InputStream dstream, String encoding, int startline,
+                        int startcolumn) throws java.io.UnsupportedEncodingException
+  {
+     this(dstream, encoding, startline, startcolumn, 4096);
+  }
+
+  public JavaCharStream(java.io.InputStream dstream, int startline,
+                        int startcolumn)
+  {
+     this(dstream, startline, startcolumn, 4096);
+  }
+
+  public JavaCharStream(java.io.InputStream dstream, String encoding) throws java.io.UnsupportedEncodingException
+  {
+     this(dstream, encoding, 1, 1, 4096);
+  }
+
+  public JavaCharStream(java.io.InputStream dstream)
+  {
+     this(dstream, 1, 1, 4096);
+  }
+
+  public void ReInit(java.io.InputStream dstream, String encoding, int startline,
+  int startcolumn, int buffersize) throws java.io.UnsupportedEncodingException
+  {
+     ReInit(encoding == null ? new java.io.InputStreamReader(dstream) : new java.io.InputStreamReader(dstream, encoding), startline, startcolumn, buffersize);
+  }
+
+  public void ReInit(java.io.InputStream dstream, int startline,
+  int startcolumn, int buffersize)
+  {
+     ReInit(new java.io.InputStreamReader(dstream), startline, startcolumn, buffersize);
+  }
+  public void ReInit(java.io.InputStream dstream, String encoding, int startline,
+                     int startcolumn) throws java.io.UnsupportedEncodingException
+  {
+     ReInit(dstream, encoding, startline, startcolumn, 4096);
+  }
+  public void ReInit(java.io.InputStream dstream, int startline,
+                     int startcolumn)
+  {
+     ReInit(dstream, startline, startcolumn, 4096);
+  }
+  public void ReInit(java.io.InputStream dstream, String encoding) throws java.io.UnsupportedEncodingException
+  {
+     ReInit(dstream, encoding, 1, 1, 4096);
+  }
+
+  public void ReInit(java.io.InputStream dstream)
+  {
+     ReInit(dstream, 1, 1, 4096);
+  }
+
+  public String GetImage()
+  {
+     if (bufpos >= tokenBegin)
+        return new String(buffer, tokenBegin, bufpos - tokenBegin + 1);
+     else
+        return new String(buffer, tokenBegin, bufsize - tokenBegin) +
+                              new String(buffer, 0, bufpos + 1);
+  }
+
+  public char[] GetSuffix(int len)
+  {
+     char[] ret = new char[len];
+
+     if ((bufpos + 1) >= len)
+        System.arraycopy(buffer, bufpos - len + 1, ret, 0, len);
+     else
+     {
+        System.arraycopy(buffer, bufsize - (len - bufpos - 1), ret, 0,
+                                                          len - bufpos - 1);
+        System.arraycopy(buffer, 0, ret, len - bufpos - 1, bufpos + 1);
+     }
+
+     return ret;
+  }
+
+  public void Done()
+  {
+     nextCharBuf = null;
+     buffer = null;
+     bufline = null;
+     bufcolumn = null;
+  }
+
+  /**
+   * Method to adjust line and column numbers for the start of a token.
+   */
+  public void adjustBeginLineColumn(int newLine, int newCol)
+  {
+     int start = tokenBegin;
+     int len;
+
+     if (bufpos >= tokenBegin)
+     {
+        len = bufpos - tokenBegin + inBuf + 1;
+     }
+     else
+     {
+        len = bufsize - tokenBegin + bufpos + 1 + inBuf;
+     }
+
+     int i = 0, j = 0, k = 0;
+     int nextColDiff = 0, columnDiff = 0;
+
+     while (i < len &&
+            bufline[j = start % bufsize] == bufline[k = ++start % bufsize])
+     {
+        bufline[j] = newLine;
+        nextColDiff = columnDiff + bufcolumn[k] - bufcolumn[j];
+        bufcolumn[j] = newCol + columnDiff;
+        columnDiff = nextColDiff;
+        i++;
+     } 
+
+     if (i < len)
+     {
+        bufline[j] = newLine++;
+        bufcolumn[j] = newCol + columnDiff;
+
+        while (i++ < len)
+        {
+           if (bufline[j = start % bufsize] != bufline[++start % bufsize])
+              bufline[j] = newLine++;
+           else
+              bufline[j] = newLine;
+        }
+     }
+
+     line = bufline[j];
+     column = bufcolumn[j];
+  }
+
+}
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/parser/model/ASTFilterConstraint.java work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTFilterConstraint.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/parser/model/ASTFilterConstraint.java	2006-07-16 19:04:06.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTFilterConstraint.java	2006-08-01 12:53:24.000000000 -0400
@@ -4,6 +4,7 @@
 
 import java.util.Collection;
 import java.util.Collections;
+import java.util.Map;
 import java.util.Set;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
@@ -24,8 +25,8 @@
         return (ExpressionLogic) this.jjtGetChild(0);
     }
 
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets, Collection namedDatasets) {
-        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets, Collection namedDatasets, Map knownValues, Map knownFilters) {
+        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
     }
 
     public Set getVariables() {
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/parser/model/ASTGraphConstraint.java work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTGraphConstraint.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/parser/model/ASTGraphConstraint.java	2006-07-16 19:04:02.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTGraphConstraint.java	2006-08-01 12:52:10.000000000 -0400
@@ -3,6 +3,7 @@
 package name.levering.ryan.sparql.parser.model;
 
 import java.util.Collection;
+import java.util.Map;
 import java.util.Set;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
@@ -40,8 +41,8 @@
         return null;
     }
 
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets, Collection namedDatasets) {
-        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets, Collection namedDatasets, Map knownValues, Map knownFilters) {
+        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
     }
 
     public Set getVariables() {
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/parser/model/ASTGroupConstraint.java work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTGroupConstraint.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/parser/model/ASTGroupConstraint.java	2006-07-16 19:04:04.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTGroupConstraint.java	2006-08-01 12:52:27.000000000 -0400
@@ -6,6 +6,7 @@
 import java.util.Collection;
 import java.util.HashSet;
 import java.util.Iterator;
+import java.util.Map;
 import java.util.Set;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
@@ -39,9 +40,8 @@
         return constraints;
     }
 
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source,
-            Collection defaultDatasets, Collection namedDatasets) {
-        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets, Collection namedDatasets, Map knownValues, Map knownFilters) {
+        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
     }
 
     public Set getVariables() {
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/parser/model/ASTLiteral.java work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTLiteral.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/parser/model/ASTLiteral.java	2006-07-16 19:04:06.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTLiteral.java	2006-07-30 09:13:48.000000000 -0400
@@ -61,4 +61,15 @@
         }
     }
     
+	public int hashCode() {
+		return label.hashCode();
+	}
+	
+	public boolean equals(Object other) {
+		if (!(other instanceof Literal)) return false;
+		Literal lit = (Literal)other;
+		return label.equals(lit.getLabel())
+			&& ((language == null && lit.getLanguage() == null) || (language != null && lit.getLanguage() != null && language.equals(lit.getLanguage())))
+			&& ((datatype == null && lit.getDatatype() == null) || (datatype != null && lit.getDatatype() != null && datatype.equals(lit.getDatatype()))); 
+	}
 }
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/parser/model/ASTOptionalConstraint.java work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTOptionalConstraint.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/parser/model/ASTOptionalConstraint.java	2006-07-16 19:04:06.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTOptionalConstraint.java	2006-08-01 12:52:44.000000000 -0400
@@ -3,6 +3,7 @@
 package name.levering.ryan.sparql.parser.model;
 
 import java.util.Collection;
+import java.util.Map;
 import java.util.Set;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
@@ -24,8 +25,8 @@
         return (GroupConstraint) this.jjtGetChild(0);
     }
 
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets, Collection namedDatasets) {
-        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets, Collection namedDatasets, Map knownValues, Map knownFilters) {
+        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
     }
 
     public Set getVariables() {
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/parser/model/ASTUnionConstraint.java work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTUnionConstraint.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/parser/model/ASTUnionConstraint.java	2006-07-16 19:04:04.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTUnionConstraint.java	2006-08-01 12:52:55.000000000 -0400
@@ -6,6 +6,7 @@
 import java.util.Collection;
 import java.util.HashSet;
 import java.util.Iterator;
+import java.util.Map;
 import java.util.Set;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
@@ -31,8 +32,8 @@
         return constraints;
     }
 
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets, Collection namedDatasets) {
-        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets, Collection namedDatasets, Map knownValues, Map knownFilters) {
+        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
     }
 
     public Set getVariables() {
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/parser/model/ASTWithExtension.java work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTWithExtension.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/parser/model/ASTWithExtension.java	2006-07-16 19:04:02.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTWithExtension.java	2006-08-01 12:48:48.000000000 -0400
@@ -6,6 +6,7 @@
 import java.util.Collections;
 import java.util.List;
 import java.util.Set;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.QueryException;
 import name.levering.ryan.sparql.common.RdfBindingSet;
@@ -25,8 +26,8 @@
         super(id);
     }
     
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets, Collection namedDatasets) {
-        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets, Collection namedDatasets, Map knownValues, Map knownFilters) {
+        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
     }
 
     public URI getName() {
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/parser/model/DelegatingTripleConstraint.java work-copy/src/main/name/levering/ryan/sparql/parser/model/DelegatingTripleConstraint.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/parser/model/DelegatingTripleConstraint.java	2006-07-16 19:04:02.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/DelegatingTripleConstraint.java	2006-08-01 12:25:56.000000000 -0400
@@ -7,6 +7,7 @@
 
 import java.util.Collection;
 import java.util.HashSet;
+import java.util.Map;
 import java.util.Set;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
@@ -39,8 +40,8 @@
         return this.statement.getObjectExpression();
     }
 
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets, Collection namedDatasets) {
-        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets, Collection namedDatasets, Map knownValues, Map knownFilters) {
+        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets, knownValues, knownFilters);
     }
 
     public Set getVariables() {
@@ -64,5 +65,5 @@
     public void setLogic(ConstraintLogic logic) {
         this.logic = logic;
     }
-
+	
 }
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/parser/model/JJTSPARQLParserState.java work-copy/src/main/name/levering/ryan/sparql/parser/model/JJTSPARQLParserState.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/parser/model/JJTSPARQLParserState.java	2006-08-01 11:34:51.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/JJTSPARQLParserState.java	2006-08-01 11:46:36.000000000 -0400
@@ -1,4 +1,4 @@
-/* Generated By:JJTree: Do not edit this line. /home/tauberer/dev/semweb/sparql/sparql-0.8/src/main/name/levering/ryan/sparql/parser/model/JJTSPARQLParserState.java */
+/* Generated By:JJTree: Do not edit this line. /home/tauberer/dev/semweb/sparql/work-copy/src/main/name/levering/ryan/sparql/parser/model/JJTSPARQLParserState.java */
 
 package name.levering.ryan.sparql.parser.model;
 
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/parser/model/SPARQLParserTreeConstants.java work-copy/src/main/name/levering/ryan/sparql/parser/model/SPARQLParserTreeConstants.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/parser/model/SPARQLParserTreeConstants.java	2006-08-01 11:35:04.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/SPARQLParserTreeConstants.java	2006-08-02 07:55:57.000000000 -0400
@@ -1,4 +1,4 @@
-/* Generated By:JJTree: Do not edit this line. /home/tauberer/dev/semweb/sparql/sparql-0.8/src/main/name/levering/ryan/sparql/parser/model/SPARQLParserTreeConstants.java */
+/* Generated By:JJTree: Do not edit this line. /home/tauberer/dev/semweb/sparql/work-copy/src/main/name/levering/ryan/sparql/parser/model/SPARQLParserTreeConstants.java */
 
 package name.levering.ryan.sparql.parser.model;
 
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/parser/SPARQLParser.java work-copy/src/main/name/levering/ryan/sparql/parser/SPARQLParser.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/parser/SPARQLParser.java	2006-08-01 11:35:06.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/SPARQLParser.java	2006-08-02 07:55:59.000000000 -0400
@@ -4158,7 +4158,10 @@
   private int jj_gc = 0;
 
   public SPARQLParser(java.io.InputStream stream) {
-    jj_input_stream = new JavaCharStream(stream, 1, 1);
+     this(stream, null);
+  }
+  public SPARQLParser(java.io.InputStream stream, String encoding) {
+    try { jj_input_stream = new JavaCharStream(stream, encoding, 1, 1); } catch(java.io.UnsupportedEncodingException e) { throw new RuntimeException(e); }
     token_source = new SPARQLParserTokenManager(jj_input_stream);
     token = new Token();
     jj_ntk = -1;
@@ -4168,7 +4171,10 @@
   }
 
   public void ReInit(java.io.InputStream stream) {
-    jj_input_stream.ReInit(stream, 1, 1);
+     ReInit(stream, null);
+  }
+  public void ReInit(java.io.InputStream stream, String encoding) {
+    try { jj_input_stream.ReInit(stream, encoding, 1, 1); } catch(java.io.UnsupportedEncodingException e) { throw new RuntimeException(e); }
     token_source.ReInit(jj_input_stream);
     token = new Token();
     jj_ntk = -1;
@@ -4374,6 +4380,7 @@
   final private void jj_rescan_token() {
     jj_rescan = true;
     for (int i = 0; i < 4; i++) {
+    try {
       JJCalls p = jj_2_rtns[i];
       do {
         if (p.gen > jj_gen) {
@@ -4387,6 +4394,7 @@
         }
         p = p.next;
       } while (p != null);
+      } catch(LookaheadSuccess ls) { }
     }
     jj_rescan = false;
   }
diff -urN --exclude=.svn sparql-0.8/src/main/name/levering/ryan/sparql/parser/SPARQLParserTokenManager.java work-copy/src/main/name/levering/ryan/sparql/parser/SPARQLParserTokenManager.java
--- sparql-0.8/src/main/name/levering/ryan/sparql/parser/SPARQLParserTokenManager.java	2006-08-01 11:35:06.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/SPARQLParserTokenManager.java	2006-08-02 07:55:59.000000000 -0400
@@ -3460,14 +3460,12 @@
 int jjimageLen;
 int lengthOfMatch;
 protected char curChar;
-public SPARQLParserTokenManager(JavaCharStream stream)
-{
+public SPARQLParserTokenManager(JavaCharStream stream){
    if (JavaCharStream.staticFlag)
       throw new Error("ERROR: Cannot use a static CharStream class with a non-static lexical analyzer.");
    input_stream = stream;
 }
-public SPARQLParserTokenManager(JavaCharStream stream, int lexState)
-{
+public SPARQLParserTokenManager(JavaCharStream stream, int lexState){
    this(stream);
    SwitchTo(lexState);
 }
@@ -3648,9 +3646,8 @@
    {
       case 10 :
          if (image == null)
-            image = new StringBuffer(new String(input_stream.GetSuffix(jjimageLen + (lengthOfMatch = jjmatchedPos + 1))));
-         else
-            image.append(input_stream.GetSuffix(jjimageLen + (lengthOfMatch = jjmatchedPos + 1)));
+            image = new StringBuffer();
+         image.append(input_stream.GetSuffix(jjimageLen + (lengthOfMatch = jjmatchedPos + 1)));
            input_stream.backup(1);
          break;
       default :
diff -urN --exclude=.svn sparql-0.8/src/tests/Creator.java work-copy/src/tests/Creator.java
--- sparql-0.8/src/tests/Creator.java	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/tests/Creator.java	2006-07-30 09:08:08.000000000 -0400
@@ -0,0 +1,38 @@
+import java.io.FileWriter;
+import java.io.IOException;
+
+/**
+ * This is a utility class used to generate a huge RDF data file.
+ * 
+ * @author Ryan Levering
+ */
+public class Creator {
+
+    /**
+     * The file name to create.
+     */
+    private static final String FILE_NAME = "simple.ttl";
+    
+    /**
+     * Creates a new file in the working directory and fill it with really simple
+     * repetitive data.
+     * 
+     * @param args ignored
+     */
+    public static void main(String[] args) throws IOException {
+        FileWriter writer = new FileWriter(FILE_NAME);
+        writer.write("@prefix foaf:       <http://xmlns.com/foaf/0.1/> .\n\n");
+
+        for (int i = 0; i < 10000; i += 2) {
+            writer.write("_:a" + i + "  foaf:name       \"Alice\".\n");
+            writer.write("_:a" + i
+                    + "  foaf:mbox       <mailto:alice@work.example> .\n");
+            writer.write("_:a" + (i + 1) + "  foaf:name       \"Ms A.\".\n");
+            writer.write("_:a" + (i + 1)
+                    + "  foaf:mbox       <mailto:alice@work.example> .\n");
+        }
+        writer.flush();
+        writer.close();
+    }
+
+}
Binary files sparql-0.8/temp/lib/sparql-core.jar and work-copy/temp/lib/sparql-core.jar differ
