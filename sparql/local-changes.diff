diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/build.xml work-copy/build.xml
--- upstream/build.xml	2006-08-20 20:01:02.000000000 -0400
+++ work-copy/build.xml	2006-12-02 11:01:18.000000000 -0500
@@ -8,7 +8,7 @@
      Ryan Levering
      ====================================================================== -->
 <project name="SPARQL Parser" default="dist_from_grammar">
-	
+
 	<!-- STRUCTURE PROPERTIES -->
 	<property name="srcdir" value="src/main" />
 	<property name="testdir" value="src/tests" />
@@ -76,12 +76,12 @@
 		<jar basedir="${temp_dir}" destfile="${libdir}/${library}" />
 		<delete dir="${temp_dir}" />
 		<mkdir dir="${temp_dir}" />
-		<javac srcdir="${testdir}" destdir="${temp_dir}">
+		<!--<javac srcdir="${testdir}" destdir="${temp_dir}">
 			<classpath>
 				<path refid="test.classpath" />
 				<pathelement path="${libdir}/${library}" />
 			</classpath>
-		</javac>
+		</javac>-->
 		<copy todir="${temp_dir}" includeemptydirs="false">
 			<fileset dir="test_files">
 				<include name="**/*" />
@@ -92,6 +92,7 @@
 	</target>
 	
 	<!-- THIS WILL BUILD THE SOURCE AND TEST IT AGAINST THE GENERIC TEST CASES -->
+	<!--
 	<target name="test" depends="jar">
 		<junit printsummary="yes" fork="yes" haltonfailure="yes">
 			<classpath>
@@ -103,6 +104,7 @@
 			<formatter type="plain" usefile="false" />
 		</junit>
 	</target>
+	-->
 		
 	<!-- THIS WILL CREATE THE JAVADOCS IN THE DOCS FOLDER -->
 	<!-- THIS ISN'T USED FOR DISTRIBUTION, BUT CAN BE USED BY END USER -->
@@ -174,4 +176,4 @@
 	<!-- THIS WILL BUILD THE WHOLE DISTRIBUTION FROM GRAMMAR -->
 	<target name="dist_from_grammar" depends="grammar,dist" />
 
-</project>
\ No newline at end of file
+</project>
Binary files upstream/lib/sparql-core.jar and work-copy/lib/sparql-core.jar differ
Binary files upstream/lib/sparql-tests.jar and work-copy/lib/sparql-tests.jar differ
Binary files upstream/sparql-0.8.zip and work-copy/sparql-0.8.zip differ
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/common/AdvancedRdfSource.java work-copy/src/main/name/levering/ryan/sparql/common/AdvancedRdfSource.java
--- upstream/src/main/name/levering/ryan/sparql/common/AdvancedRdfSource.java	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/common/AdvancedRdfSource.java	2006-12-02 11:00:47.000000000 -0500
@@ -0,0 +1,26 @@
+/*
+ * SPARQL Engine
+ * Copyright (C) 2005 Ryan Levering, All rights reserved.
+ * See LICENSE for full license information
+ */
+package name.levering.ryan.sparql.common;
+
+import java.util.Iterator;
+import java.util.List;
+
+import org.openrdf.model.URI;
+import org.openrdf.model.Value;
+import org.openrdf.model.ValueFactory;
+
+/**
+ * Description...
+ * 
+ * @author Joshua Tauberer
+ * @version 1.0
+ */
+public interface AdvancedRdfSource extends RdfSource {
+    public Iterator getStatements(Value[] subj, Value[] pred, Value[] obj, URI[] graph, Object[] litFilters);
+    public Iterator getDefaultStatements(Value[] subj, Value[] pred, Value[] obj, Object[] litFilters);
+    public Iterator getStatements(Value[] subj, Value[] pred, Value[] obj, Object[] litFilters);
+}
+
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/common/impl/RdfBindingSetImpl.java work-copy/src/main/name/levering/ryan/sparql/common/impl/RdfBindingSetImpl.java
--- upstream/src/main/name/levering/ryan/sparql/common/impl/RdfBindingSetImpl.java	2006-08-20 20:00:59.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/common/impl/RdfBindingSetImpl.java	2007-02-17 11:09:33.000000000 -0500
@@ -98,6 +98,8 @@
 		for (Iterator oldRows = oldSet.iterator(); oldRows.hasNext();) {
 			this.addRow((RdfBindingRow) oldRows.next());
 		}
+		setDistinct(oldSet.isDistinct());
+		setOrdered(oldSet.isOrdered());
 	}
 
 	/**
@@ -141,11 +143,10 @@
 		if (row == null) {
 			throw new NullPointerException("RdfBindingRow 'row' cannot be null");
 		}
-		List newValues = new ArrayList();
-		for (int i = 0; i < this.variables.length; i++) {
-			newValues.add(row.getValue(this.variables[i]));
-		}
-		this.values.add(newValues.toArray(new Value[0]));
+		Value[] newValues = new Value[this.variables.length];
+		for (int i = 0; i < this.variables.length; i++)
+			newValues[i] = row.getValue(this.variables[i]);
+		this.values.add(newValues);
 	}
 
 	/**
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/extensions/fpredicates/FunctionalPredicateLogic.java work-copy/src/main/name/levering/ryan/sparql/extensions/fpredicates/FunctionalPredicateLogic.java
--- upstream/src/main/name/levering/ryan/sparql/extensions/fpredicates/FunctionalPredicateLogic.java	2006-08-20 20:00:59.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/extensions/fpredicates/FunctionalPredicateLogic.java	2007-02-21 07:08:18.000000000 -0500
@@ -1,6 +1,7 @@
 package name.levering.ryan.sparql.extensions.fpredicates;
 
 import java.util.Collection;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -41,10 +42,9 @@
 	 * @param namedDatasets the named graphs, ignored
 	 * @return a binding set according to the function
 	 */
-	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
 		
-		return this.function.getBindingSet(this.data.getSubjectExpression(), this.data.getObjectExpression(), source);
+		return this.function.getBindingSet(this.data.getSubjectExpression(), this.data.getObjectExpression(), p.source);
 	}
 
 }
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/IsMaxFunction.java work-copy/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/IsMaxFunction.java
--- upstream/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/IsMaxFunction.java	2006-08-20 20:00:59.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/IsMaxFunction.java	2006-12-02 11:00:47.000000000 -0500
@@ -128,7 +128,7 @@
 		return new ExternalFunctionFactory() {
 
 			public ExternalFunction create(LogicFactory logicFactory, SPARQLValueFactory valueFactory) {
-				return new IsMaxFunction(logicFactory.getValueOrderingLogic());
+				return new IsMaxFunction(logicFactory.getValueOrderingLogic(valueFactory));
 			}
 
 		};
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/IsMinFunction.java work-copy/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/IsMinFunction.java
--- upstream/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/IsMinFunction.java	2006-08-20 20:00:59.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/IsMinFunction.java	2006-12-02 11:00:47.000000000 -0500
@@ -126,7 +126,7 @@
 		return new ExternalFunctionFactory() {
 
 			public ExternalFunction create(LogicFactory logicFactory, SPARQLValueFactory valueFactory) {
-				return new IsMinFunction(logicFactory.getValueOrderingLogic());
+				return new IsMinFunction(logicFactory.getValueOrderingLogic(valueFactory));
 			}
 
 		};
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/MaxFunction.java work-copy/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/MaxFunction.java
--- upstream/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/MaxFunction.java	2006-08-20 20:00:59.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/MaxFunction.java	2006-12-02 11:00:47.000000000 -0500
@@ -121,7 +121,7 @@
 		return new ExternalFunctionFactory() {
 
 			public ExternalFunction create(LogicFactory logicFactory, SPARQLValueFactory valueFactory) {
-				return new MaxFunction(logicFactory.getValueOrderingLogic());
+				return new MaxFunction(logicFactory.getValueOrderingLogic(valueFactory));
 			}
 
 		};
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/MinFunction.java work-copy/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/MinFunction.java
--- upstream/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/MinFunction.java	2006-08-20 20:00:59.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/extensions/functions/aggregate/MinFunction.java	2006-12-02 11:00:47.000000000 -0500
@@ -121,7 +121,7 @@
 		return new ExternalFunctionFactory() {
 
 			public ExternalFunction create(LogicFactory logicFactory, SPARQLValueFactory valueFactory) {
-				return new MinFunction(logicFactory.getValueOrderingLogic());
+				return new MinFunction(logicFactory.getValueOrderingLogic(valueFactory));
 			}
 
 		};
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/extensions/with/DefaultWithConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/extensions/with/DefaultWithConstraintLogic.java
--- upstream/src/main/name/levering/ryan/sparql/extensions/with/DefaultWithConstraintLogic.java	2006-08-20 20:00:59.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/extensions/with/DefaultWithConstraintLogic.java	2007-02-21 07:07:42.000000000 -0500
@@ -1,6 +1,7 @@
 package name.levering.ryan.sparql.extensions.with;
 
 import java.util.Collection;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -43,10 +44,9 @@
 	 * @param namedDatasets the named data sets to query against, ignored
 	 * @return the binding set created by the extension
 	 */
-	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
 		return this.extension.getBindingSet((ExpressionLogic[]) this.data.getArguments().toArray(
-				new ExpressionLogic[] {}), source);
+				new ExpressionLogic[] {}), p.source);
 	}
 
 }
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/BaseLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/BaseLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/BaseLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/BaseLogic.java	2006-12-02 11:01:18.000000000 -0500
@@ -345,8 +345,8 @@
 	 * 
 	 * @return the logic that orders Value objects
 	 */
-	public ValueOrderingLogic getValueOrderingLogic() {
-		return new DefaultValueOrderingLogic();
+	public ValueOrderingLogic getValueOrderingLogic(SPARQLValueFactory valueFactory) {
+		return new DefaultValueOrderingLogic(getNumericPromotionLogic(valueFactory), getValueConversionLogic(valueFactory));
 	}
 
 }
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/BNodeRenamingConstructQueryLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/BNodeRenamingConstructQueryLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/BNodeRenamingConstructQueryLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/BNodeRenamingConstructQueryLogic.java	2007-02-21 07:51:02.000000000 -0500
@@ -22,6 +22,7 @@
 import name.levering.ryan.sparql.model.GroupConstraint;
 import name.levering.ryan.sparql.model.TripleConstraint;
 import name.levering.ryan.sparql.model.data.ConstructQueryData;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
 import name.levering.ryan.sparql.model.logic.ConstructQueryLogic;
 import name.levering.ryan.sparql.model.logic.OrderExpressionLogic;
 import name.levering.ryan.sparql.model.logic.helper.SetRangeLogic;
@@ -85,16 +86,20 @@
 	 * @return an RDF graph containing the formed triples
 	 */
 	public RdfGraph execute(RdfSource source) {
+		ConstraintLogic.CallParams p = new ConstraintLogic.CallParams();
+		p.bindings = new RdfBindingSetImpl();
+		p.source = source;
+		
 		// Grab the necessary fields from the data
 		GroupConstraint constraint = this.data.getConstraint();
-		Collection defaultDatasets = this.data.getDefaultDatasets();
-		Collection namedDatasets = this.data.getNamedDatasets();
+		p.defaultDatasets = this.data.getDefaultDatasets();
+		p.namedDatasets = this.data.getNamedDatasets();
 		List orderExpressions = this.data.getOrderExpressions();
 		int limit = this.data.getLimit();
 		int offset = this.data.getOffset();
 
 		// First bind the result table
-		RdfBindingSet results = constraint.constrain(new RdfBindingSetImpl(), source, defaultDatasets, namedDatasets);
+		RdfBindingSet results = constraint.constrain(p);
 
 		// Now apply ordering in reverse order to give priority to the first
 		// variable
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/debug/DebugLogicWrapper.java work-copy/src/main/name/levering/ryan/sparql/logic/debug/DebugLogicWrapper.java
--- upstream/src/main/name/levering/ryan/sparql/logic/debug/DebugLogicWrapper.java	2006-12-02 11:09:25.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/debug/DebugLogicWrapper.java	2006-12-02 11:11:22.000000000 -0500
@@ -173,8 +173,8 @@
 		return new OptionalConstraintDebug(this.baseFactory.getOptionalConstraintLogic(data, valueFactory), this.out);
 	}
 
-	public OrderExpressionLogic getOrderExpressionLogic(OrderExpressionData data) {
-		return this.baseFactory.getOrderExpressionLogic(data);
+	public OrderExpressionLogic getOrderExpressionLogic(OrderExpressionData data, SPARQLValueFactory valueFactory) {
+		return this.baseFactory.getOrderExpressionLogic(data, valueFactory);
 	}
 
 	public ExpressionLogic getOrLogic(BinaryExpressionData data, SPARQLValueFactory valueFactory) {
@@ -236,8 +236,8 @@
 		return this.baseFactory.getValueConversionLogic(valueFactory);
 	}
 
-	public ValueOrderingLogic getValueOrderingLogic() {
-		return this.baseFactory.getValueOrderingLogic();
+	public ValueOrderingLogic getValueOrderingLogic(SPARQLValueFactory valueFactory) {
+		return this.baseFactory.getValueOrderingLogic(valueFactory);
 	}
 
 	public ConstructQueryLogic getConstructQueryLogic(ExtendedConstructQueryData data, SPARQLValueFactory valueFactory) {
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/debug/FilterConstraintDebug.java work-copy/src/main/name/levering/ryan/sparql/logic/debug/FilterConstraintDebug.java
--- upstream/src/main/name/levering/ryan/sparql/logic/debug/FilterConstraintDebug.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/debug/FilterConstraintDebug.java	2007-02-21 07:09:08.000000000 -0500
@@ -1,6 +1,7 @@
 package name.levering.ryan.sparql.logic.debug;
 
 import java.util.Collection;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -19,11 +20,10 @@
 		this.out = listener;
 	}
 	
-	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
-        this.out.filterConstraintPreExecute(this.data, bindings);
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+        this.out.filterConstraintPreExecute(this.data, p.bindings);
         long start = System.currentTimeMillis();
-        RdfBindingSet returnSet = this.filterLogic.constrain(bindings, source, defaultDatasets, namedDatasets);
+        RdfBindingSet returnSet = this.filterLogic.constrain(p);
         long end = System.currentTimeMillis();
         this.out.filterConstraintPostExecute(end-start, returnSet);
         return returnSet;
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/debug/GraphConstraintDebug.java work-copy/src/main/name/levering/ryan/sparql/logic/debug/GraphConstraintDebug.java
--- upstream/src/main/name/levering/ryan/sparql/logic/debug/GraphConstraintDebug.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/debug/GraphConstraintDebug.java	2007-02-21 07:09:15.000000000 -0500
@@ -1,6 +1,7 @@
 package name.levering.ryan.sparql.logic.debug;
 
 import java.util.Collection;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -16,11 +17,10 @@
 		this.out = listener;
 	}
 
-	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
         this.out.graphConstraintPreExecute();
         long start = System.currentTimeMillis();
-        RdfBindingSet returnSet = this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+        RdfBindingSet returnSet = this.logic.constrain(p);
         long end = System.currentTimeMillis();
         this.out.graphConstraintPostExecute(end-start, returnSet);
         return returnSet;
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/debug/GroupConstraintDebug.java work-copy/src/main/name/levering/ryan/sparql/logic/debug/GroupConstraintDebug.java
--- upstream/src/main/name/levering/ryan/sparql/logic/debug/GroupConstraintDebug.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/debug/GroupConstraintDebug.java	2007-02-21 07:09:19.000000000 -0500
@@ -1,6 +1,7 @@
 package name.levering.ryan.sparql.logic.debug;
 
 import java.util.Collection;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -16,11 +17,10 @@
 		this.out = listener;
 	}
 
-	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
         this.out.groupConstraintPreExecute();
         long start = System.currentTimeMillis();
-        RdfBindingSet returnSet = this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+        RdfBindingSet returnSet = this.logic.constrain(p);
         long end = System.currentTimeMillis();
         this.out.groupConstraintPostExecute(end-start, returnSet);
         return returnSet;
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/debug/OptionalConstraintDebug.java work-copy/src/main/name/levering/ryan/sparql/logic/debug/OptionalConstraintDebug.java
--- upstream/src/main/name/levering/ryan/sparql/logic/debug/OptionalConstraintDebug.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/debug/OptionalConstraintDebug.java	2007-02-21 07:09:24.000000000 -0500
@@ -1,6 +1,7 @@
 package name.levering.ryan.sparql.logic.debug;
 
 import java.util.Collection;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -16,11 +17,10 @@
 		this.out = listener;
 	}
 
-	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
         this.out.optionalConstraintPreExecute();
         long start = System.currentTimeMillis();
-        RdfBindingSet returnSet = this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+        RdfBindingSet returnSet = this.logic.constrain(p);
         long end = System.currentTimeMillis();
         this.out.optionalConstraintPostExecute(end-start, returnSet);
         return returnSet;
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/debug/TripleConstraintDebug.java work-copy/src/main/name/levering/ryan/sparql/logic/debug/TripleConstraintDebug.java
--- upstream/src/main/name/levering/ryan/sparql/logic/debug/TripleConstraintDebug.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/debug/TripleConstraintDebug.java	2007-02-21 07:09:43.000000000 -0500
@@ -6,6 +6,7 @@
 package name.levering.ryan.sparql.logic.debug;
 
 import java.util.Collection;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -24,11 +25,10 @@
         this.out = listener;
     }
 
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source,
-            Collection defaultDatasets, Collection namedDatasets) {
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
         this.out.tripleFetchPreExecute(this.data);
         long start = System.currentTimeMillis();
-        RdfBindingSet returnSet = this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+        RdfBindingSet returnSet = this.logic.constrain(p);
         long end = System.currentTimeMillis();
         this.out.tripleFetchPostExecute(end-start, returnSet);
         return returnSet;
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/debug/UnionConstraintDebug.java work-copy/src/main/name/levering/ryan/sparql/logic/debug/UnionConstraintDebug.java
--- upstream/src/main/name/levering/ryan/sparql/logic/debug/UnionConstraintDebug.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/debug/UnionConstraintDebug.java	2007-02-21 07:09:49.000000000 -0500
@@ -1,6 +1,7 @@
 package name.levering.ryan.sparql.logic.debug;
 
 import java.util.Collection;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -16,11 +17,10 @@
 		this.out = listener;
 	}
 
-	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
         this.out.unionConstrainPreExecute();
         long start = System.currentTimeMillis();
-        RdfBindingSet returnSet = this.unionLogic.constrain(bindings, source, defaultDatasets, namedDatasets);
+        RdfBindingSet returnSet = this.unionLogic.constrain(p);
         long end = System.currentTimeMillis();
         this.out.unionConstraintPostExecute(end-start, returnSet);
         return returnSet;
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/DefaultAskQueryLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/DefaultAskQueryLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/DefaultAskQueryLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/DefaultAskQueryLogic.java	2007-02-21 07:51:29.000000000 -0500
@@ -13,6 +13,7 @@
 import name.levering.ryan.sparql.model.GroupConstraint;
 import name.levering.ryan.sparql.model.data.AskQueryData;
 import name.levering.ryan.sparql.model.logic.AskQueryLogic;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
 
 /**
  * This is the simplest query logic in SPARQL, as it doesn't have to deal with
@@ -48,14 +49,17 @@
      * @return true if the delegated query data binds any value rows
      */
     public boolean execute(RdfSource source) {
-        // Grab the necessary fields from the data
+		  ConstraintLogic.CallParams p = new ConstraintLogic.CallParams();
+		  p.bindings = new RdfBindingSetImpl();
+		  p.source = source;
+
+		  // Grab the necessary fields from the data
         GroupConstraint constraint = this.data.getConstraint();
-        Collection defaultDatasets = this.data.getDefaultDatasets();
-        Collection namedDatasets = this.data.getNamedDatasets();
+        p.defaultDatasets = this.data.getDefaultDatasets();
+        p.namedDatasets = this.data.getNamedDatasets();
 
         // First bind the result table
-        RdfBindingSet results = constraint.constrain(new RdfBindingSetImpl(),
-                source, defaultDatasets, namedDatasets);
+        RdfBindingSet results = constraint.constrain(p);
 
         // Return whether or not the iterator returns any rows
         return results.iterator().hasNext();
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/DefaultConstructQueryLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/DefaultConstructQueryLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/DefaultConstructQueryLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/DefaultConstructQueryLogic.java	2007-02-21 07:51:22.000000000 -0500
@@ -22,6 +22,7 @@
 import name.levering.ryan.sparql.model.GroupConstraint;
 import name.levering.ryan.sparql.model.TripleConstraint;
 import name.levering.ryan.sparql.model.data.ConstructQueryData;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
 import name.levering.ryan.sparql.model.logic.ConstructQueryLogic;
 import name.levering.ryan.sparql.model.logic.OrderExpressionLogic;
 import name.levering.ryan.sparql.model.logic.helper.GraphTranslationLogic;
@@ -30,6 +31,7 @@
 import org.openrdf.model.BNode;
 import org.openrdf.model.URI;
 import org.openrdf.model.Value;
+import org.openrdf.model.BNode;
 
 /**
  * This query logic constructs an RDF graph by applying an RDF template to a set
@@ -79,17 +81,20 @@
      * @return an RDF graph containing the formed triples
      */
     public RdfGraph execute(RdfSource source) {
+		  ConstraintLogic.CallParams p = new ConstraintLogic.CallParams();
+		  p.bindings = new RdfBindingSetImpl();
+		  p.source = source;
+		
         // Grab the necessary fields from the data
         GroupConstraint constraint = this.data.getConstraint();
-        Collection defaultDatasets = this.data.getDefaultDatasets();
-        Collection namedDatasets = this.data.getNamedDatasets();
+        p.defaultDatasets = this.data.getDefaultDatasets();
+        p.namedDatasets = this.data.getNamedDatasets();
         List orderExpressions = this.data.getOrderExpressions();
         int limit = this.data.getLimit();
         int offset = this.data.getOffset();
 
         // First bind the result table
-        RdfBindingSet results = constraint.constrain(new RdfBindingSetImpl(),
-                source, defaultDatasets, namedDatasets);
+        RdfBindingSet results = constraint.constrain(p);
 
         // Now apply ordering in reverse order to give priority to the first
         // variable
@@ -105,7 +110,7 @@
         if (offset >= 0) {
             results = this.rangeLogic.offset(results, offset);
         }
-
+		
         return this.translationLogic.translate(this.data.getTriples(), results);
     }
 
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/DefaultDescribeQueryLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/DefaultDescribeQueryLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/DefaultDescribeQueryLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/DefaultDescribeQueryLogic.java	2007-02-21 07:51:39.000000000 -0500
@@ -22,6 +22,7 @@
 import name.levering.ryan.sparql.common.impl.RdfGraphImpl;
 import name.levering.ryan.sparql.model.GroupConstraint;
 import name.levering.ryan.sparql.model.data.DescribeQueryData;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
 import name.levering.ryan.sparql.model.logic.DescribeQueryLogic;
 import name.levering.ryan.sparql.model.logic.OrderExpressionLogic;
 import name.levering.ryan.sparql.model.logic.helper.SetProjectionLogic;
@@ -83,17 +84,23 @@
 	 * @return an RDF graph containing the formed triples
 	 */
 	public RdfGraph execute(RdfSource source) {
+		ConstraintLogic.CallParams p = new ConstraintLogic.CallParams();
+		p.bindings = new RdfBindingSetImpl();
+		p.source = source;
+		
 		// Grab the necessary fields from the data
 		GroupConstraint constraint = this.data.getConstraint();
-		Collection defaultDatasets = this.data.getDefaultDatasets();
-		Collection namedDatasets = this.data.getNamedDatasets();
+		p.defaultDatasets = this.data.getDefaultDatasets();
+		p.namedDatasets = this.data.getNamedDatasets();
 		List orderExpressions = this.data.getOrderExpressions();
 		List queryResources = this.data.getQueryResources();
 		int limit = this.data.getLimit();
 		int offset = this.data.getOffset();
 
 		// First bind the result table
-		RdfBindingSet results = constraint.constrain(new RdfBindingSetImpl(), source, defaultDatasets, namedDatasets);
+		RdfBindingSet results = new RdfBindingSetImpl();
+		if (constraint != null)
+			results = constraint.constrain(p);
 
 		// Now project to the solution set
 		List variables = new ArrayList();
@@ -106,7 +113,7 @@
 		results = this.logic.project(results, variables);
 
 		// Now apply ordering in reverse order
-		for (int i = orderExpressions.size(); i >= 0; i--) {
+		for (int i = orderExpressions.size()-1; i >= 0; i--) {
 			OrderExpressionLogic orderer = (OrderExpressionLogic) orderExpressions.get(i);
 			orderer.order(results);
 		}
@@ -182,7 +189,7 @@
 					descriptions.addAll(describe(statement.getObject(), source, alreadyDescribed));
 				}
 			}
-			descriptions.add(statements.next());
+			descriptions.add(statement);
 		}
 		return descriptions;
 	}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/DefaultSelectQueryLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/DefaultSelectQueryLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/DefaultSelectQueryLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/DefaultSelectQueryLogic.java	2007-02-21 07:51:46.000000000 -0500
@@ -12,6 +12,7 @@
 import name.levering.ryan.sparql.common.RdfSource;
 import name.levering.ryan.sparql.model.GroupConstraint;
 import name.levering.ryan.sparql.model.data.SelectQueryData;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
 import name.levering.ryan.sparql.model.logic.OrderExpressionLogic;
 import name.levering.ryan.sparql.model.logic.SelectQueryLogic;
 import name.levering.ryan.sparql.model.logic.helper.SetDistinctionLogic;
@@ -74,10 +75,13 @@
      * @return an RDF graph containing the formed triples
      */
     public RdfBindingSet execute(RdfSource source) {
+		  ConstraintLogic.CallParams p = new ConstraintLogic.CallParams();
+		  p.source = source;
+		
         // Grab the necessary fields from the data
         GroupConstraint constraint = this.data.getConstraint();
-        Collection defaultDatasets = this.data.getDefaultDatasets();
-        Collection namedDatasets = this.data.getNamedDatasets();
+        p.defaultDatasets = this.data.getDefaultDatasets();
+        p.namedDatasets = this.data.getNamedDatasets();
         List orderExpressions = this.data.getOrderExpressions();
         List queryExpressions = this.data.getQueryVariables();
         int limit = this.data.getLimit();
@@ -85,8 +89,7 @@
         boolean distinct = this.data.getDistinct();
 
         // First bind the result table
-        RdfBindingSet results = constraint.constrain(null,
-                source, defaultDatasets, namedDatasets);
+        RdfBindingSet results = constraint.constrain(p);
 
         // Now project to the solution set or the variable set
         if (!queryExpressions.isEmpty()) {
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/DefaultValueOrderingLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/DefaultValueOrderingLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/DefaultValueOrderingLogic.java	2006-12-02 11:09:25.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/DefaultValueOrderingLogic.java	2006-12-02 11:14:00.000000000 -0500
@@ -1,5 +1,9 @@
 package name.levering.ryan.sparql.logic;
 
+import name.levering.ryan.sparql.common.impl.DateTime;
+
+import name.levering.ryan.sparql.model.logic.NumericPromotionLogic;
+import name.levering.ryan.sparql.model.logic.helper.ValueConversionLogic;
 import name.levering.ryan.sparql.model.logic.helper.ValueOrderingLogic;
 
 import org.openrdf.model.BNode;
@@ -22,6 +26,13 @@
  * @version 1.0
  */
 public class DefaultValueOrderingLogic implements ValueOrderingLogic {
+	NumericPromotionLogic promoter;
+	ValueConversionLogic converter;
+	
+	public DefaultValueOrderingLogic(NumericPromotionLogic promoter, ValueConversionLogic converter) {
+		this.promoter = promoter;
+		this.converter = converter;
+	}
 
 	/**
 	 * Compares two value objects according to section 10.1.
@@ -64,14 +75,41 @@
 			return -1;
 		}
 
-		// First value is an untyped literal
-		if (value1 instanceof Literal && ((Literal) value1).getDatatype() == null) {
-			if (value2 == null || value2 instanceof BNode || value2 instanceof URI) {
+		// First value is a literal
+		if (value1 instanceof Literal) {
+			if (value2 == null || value2 instanceof BNode || value2 instanceof URI)
 				return 1;
+
+			if (value2 instanceof Literal) {
+				if (((Literal) value1).getDatatype() == null && ((Literal) value2).getDatatype() == null)
+					return ((Literal) value1).getLabel().compareTo(((Literal) value2).getLabel());
+					
+				if (((Literal) value1).getDatatype() == null)
+					return -1;
+				if (((Literal) value2).getDatatype() == null)
+					return 1;
+				
+				Literal[] promoted = promoter.promote(new Literal[] { (Literal) value1, (Literal) value2 } );
+				
+				Object v1 = converter.convertLiteral(promoted[0]);
+				Object v2 = converter.convertLiteral(promoted[1]);
+				
+				if (v1 instanceof Double)
+					return ((Double)v1).compareTo((Double)v2);
+				if (v1 instanceof Float)
+					return ((Float)v1).compareTo((Float)v2);
+				if (v1 instanceof Long)
+					return ((Long)v1).compareTo((Long)v2);
+				if (v1 instanceof Integer)
+					return ((Integer)v1).compareTo((Integer)v2);
+				if (v1 instanceof Boolean)
+					return ((Boolean)v1).compareTo((Boolean)v2);
+				if (v1 instanceof DateTime)
+					return ((DateTime)v1).compareTo((DateTime)v2);
+				if (v1 instanceof String)
+					return ((String)v1).compareTo((String)v2);
 			}
-			if (value2 instanceof Literal && ((Literal) value2).getDatatype() == null) {
-				return ((Literal) value1).getLabel().compareTo(((Literal) value2).getLabel());
-			}
+			
 			return -1;
 		}
 
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/expression/GreaterThanEqualsLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/expression/GreaterThanEqualsLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/expression/GreaterThanEqualsLogic.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/expression/GreaterThanEqualsLogic.java	2006-12-02 11:00:48.000000000 -0500
@@ -96,11 +96,10 @@
      * 
      * @param string1 the first String to compare
      * @param string2 the second String to compare
-     * @return never
-     * @throws UnsupportedOperationException always
+     * @return true if the first string is greater than or equal to the second
      */
     public boolean evaluateString(String string1, String string2) {
-        throw new UnsupportedOperationException("Strings cannot be compared using a >= operation");
+        return string1.compareTo(string2) >= 0;
     }
 
     /**
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/expression/GreaterThanLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/expression/GreaterThanLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/expression/GreaterThanLogic.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/expression/GreaterThanLogic.java	2006-12-02 11:00:48.000000000 -0500
@@ -96,11 +96,10 @@
      * 
      * @param string1 the first String to compare
      * @param string2 the second String to compare
-     * @return never
-     * @throws UnsupportedOperationException always
+     * @return true if the first string is greater than the second
      */
     public boolean evaluateString(String string1, String string2) {
-        throw new UnsupportedOperationException("Strings cannot be compared using a > operation");
+        return string1.compareTo(string2) > 0;
     }
 
     /**
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/expression/LessThanEqualsLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/expression/LessThanEqualsLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/expression/LessThanEqualsLogic.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/expression/LessThanEqualsLogic.java	2006-12-02 11:00:48.000000000 -0500
@@ -96,11 +96,10 @@
      * 
      * @param string1 the first String to compare
      * @param string2 the second String to compare
-     * @return never
-     * @throws UnsupportedOperationException always
+     * @return true if the first string is less than or equal to the second
      */
     public boolean evaluateString(String string1, String string2) {
-        throw new UnsupportedOperationException("Strings cannot be compared using a <= operation");
+        return string1.compareTo(string2) <= 0;
     }
 
     /**
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/expression/LessThanLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/expression/LessThanLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/expression/LessThanLogic.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/expression/LessThanLogic.java	2006-12-02 11:00:48.000000000 -0500
@@ -96,11 +96,10 @@
      * 
      * @param string1 the first String to compare
      * @param string2 the second String to compare
-     * @return never
-     * @throws UnsupportedOperationException always
+     * @return true if the first string is less than the second
      */
     public boolean evaluateString(String string1, String string2) {
-        throw new UnsupportedOperationException("Fix this");
+        return string1.compareTo(string2) < 0;
     }
     
     /**
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/ExtendedConstructQueryLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/ExtendedConstructQueryLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/ExtendedConstructQueryLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/ExtendedConstructQueryLogic.java	2007-02-21 07:45:27.000000000 -0500
@@ -88,17 +88,21 @@
 	 * @return an RDF graph containing the formed triples
 	 */
 	public RdfGraph execute(RdfSource source) {
+		ConstraintLogic.CallParams p = new ConstraintLogic.CallParams();
+		p.bindings = new RdfBindingSetImpl();
+		p.source = source;
+
 		// Grab the necessary fields from the data
 		GroupConstraint constraint = this.data.getConstraint();
-		Collection defaultDatasets = this.data.getDefaultDatasets();
-		Collection namedDatasets = this.data.getNamedDatasets();
+		p.defaultDatasets = this.data.getDefaultDatasets();
+		p.namedDatasets = this.data.getNamedDatasets();
 		List orderExpressions = this.data.getOrderExpressions();
 		int limit = this.data.getLimit();
 		int offset = this.data.getOffset();
 		boolean distinct = this.data.isDistinct();
 
 		// First bind the result table
-		RdfBindingSet results = constraint.constrain(new RdfBindingSetImpl(), source, defaultDatasets, namedDatasets);
+		RdfBindingSet results = constraint.constrain(p);
 
 		// Now apply ordering in reverse order to give priority to the first
 		// variable
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/function/BoundLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/BoundLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/function/BoundLogic.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/BoundLogic.java	2006-12-02 11:00:48.000000000 -0500
@@ -23,12 +23,7 @@
  * @author Ryan Levering
  * @version 1.0
  */
-public class BoundLogic implements ExpressionLogic {
-
-    /**
-     * The data holding the arguments of the bound function.
-     */
-    private final CallExpressionData data;
+public class BoundLogic extends FunctionLogic {
 
     /**
      * The logic to return the correct boolean value.
@@ -43,7 +38,7 @@
      */
     public BoundLogic(CallExpressionData data, ValueConversionLogic converter) {
         //TODO Check for whether the argument is a variable
-        this.data = data;
+        super(data);
         this.converter = converter;
     }
 
@@ -58,5 +53,5 @@
         boolean result = (bindings.getValue(variable) != null);
         return this.converter.convertBoolean(result);
     }
-
+ 
 }
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/function/DataTypeLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/DataTypeLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/function/DataTypeLogic.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/DataTypeLogic.java	2006-12-02 11:00:48.000000000 -0500
@@ -21,22 +21,17 @@
  * @author Ryan Levering
  * @version 1.0
  */
-public class DataTypeLogic implements ExpressionLogic {
+public class DataTypeLogic extends FunctionLogic {
 
-	/**
-	 * The data holding the argument to evaluate.
-	 */
-	private final CallExpressionData data;
-
-	/**
-	 * Creates a new logic object that returns the IRI of the datatype of a
-	 * particular typed literal.
-	 * 
-	 * @param data the argument data
-	 */
-	public DataTypeLogic(CallExpressionData data) {
-		this.data = data;
-	}
+    /**
+     * Creates a new logic object that returns the IRI of the datatype of a
+     * particular typed literal.
+     * 
+     * @param data the argument data
+     */
+    public DataTypeLogic(CallExpressionData data) {
+        super(data);
+    }
 
 	/**
 	 * Evaluates the datatype of a typed literal that is an argument.
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/function/DecimalCastFunction.java work-copy/src/main/name/levering/ryan/sparql/logic/function/DecimalCastFunction.java
--- upstream/src/main/name/levering/ryan/sparql/logic/function/DecimalCastFunction.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/DecimalCastFunction.java	2006-12-02 11:00:48.000000000 -0500
@@ -144,11 +144,11 @@
      */
     public Value castLiteral(Literal literal) throws IllegalCastException {
         try {
-            Long.parseLong(literal.getLabel());
+            Double.parseDouble(literal.getLabel());
             return this.factory.createLiteral(literal.getLabel(),
                     SPARQLConstants.DECIMAL_TYPE);
         } catch (NumberFormatException e) {
-            throw new IllegalCastException("Unable to cast string to integer");
+            throw new IllegalCastException("Unable to cast string to double");
         }
     }
     
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/function/ExternalFunctionLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/ExternalFunctionLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/function/ExternalFunctionLogic.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/ExternalFunctionLogic.java	2006-12-02 11:00:48.000000000 -0500
@@ -23,34 +23,29 @@
  * @author Ryan Levering
  * @version 1.1
  */
-public class ExternalFunctionLogic implements ExpressionLogic {
+public class ExternalFunctionLogic extends FunctionLogic {
 
-	/**
-	 * The data containing the argument expressions to evaluate
-	 */
-	private final CallExpressionData data;
-
-	/**
-	 * The function to delegate the logic to.
-	 */
-	private final ExternalFunction function;
-
-	/**
-	 * The factory that's used to convert returns into SPARQL values.
-	 */
-	private final SPARQLValueFactory factory;
-
-	/**
-	 * Creates a new external function logic that evaluates a function call to
-	 * produce a Value.
-	 * 
-	 * @param data the data containing the function arguments and it's name
-	 */
-	public ExternalFunctionLogic(CallExpressionData data, ExternalFunction function, SPARQLValueFactory factory) {
-		this.data = data;
-		this.function = function;
-		this.factory = factory;
-	}
+    /**
+     * The function to delegate the logic to.
+     */
+    private final ExternalFunction function;
+
+    /**
+     * The factory that's used to convert returns into SPARQL values.
+     */
+    private SPARQLValueFactory factory;
+    
+    /**
+     * Creates a new external function logic that evaluates a function call to
+     * produce a Value.
+     * 
+     * @param data the data containing the function arguments and it's name
+     */
+    public ExternalFunctionLogic(CallExpressionData data, ExternalFunction function, SPARQLValueFactory factory) {
+        super(data);
+        this.function = function;
+        this.factory = factory;
+    }
 
 	/**
 	 * Evaluates the function by evaluating the arguments and passing them to
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/function/FunctionLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/FunctionLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/function/FunctionLogic.java	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/FunctionLogic.java	2006-12-02 11:14:52.000000000 -0500
@@ -0,0 +1,41 @@
+/*
+ * SPARQL Engine
+ * Copyright (C) 2005 Ryan Levering, All rights reserved.
+ * See LICENSE for full license information
+ */
+package name.levering.ryan.sparql.logic.function;
+
+import java.util.Iterator;
+import java.util.Set;
+
+import name.levering.ryan.sparql.common.RdfBindingRow;
+import name.levering.ryan.sparql.common.Variable;
+import name.levering.ryan.sparql.model.data.CallExpressionData;
+import name.levering.ryan.sparql.model.logic.ExpressionLogic;
+import name.levering.ryan.sparql.model.logic.helper.ValueConversionLogic;
+
+import org.openrdf.model.Value;
+
+/**
+ * The base class of function-type logics.
+ * 
+ * @author Ryan Levering
+ * @version 1.0
+ */
+public abstract class FunctionLogic implements ExpressionLogic {
+
+    /**
+     * The data holding the arguments of the bound function.
+     */
+    protected CallExpressionData data;
+
+    /**
+     * Creates a new logic object that handles sop:bound function calls.
+     * 
+     * @param data the data holding the expression arguments to evaluate
+     * @param converter
+     */
+    public FunctionLogic(CallExpressionData data) {
+        this.data = data;
+    }
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/function/IsBlankLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/IsBlankLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/function/IsBlankLogic.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/IsBlankLogic.java	2006-12-02 11:00:48.000000000 -0500
@@ -21,30 +21,23 @@
  * @author Ryan Levering
  * @version 1.0
  */
-public class IsBlankLogic implements ExpressionLogic {
-
-	/**
-	 * The data that holds the argument to evaluate for blank node.
-	 */
-	private final CallExpressionData data;
-
+public class IsBlankLogic extends FunctionLogic {
 	/**
 	 * The converter used to return the true or false value.
 	 */
 	private final ValueConversionLogic converter;
 
-	/**
-	 * Creates a new logic object that can evaluate whether a bound variable or
-	 * value is a blank node.
-	 * 
-	 * @param data the data holding the argument for evaluation
-	 * @param converter the value conversion logic to convert the boolean to a
-	 *            literal
-	 */
-	public IsBlankLogic(CallExpressionData data, ValueConversionLogic converter) {
-		this.data = data;
-		this.converter = converter;
-	}
+    /**
+     * Creates a new logic object that can evaluate whether a bound variable or
+     * value is a blank node.
+     * 
+     * @param data the data holding the argument for evaluation
+     * @param converter the value conversion logic to convert the boolean to a literal
+     */
+    public IsBlankLogic(CallExpressionData data, ValueConversionLogic converter) {
+        super(data);
+        this.converter = converter;
+    }
 
 	/**
 	 * Evaluates whether the value returned by an expression is a blank node.
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/function/IsIRILogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/IsIRILogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/function/IsIRILogic.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/IsIRILogic.java	2006-12-02 11:00:48.000000000 -0500
@@ -21,38 +21,30 @@
  * @author Ryan Levering
  * @version 1.0
  */
-public class IsIRILogic implements ExpressionLogic {
-
-	/**
-	 * The data that holds the argument to evaluate for IRI.
-	 */
-	private final CallExpressionData data;
-
-	/**
-	 * The converter used to return the true or false value.
-	 */
-	private final ValueConversionLogic converter;
-
-	/**
-	 * Creates a new logic object that can evaluate whether a bound variable or
-	 * value is an IRI.
-	 * 
-	 * @param data the data holding the argument for evaluation
-	 * @param converter the value conversion logic to convert the boolean to a
-	 *            literal
-	 */
-	public IsIRILogic(CallExpressionData data, ValueConversionLogic converter) {
-		this.data = data;
-		this.converter = converter;
-	}
-
-	/**
-	 * Evaluates whether the value returned by an expression is an IRI.
-	 * 
-	 * @param bindings the value bindings to use in argument evaluation
-	 * @return true or false literals representing whether the argument is an
-	 *         IRI
-	 */
+public class IsIRILogic extends FunctionLogic {
+    /**
+     * The converter used to return the true or false value.
+     */
+    private final ValueConversionLogic converter;
+    
+    /**
+     * Creates a new logic object that can evaluate whether a bound variable or
+     * value is an IRI.
+     * 
+     * @param data the data holding the argument for evaluation
+     * @param converter the value conversion logic to convert the boolean to a literal
+     */
+    public IsIRILogic(CallExpressionData data, ValueConversionLogic converter) {
+        super(data);
+        this.converter = converter;
+    }
+    
+    /**
+     * Evaluates whether the value returned by an expression is an IRI.
+     * 
+     * @param bindings the value bindings to use in argument evaluation
+     * @return true or false literals representing whether the argument is an IRI
+     */
 	public Value evaluate(RdfBindingRow bindings) {
 		ExpressionLogic expression = (ExpressionLogic) this.data.getArguments().get(0);
 		Object value = expression.evaluate(bindings);
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/function/IsLiteralLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/IsLiteralLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/function/IsLiteralLogic.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/IsLiteralLogic.java	2006-12-02 11:00:48.000000000 -0500
@@ -21,38 +21,31 @@
  * @author Ryan Levering
  * @version 1.0
  */
-public class IsLiteralLogic implements ExpressionLogic {
-
-	/**
-	 * The data that holds the argument to evaluate for literal.
-	 */
-	private final CallExpressionData data;
-
-	/**
-	 * The converter used to return the true or false value.
-	 */
-	private final ValueConversionLogic converter;
-
-	/**
-	 * Creates a new logic object that can evaluate whether a bound variable or
-	 * value is a literal.
-	 * 
-	 * @param data the data holding the argument for evaluation
-	 * @param converter the value conversion logic to convert the boolean to a
-	 *            literal
-	 */
-	public IsLiteralLogic(CallExpressionData data, ValueConversionLogic converter) {
-		this.data = data;
-		this.converter = converter;
-	}
-
-	/**
-	 * Evaluates whether the value returned by an expression is a literal.
-	 * 
-	 * @param bindings the value bindings to use in argument evaluation
-	 * @return true or false literals representing whether the argument is an
-	 *         literal
-	 */
+public class IsLiteralLogic extends FunctionLogic {
+   
+    /**
+     * The converter used to return the true or false value.
+     */
+    private final ValueConversionLogic converter;
+    
+    /**
+     * Creates a new logic object that can evaluate whether a bound variable or
+     * value is a literal.
+     * 
+     * @param data the data holding the argument for evaluation
+     * @param converter the value conversion logic to convert the boolean to a literal
+     */
+    public IsLiteralLogic(CallExpressionData data, ValueConversionLogic converter) {
+        super(data);
+        this.converter = converter;
+    }
+    
+    /**
+     * Evaluates whether the value returned by an expression is a literal.
+     * 
+     * @param bindings the value bindings to use in argument evaluation
+     * @return true or false literals representing whether the argument is an literal
+     */
 	public Value evaluate(RdfBindingRow bindings) {
 		ExpressionLogic expression = (ExpressionLogic) this.data.getArguments().get(0);
 		Object value = expression.evaluate(bindings);
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/function/LangLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/LangLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/function/LangLogic.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/LangLogic.java	2006-12-02 11:00:48.000000000 -0500
@@ -21,30 +21,22 @@
  * @author Ryan Levering
  * @version 1.0
  */
-public class LangLogic implements ExpressionLogic {
-
-	/**
-	 * The data that holds the argument to evaluate for literal language.
-	 */
-	private final CallExpressionData data;
-
+public class LangLogic extends FunctionLogic {
 	/**
 	 * The converter used to return the string value.
 	 */
 	private final ValueConversionLogic converter;
 
-	/**
-	 * Creates a new logic object that can return the language of a given
-	 * literal.
-	 * 
-	 * @param data the data holding the argument for evaluation
-	 * @param converter the value conversion logic to convert the string to a
-	 *            literal
-	 */
-	public LangLogic(CallExpressionData data, ValueConversionLogic converter) {
-		this.data = data;
-		this.converter = converter;
-	}
+   /**
+    * Creates a new logic object that can return the language of a given literal.
+    * 
+    * @param data the data holding the argument for evaluation
+    * @param converter the value conversion logic to convert the string to a literal
+    */
+    public LangLogic(CallExpressionData data, ValueConversionLogic converter) {
+        super(data);
+        this.converter = converter;
+    }
 
 	/**
 	 * Returns the language of a language tagged literal.
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/function/LangMatchesLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/LangMatchesLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/function/LangMatchesLogic.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/LangMatchesLogic.java	2006-12-02 11:00:48.000000000 -0500
@@ -21,14 +21,7 @@
  * @author Ryan Levering
  * @version 1.0
  */
-public class LangMatchesLogic implements ExpressionLogic {
-
-	/**
-	 * The data that holds the arguments to evaluate for language range and
-	 * literal to match.
-	 */
-	private final CallExpressionData data;
-
+public class LangMatchesLogic extends FunctionLogic {
 	/**
 	 * The converter used to return the boolean value.
 	 */
@@ -43,7 +36,7 @@
 	 *            literal
 	 */
 	public LangMatchesLogic(CallExpressionData data, ValueConversionLogic converter) {
-		this.data = data;
+		super(data);
 		this.converter = converter;
 	}
 
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/function/RegexLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/RegexLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/function/RegexLogic.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/RegexLogic.java	2006-12-02 11:00:48.000000000 -0500
@@ -25,31 +25,25 @@
  * @author Ryan Levering
  * @version 1.1
  */
-public class RegexLogic implements ExpressionLogic {
-
-	/**
-	 * The data that holds the argument to evaluate for string matching.
-	 */
-	private final CallExpressionData data;
-
-	/**
-	 * The converter used to return the boolean literal and convert the string
-	 * value.
-	 */
-	private final ValueConversionLogic converter;
-
-	/**
-	 * Creates a new logic object that can evaluate whether one string occurs in
-	 * another.
-	 * 
-	 * @param data the data holding the argument for evaluation
-	 * @param converter the value conversion logic to convert the result to a
-	 *            literal and the strings to Java strings
-	 */
-	public RegexLogic(CallExpressionData data, ValueConversionLogic converter) {
-		this.data = data;
-		this.converter = converter;
-	}
+public class RegexLogic extends FunctionLogic {
+    /**
+     * The converter used to return the boolean literal and convert the string
+     * value.
+     */
+    private final ValueConversionLogic converter;
+
+    /**
+     * Creates a new logic object that can evaluate whether one string occurs in
+     * another.
+     * 
+     * @param data the data holding the argument for evaluation
+     * @param converter the value conversion logic to convert the result to a
+     *            literal and the strings to Java strings
+     */
+    public RegexLogic(CallExpressionData data, ValueConversionLogic converter) {
+        super(data);
+        this.converter = converter;
+    }
 
 	/**
 	 * Converts the evaluated arguments to strings and uses Java string matching
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/function/StrLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/function/StrLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/function/StrLogic.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/function/StrLogic.java	2006-12-02 11:00:48.000000000 -0500
@@ -23,28 +23,22 @@
  * @author Ryan Levering
  * @version 1.2
  */
-public class StrLogic implements ExpressionLogic {
-
-	/**
-	 * The data that holds the argument to evaluate for string conversion.
-	 */
-	private final CallExpressionData data;
-
-	/**
-	 * The factory used to create new string literals.
-	 */
-	private final SPARQLValueFactory factory;
-
-	/**
-	 * Creates a new logic object that can evaluate the string representation of
-	 * a IRI or literal.
-	 * 
-	 * @param data the data holding the argument for evaluation
-	 */
-	public StrLogic(CallExpressionData data, SPARQLValueFactory factory) {
-		this.data = data;
-		this.factory = factory;
-	}
+public class StrLogic extends FunctionLogic {
+    /**
+     * The factory used to create new string literals.
+     */
+    private final SPARQLValueFactory factory;
+
+    /**
+     * Creates a new logic object that can evaluate the string representation of
+     * a IRI or literal.
+     * 
+     * @param data the data holding the argument for evaluation
+     */
+    public StrLogic(CallExpressionData data, SPARQLValueFactory factory) {
+        super(data);
+        this.factory = factory;
+    }
 
 	/**
 	 * Evaluates the argument to the function and does simplistic conversion to
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/naive/DefaultFilterConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultFilterConstraintLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/naive/DefaultFilterConstraintLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultFilterConstraintLogic.java	2007-02-21 07:11:04.000000000 -0500
@@ -8,6 +8,7 @@
 import java.util.Collection;
 import java.util.Collections;
 import java.util.Iterator;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingRow;
 import name.levering.ryan.sparql.common.RdfBindingSet;
@@ -74,17 +75,16 @@
      *            this constraint
      * @return a binding set with values that pass through the filter expression
      */
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source,
-            Collection defaultDatasets, Collection namedDatasets) {
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
         // Grab the necessary fields from the data
         ExpressionLogic filterExpression = this.data.getExpression();
 
         // Create a new binding set with the same variables
         RdfBindingSetImpl newBindings = new RdfBindingSetImpl(
-                bindings.getVariables());
+                p.bindings.getVariables());
 
         // Only add rows to the new set if they return true boolean literals
-        for (Iterator rows = bindings.iterator(); rows.hasNext();) {
+        for (Iterator rows = p.bindings.iterator(); rows.hasNext();) {
             RdfBindingRow row = (RdfBindingRow) rows.next();
             try {
                 Value rawEvaluate = filterExpression.evaluate(row);
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/naive/DefaultGroupConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultGroupConstraintLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/naive/DefaultGroupConstraintLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultGroupConstraintLogic.java	2007-02-21 07:16:02.000000000 -0500
@@ -9,6 +9,7 @@
 import java.util.Iterator;
 import java.util.LinkedList;
 import java.util.List;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -73,18 +74,19 @@
 	 * @param namedDatasets the named datasets to query in an unbound graph
 	 *            query, passed on to subconstraints
 	 */
-	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
-		return this.constrain(bindings, source, defaultDatasets, namedDatasets, true);
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+		return this.constrain(p, true);
 	}
 
-	private RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets, boolean withFilter) {
+	private RdfBindingSet constrain(ConstraintLogic.CallParams p, boolean withFilter) {
 
 		List filterQueue = new LinkedList();
 		List optionalQueue = new LinkedList();
 		List graphQueue = new LinkedList();
 
+		ConstraintLogic.CallParams p2 = p.clone();
+		p2.bindings = null;
+
 		RdfBindingSet current = null;
 		// Constrain in order, unless we hit an optional, graph, or value filter
 		// These things all kind of depend on the previous bindings
@@ -99,7 +101,7 @@
 			} else if (c instanceof GraphConstraintData) {
 				graphQueue.add(c);
 			} else {
-				this.orderLogic.addBindingSet(c.constrain(null, source, defaultDatasets, namedDatasets));
+				this.orderLogic.addBindingSet(c.constrain(p2));
 			}
 
 		}
@@ -108,10 +110,11 @@
 		// This scoped graphing isn't required by the spec, but it's allowed
 		for (Iterator graphs = graphQueue.iterator(); graphs.hasNext();) {
 			ConstraintLogic c = (ConstraintLogic) graphs.next();
+			p2.bindings = current;
 			if (current == null) {
-				current = c.constrain(null, source, defaultDatasets, namedDatasets);
+				current = c.constrain(p2);
 			} else {
-				current = this.logic.intersect(current, c.constrain(current, source, defaultDatasets, namedDatasets));
+				current = this.logic.intersect(current, c.constrain(p2));
 			}
 		}
 
@@ -123,11 +126,13 @@
 
 		for (Iterator optionals = optionalQueue.iterator(); optionals.hasNext();) {
 			ConstraintLogic c = (ConstraintLogic) optionals.next();
-			current = c.constrain(current, source, defaultDatasets, namedDatasets);
+			p2.bindings = current;
+			current = c.constrain(p2);
 		}
 		for (Iterator filters = filterQueue.iterator(); filters.hasNext();) {
 			ConstraintLogic c = (ConstraintLogic) filters.next();
-			current = c.constrain(current, source, defaultDatasets, namedDatasets);
+			p2.bindings = current;
+			current = c.constrain(p2);
 		}
 		return current;
 	}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/naive/DefaultOptionalConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultOptionalConstraintLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/naive/DefaultOptionalConstraintLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultOptionalConstraintLogic.java	2007-02-21 07:48:26.000000000 -0500
@@ -9,6 +9,7 @@
 import java.util.Iterator;
 import java.util.LinkedList;
 import java.util.List;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -74,13 +75,16 @@
 	 * @param namedDatasets the named datasets for named queries, passed onto
 	 *            the grouped constraint
 	 */
-	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
 		List filterQueue = new LinkedList();
 		List optionalQueue = new LinkedList();
 		List graphQueue = new LinkedList();
 
 		RdfBindingSet current = null;
+		
+		ConstraintLogic.CallParams p2 = p.clone();
+		p2.bindings = null;
+
 		// Constrain in order, unless we hit an optional, graph, or value filter
 		// These things all kind of depend on the previous bindings
 		// Graph probably shouldn't technically, but I think in this
@@ -94,7 +98,7 @@
 			} else if (c instanceof GraphConstraint) {
 				graphQueue.add(c);
 			} else {
-				this.orderLogic.addBindingSet(c.constrain(null, source, defaultDatasets, namedDatasets));
+				this.orderLogic.addBindingSet(c.constrain(p2));
 			}
 
 		}
@@ -104,10 +108,10 @@
 		for (Iterator graphs = graphQueue.iterator(); graphs.hasNext();) {
 			ConstraintLogic c = (ConstraintLogic) graphs.next();
 			if (current == null) {
-				current = c.constrain(null, source, defaultDatasets, namedDatasets);
+				current = c.constrain(p2);
 			} else {
-				current = this.intersectLogic.intersect(current, c.constrain(current, source, defaultDatasets,
-						namedDatasets));
+				p2.bindings = current;
+				current = this.intersectLogic.intersect(current, c.constrain(p2));
 			}
 		}
 
@@ -119,10 +123,11 @@
 
 		for (Iterator optionals = optionalQueue.iterator(); optionals.hasNext();) {
 			ConstraintLogic c = (ConstraintLogic) optionals.next();
-			current = c.constrain(current, source, defaultDatasets, namedDatasets);
+			p2.bindings = current;
+			current = c.constrain(p2);
 		}
 		
-		return this.logic.join(bindings, current, filterQueue);
+		return this.logic.join(p.bindings, current, filterQueue);
 	}
 
 }
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/naive/DefaultTripleConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultTripleConstraintLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/naive/DefaultTripleConstraintLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultTripleConstraintLogic.java	2007-02-21 07:48:10.000000000 -0500
@@ -9,6 +9,7 @@
 import java.util.Collection;
 import java.util.Iterator;
 import java.util.List;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.GraphStatement;
 import name.levering.ryan.sparql.common.LenientStatement;
@@ -63,8 +64,7 @@
      *            used in this constraint
      * 
      */
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source,
-            Collection defaultDatasets, Collection namedDatasets) {
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
 
         ExpressionLogic subExpr = this.data.getSubjectExpression();
         ExpressionLogic predExpr = this.data.getPredicateExpression();
@@ -110,25 +110,25 @@
 
         Iterator statements;
         if (!variables.isEmpty()) {
-            if (defaultDatasets == null) {
+            if (p.defaultDatasets == null) {
                 // This adds an extra column to the returned set for the GRAPH
                 // constraint to process
                 variables.add(StreamedGraphConstraintLogic.CONTEXT_VARIABLE);
                 newBindings = new RdfBindingSetImpl(
                         (Variable[]) variables.toArray(new Variable[0]));
-                statements = source.getStatements(subject, verb, object);
+                statements = p.source.getStatements(subject, verb, object);
                 addGraphStatements(newBindings, statements, flags);
             } else {
-                if (defaultDatasets.isEmpty()) {
+                if (p.defaultDatasets.isEmpty()) {
                     // This is if no FROM graphs are specified
-                    statements = source.getDefaultStatements(subject, verb,
+                    statements = p.source.getDefaultStatements(subject, verb,
                             object);
                     addStatements(newBindings, statements, flags);
                 } else {
                     // This is if FROM graphs are specified or FROM NAMED and
                     // we're in a GRAPH constraint
-                    for (Iterator i = defaultDatasets.iterator(); i.hasNext();) {
-                        statements = source.getStatements(subject, verb,
+                    for (Iterator i = p.defaultDatasets.iterator(); i.hasNext();) {
+                        statements = p.source.getStatements(subject, verb,
                                 object, (URI) i.next());
                         addStatements(newBindings, statements, flags);
                     }
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/naive/DefaultUnionConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultUnionConstraintLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/naive/DefaultUnionConstraintLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/naive/DefaultUnionConstraintLogic.java	2007-02-21 07:30:41.000000000 -0500
@@ -7,6 +7,7 @@
 
 import java.util.Collection;
 import java.util.Iterator;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -62,15 +63,16 @@
 	 * @return a set containing the union of all the bound values of all the sub
 	 *         constraints
 	 */
-	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
 		RdfBindingSet current = null;
+		ConstraintLogic.CallParams p2 = p.clone();
 		for (Iterator groupOrUnions = this.data.getConstraints().iterator(); groupOrUnions.hasNext();) {
 			ConstraintLogic group = (ConstraintLogic) groupOrUnions.next();
+			p2.bindings = current;
 			if (current == null) {
-				current = group.constrain(current, source, defaultDatasets, namedDatasets);
+				current = group.constrain(p2);
 			} else {
-				current = this.logic.union(current, group.constrain(current, source, defaultDatasets, namedDatasets));
+				current = this.logic.union(current, group.constrain(p2));
 			}
 		}
 
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/streamed/AdvancedGroupConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/streamed/AdvancedGroupConstraintLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/streamed/AdvancedGroupConstraintLogic.java	1969-12-31 19:00:00.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/logic/streamed/AdvancedGroupConstraintLogic.java	2007-02-21 07:43:36.000000000 -0500
@@ -0,0 +1,568 @@
+/*
+ * SPARQL Engine
+ * Copyright (C) 2005 Ryan Levering, All rights reserved.
+ * See LICENSE for full license information
+ */
+package name.levering.ryan.sparql.logic;
+
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+
+import org.openrdf.model.URI;
+import org.openrdf.model.BNode;
+import org.openrdf.model.Literal;
+import org.openrdf.model.Value;
+
+import name.levering.ryan.sparql.common.impl.AbstractRdfBindingRow;
+import name.levering.ryan.sparql.common.RdfBindingSet;
+import name.levering.ryan.sparql.common.RdfBindingRow;
+import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.common.Variable;
+import name.levering.ryan.sparql.common.impl.RdfBindingSetImpl;
+import name.levering.ryan.sparql.logic.function.ExternalFunctionLogic;
+import name.levering.ryan.sparql.model.TripleConstraint;
+import name.levering.ryan.sparql.model.data.FilterConstraintData;
+import name.levering.ryan.sparql.model.data.GroupConstraintData;
+import name.levering.ryan.sparql.model.data.OptionalConstraintData;
+import name.levering.ryan.sparql.model.logic.ConstraintLogic;
+import name.levering.ryan.sparql.model.logic.ExpressionLogic;
+import name.levering.ryan.sparql.model.logic.helper.SetIntersectLogic;
+import name.levering.ryan.sparql.parser.model.ASTAndNode;
+import name.levering.ryan.sparql.parser.model.ASTEqualsNode;
+import name.levering.ryan.sparql.parser.model.ASTOrNode;
+import name.levering.ryan.sparql.parser.model.ASTVar;
+import name.levering.ryan.sparql.parser.model.BinaryExpressionNode;
+import name.levering.ryan.sparql.parser.model.DelegatingTripleConstraint;
+import name.levering.ryan.sparql.parser.model.EmptyVisitor;
+import name.levering.ryan.sparql.parser.model.SimpleNode;
+
+/**
+ * This logic is the default logic for the main constraint that is used as an
+ * aggregate of other constraints. TripleConstraints, UnionConstraints, and
+ * GraphConstraints all are intersected with the running binding set. After
+ * that, OptionalConstraints and FilterConstraints modify the set themselves.
+ * 
+ * @author Ryan Levering
+ * @version 1.0
+ */
+public class AdvancedGroupConstraintLogic implements ConstraintLogic {
+
+    /**
+     * The data that holds the constraints that this group constraint
+     * aggregates.
+     */
+    private final GroupConstraintData data;
+
+    /**
+     * This logic that intersects the parts of the graph pattern.
+     */
+    private final SetIntersectLogic logic;
+    
+    private static final Map
+		isFunctional = new HashMap(),
+    	isInverseFunctional = new HashMap();
+    
+    /**
+     * Creates a new default group logic, with the given subconstraints found in
+     * the data.
+     * 
+     * @param data the data holding the subconstraints to bind
+     */
+    public AdvancedGroupConstraintLogic(GroupConstraintData data, SetIntersectLogic logic) {
+        this.logic = logic;
+        this.data = data;
+    }
+
+    /**
+     * Applies each subconstraint in turn, saving filter and optional
+     * constraints for last, as according to specification.
+     * 
+     * @param bindings the current running bindings, ignored here
+     * @param source the source to query RDF triples, passed on to
+     *            subconstraints
+     * @param defaultDatasets the datasets to query by default, passed on to
+     *            subconstraints
+     * @param namedDatasets the named datasets to query in an unbound graph
+     *            query, passed on to subconstraints
+     */
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+	
+		// Build separate lists for the different constraints that this group may contain.
+
+		List tripleConstraints = new LinkedList();
+        List filterQueue = new LinkedList();
+        List optionalQueue = new LinkedList();
+		List otherQueue = new LinkedList();
+
+		// Clone knownValues and knownFilters so we can freely modify it without affecting the caller.
+		
+		p = p.clone();
+		if (p.knownValues == null)
+			p.knownValues = new HashMap();
+		else
+			p.knownValues = new HashMap(p.knownValues);
+			
+		if (p.knownFilters == null)
+			p.knownFilters = new HashMap();
+		else
+			p.knownFilters = new HashMap(p.knownFilters);
+		
+		// Get a list of variables that have known values, and of those the ones that are really cheap
+		// (i.e. have just a few values).
+		// We'll build these sets in the course of reordering the statements to query most efficiently.
+
+		Set knownVars = new HashSet();
+		Set cheapVars = new HashSet();
+		
+		// Any variables known by groups on top of us are known here, and cheap (I guess).
+		knownVars.addAll(p.knownValues.keySet());
+		cheapVars.addAll(p.knownValues.keySet());
+		
+		// Split out the types of constraints and look for filters that tell us interesting things.
+		
+        for (Iterator cons = data.getConstraints().iterator(); cons.hasNext();) {
+            ConstraintLogic c = (ConstraintLogic) cons.next();
+            if (c instanceof OptionalConstraintData) {
+				optionalQueue.add(c);
+            } else if (c instanceof FilterConstraintData) {
+				filterQueue.add(c);
+				
+				FilterConstraintData f = (FilterConstraintData)c;
+				if (f.getExpression() instanceof BinaryExpressionNode) {
+					// If this filter is of the form FILTER(?var = <uri> || ?var = <uri> || ...)
+					// then this is giving us some known values for the variable.
+					BinaryExpressionNode b = (BinaryExpressionNode)f.getExpression();
+					Variable v = getFilterPrimaryVariable(b);
+					if (v != null) {
+						Set values = new HashSet();
+						getFilterValues(b, values);
+						if (!p.knownValues.containsKey(v)) {
+							p.knownValues.put(v, values);
+							knownVars.add(v);
+							cheapVars.add(v);
+						} else {
+							Set othervalues = (Set)p.knownValues.get(v);
+							othervalues.retainAll(values);
+						}
+					}
+				}
+				
+				// This by default does nothing, but subclassors may decide to do things here.
+				extractLiteralFilters(f.getExpression(), p.knownFilters);
+				
+			} else if (c instanceof TripleConstraint) {
+				tripleConstraints.add(c);
+			} else {
+				otherQueue.add(c);
+			}
+		}
+		
+		// Reorder the triple constraints so that complex constraints are done
+		// after some of their variables have already been evaluated.  This is
+		// a bit N^2-ish in the number of triple constraints, but it can be improved.
+		List constraintOrder = new LinkedList();
+		Set selectedVars = new HashSet();
+		while (tripleConstraints.size() > 0) {
+			TripleConstraint leastConstraint = null;
+			float leastComplexity = -1;
+			
+			if (tripleConstraints.size() == 1) {
+				leastConstraint = (TripleConstraint)tripleConstraints.get(0);
+			} else {
+				//System.err.println(">>>");
+				
+				for (Iterator cons = tripleConstraints.iterator(); cons.hasNext();) {
+					TripleConstraint c = (TripleConstraint) cons.next();
+					float complexity = getComplexity(c, knownVars, cheapVars, p.knownFilters, p.source);
+					//System.err.println(">>> " + complexity + "\t" + c);
+					if (leastConstraint == null || complexity < leastComplexity) {
+						leastComplexity = complexity;
+						leastConstraint = c;
+					}
+				}
+			}
+
+			tripleConstraints.remove(leastConstraint);
+			constraintOrder.add(leastConstraint);
+			
+			// Get the variables mentioned in this triple constraint
+			Set constraintVars = new HashSet();
+			getVariables(leastConstraint, constraintVars);
+			
+			// Keep a list of variables that have been selected on so far
+			selectedVars.addAll(constraintVars);
+			
+			// And all of these variables are now considered 'known' for the purposes of
+			// selecting which statement goes next.  But they're not considered 'cheap'.
+			knownVars.addAll(constraintVars);
+			
+			// Well, if this triple was functional or inverse functional, we *can*
+			// consider the variables mentioned in the triple cheap.
+			if (leastComplexity <= 1)
+				cheapVars.addAll(constraintVars);
+			
+			// Perform any filters that are such that all of the
+			// variables mentioned in the filter have already been selected
+			// on.  The earlier we filter the better.  (We have to know not just
+			// which variables are known so far, because ones that are known from
+			// filters may not yet be actually bound in the binding set.  Rather,
+			// we have to know which ones have actually been selected on in a
+			// triple.  Here, we only know what's been selected on in this group,
+			// and not at a higher level.)
+	        for (Iterator filters = filterQueue.iterator(); filters.hasNext();) {
+	            FilterConstraintData c = (FilterConstraintData) filters.next();
+	            /*boolean allvarsknown = true;
+	            Set filterVars = getFilterVariables((SimpleNode)c);
+	            for (Iterator vars = filterVars.iterator(); vars.hasNext(); ) {
+	            	if (!selectedVars.contains(vars.next())) {
+	            		allvarsknown = false;
+	            		break;
+	            	}
+	            }
+	            if (allvarsknown) {
+	            	constraintOrder.add(c);
+	            	filters.remove();
+	            }*/
+	        }
+        }
+		
+		// Add the otherQueue back in.
+		constraintOrder.addAll(otherQueue);
+
+		// Run the constraints in the new order.
+        RdfBindingSet current = null;
+		
+		// Allow a subclass to take over running the constraints.
+		current = runTripleConstraints(constraintOrder, p.source, p.defaultDatasets, p.namedDatasets, p.knownValues, p.knownFilters);
+		if (current != null) {
+			constraintOrder.clear();
+			if (optionalQueue.size() > 0)
+				current = updateKnownVariables(current, p.knownValues);
+		}
+		
+		for (Iterator cons = constraintOrder.iterator(); cons.hasNext();) {
+			ConstraintLogic c = (ConstraintLogic) cons.next();
+			
+			p.bindings = current;
+			
+			if (current == null) {
+				current = c.constrain(p);
+			} else if (c instanceof FilterConstraintData) {
+	            current = c.constrain(p);
+	            filterQueue.remove(c);
+			} else {
+				current = logic.intersect(current, c.constrain(p));
+			}
+
+			if (cons.hasNext() || optionalQueue.size() > 0)
+				current = updateKnownVariables(current, p.knownValues);
+        }
+        
+        // At this point, we're operating on the set, so let's make it an empty one
+        if (current == null) {
+            current = new RdfBindingSetImpl();
+        }
+
+		// Any optionals...
+        for (Iterator optionals = optionalQueue.iterator(); optionals.hasNext();) {
+            ConstraintLogic c = (ConstraintLogic) optionals.next();
+				p.bindings = current;
+            current = c.constrain(p);
+        }
+		
+		// Any filters that were not moved up in the logic to process them as early as possible.
+        for (Iterator filters = filterQueue.iterator(); filters.hasNext();) {
+            ConstraintLogic c = (ConstraintLogic) filters.next();
+				p.bindings = current;
+            current = c.constrain(p);
+        }
+        return current;
+    }
+
+	protected RdfBindingSet runTripleConstraints(List tripleConstraints, RdfSource source,
+            Collection defaultDatasets, Collection namedDatasets, Map knownValues, Map knownFilters) {
+		return null;
+	}
+	
+	private RdfBindingSet updateKnownVariables(RdfBindingSet current, Map knownValues) {
+		// If there are more things happening later, update our knownValue
+		// mapping based on what has currently been queried.  We have to
+		// loop through all of the bindings found so far, so we'll put
+		// those bindings into a new set to cache them.
+		
+		current = new RdfBindingSetImpl(current);
+		List variables = current.getVariables();
+		
+		Set hadNewValues = new HashSet();
+		for (Iterator biter = current.iterator(); biter.hasNext(); ) {
+			RdfBindingRow row = (RdfBindingRow)biter.next();
+			List rowvalues = row.getValues();
+			
+			for (int i = 0; i < variables.size(); i++) {
+				Variable var = (Variable) variables.get(i);
+				Value val = (Value) rowvalues.get(i);
+				
+				if (val == null) continue;
+				
+				Set values = (Set)knownValues.get(var);
+				
+				// If knownValues has no mapping for this variable yet,
+				// or if knownValues had a mapping, we want to clear
+				// the mapping and start fresh with the values actually
+				// found.
+				if (values == null || !hadNewValues.contains(var)) { 
+					values = new HashSet();
+					knownValues.put(var, values);
+					hadNewValues.add(var);
+				}
+					
+				values.add(val);
+			}
+		}
+		
+		extractVariableFunctions(knownValues);	
+		
+		return current;
+	}
+	
+    /**
+     * Creates a mapping from variables to a List of filters based on
+	 * the expression.
+     * 
+     * @param node the expression to extract filters from
+	 * @param literalFilters a map from variables to a List of filters (of any type
+	 *                       supported by the underlying AdvancedRdfSource).
+     */
+	protected void extractLiteralFilters(ExpressionLogic node, Map literalFilters) {
+		if (node instanceof ASTAndNode) {
+			extractLiteralFilters(((ASTAndNode)node).getLeftExpression(), literalFilters);
+			extractLiteralFilters(((ASTAndNode)node).getRightExpression(), literalFilters);
+		}
+	}
+	
+	protected void addLiteralFilter(Variable variable, Object filter, Map literalFilters) {
+		List list = (List)literalFilters.get(variable);
+		if (list == null) {
+			list = new java.util.ArrayList();
+			literalFilters.put(variable, list);
+		}
+		list.add(filter);
+	}
+	
+	private void extractVariableFunctions(Map knownValues) {
+        for (Iterator cons = data.getConstraints().iterator(); cons.hasNext();) {
+            ConstraintLogic c = (ConstraintLogic) cons.next();
+            if (c instanceof FilterConstraintData) {
+				FilterConstraintData f = (FilterConstraintData)c;
+				extractVariableFunctions(f.getExpression(), knownValues);
+			}
+		}
+	}
+	
+	private void extractVariableFunctions(ExpressionLogic node, Map knownValues) {
+		if (node instanceof ASTAndNode) {
+			extractVariableFunctions(((ASTAndNode)node).getLeftExpression(), knownValues);
+			extractVariableFunctions(((ASTAndNode)node).getRightExpression(), knownValues);
+		}
+		if (node instanceof ASTOrNode) {
+			Map a = new HashMap();
+			Map b = new HashMap();
+			extractVariableFunctions(((ASTOrNode)node).getLeftExpression(), a);
+			extractVariableFunctions(((ASTOrNode)node).getRightExpression(), b);
+			for (Iterator i = a.keySet().iterator(); i.hasNext(); ) {
+				Variable v = (Variable)i.next();
+				if (b.containsKey(v)) {
+					Set av = (Set)a.get(v);
+					Set bv = (Set)b.get(v);
+					av.addAll(bv);
+					if (knownValues.containsKey(v)) {
+						((Set)knownValues.get(v)).retainAll(av);
+					} else {
+						knownValues.put(v, av);
+					}
+				}
+			}
+		}
+		if (node instanceof ASTEqualsNode) {
+			extractVariableFunctions(((ASTEqualsNode)node).getLeftExpression(), ((ASTEqualsNode)node).getRightExpression(), knownValues);
+			extractVariableFunctions(((ASTEqualsNode)node).getRightExpression(), ((ASTEqualsNode)node).getLeftExpression(), knownValues);
+		}
+	}
+	
+	private void extractVariableFunctions(ExpressionLogic a, ExpressionLogic b, Map knownValues) {
+		if (!(a instanceof Variable)) return;
+		if (knownValues.containsKey(a)) return; // we could intersect with existing values, but be sure not to do this for values we just inserted into the hash
+		
+		if (b instanceof Variable && knownValues.containsKey(b)) {
+			knownValues.put(a, knownValues.get(b));
+		
+		} else if (b instanceof ExternalFunctionLogic) {
+			// if this is a function of one variable, get the values by applying the function
+			// to all of the variables values.  (if it's of more than one variable, we could
+			// permute through the variables...)
+			ExternalFunctionLogic f = (ExternalFunctionLogic)b;
+			Set varargs =  getFilterVariables((SimpleNode)b);
+			
+			if (varargs.size() == 0) { // a constant, ok
+				Value v = f.evaluate(new MyBindingRow(new HashMap()));
+				HashSet vs = new HashSet();
+				vs.add(v);
+				knownValues.put(a, vs);
+				return;
+			}
+			
+			if (varargs.size() > 1) return;
+			
+			for (Iterator i = varargs.iterator(); i.hasNext(); ) {
+				Variable var = (Variable)i.next();
+				if (!knownValues.containsKey(var))
+					return;
+				
+				Set varvalues = (Set)knownValues.get(var);
+				Set newvalues = new HashSet();
+				Map bindings = new HashMap();
+				for (Iterator j = varvalues.iterator(); j.hasNext(); ) {
+					bindings.put(var, j.next());
+					newvalues.add( f.evaluate(new MyBindingRow(bindings)) );
+				}
+				
+				knownValues.put(a, newvalues);
+			}
+		}
+		
+		
+		// TODO: if b is a function whose arguments are all constants or known values, evaluate the function
+	}
+	
+	private class MyBindingRow extends AbstractRdfBindingRow {
+		Map values;
+		public MyBindingRow(Map values) { super(null); this.values = values; }
+		public List getVariables() { return new java.util.ArrayList(values.keySet()); }
+		public Value getValue(Variable v) { return (Value)values.get(v); }
+	}
+	
+    /**
+     * Returns the complexity of the triple constraint, given a set of
+	 * variables that already have known values.  The return value is a
+	 * measure of the number of statements that we expect to match the
+	 * filter, on a nonsensical scale.
+     * 
+     * @param variablesKnown a set of variables whose values are known
+     */
+	private float getComplexity(TripleConstraint triple, Set variablesKnown, Set cheapVariables, Map knownFilters, RdfSource source) {
+		Object subject = triple.getSubjectExpression();
+		Object predicate = triple.getPredicateExpression();
+		Object object = triple.getObjectExpression();
+		
+		boolean isFunctional = predicate instanceof URI && isFunctional((URI)predicate, source, true);
+		boolean isInverseFunctional = predicate instanceof URI && isFunctional((URI)predicate, source, false);
+		
+		// Properties in RDF tend to be many-to-few.  That is, lots of people
+		// may have a particular foaf:name, and one person has very few foaf:names.
+		// Thus, we give a penalty when a new variable occurs in subject position.
+		// Furthermore, we give an even bigger penality for variables in predicate position.
+		
+		float subjComplexity = getComplexity2(subject, variablesKnown, cheapVariables, knownFilters, 3);
+		float predComplexity = getComplexity2(predicate, variablesKnown, cheapVariables, knownFilters, 4);
+		float objComplexity = getComplexity2(object, variablesKnown, cheapVariables, knownFilters, 2);
+
+		// If this is a functional or inverse functional statement, then we reduce the
+		// complexity of the object because we know it is in a 1-to-1 relation with
+		// the subject (or the other way around).  (And, in these cases the predicate
+		// isn't a variable, so its complexity is zero anyway.)  Note that these
+		// computations are based on the 1 + maximum possible complexity for the
+		// subject and object, so *modifications to the getComplexity2 function and
+		// the penalities should be reflected here.
+		
+		if (isFunctional) objComplexity /= (6 - subjComplexity);
+		if (isInverseFunctional) subjComplexity /= (5 - objComplexity);
+		// If both functional and inverse functional, then does this make sense?
+		
+		return subjComplexity + predComplexity + objComplexity;
+	}
+	
+	private int getComplexity2(Object thing, Set variablesKnown, Set cheapVariables, Map knownFilters, int penalty) {
+		int ret = 0;
+		if (thing instanceof Variable && !cheapVariables.contains(thing)) {
+			ret++;
+			if (!knownFilters.containsKey(thing)) ret++;
+			if (!variablesKnown.contains(thing)) ret += penalty;
+		}
+		return ret;
+	}
+	
+	private boolean isFunctional(URI predicate, RdfSource source, boolean forward) {
+		Map map = forward ? isFunctional : isInverseFunctional;
+		if (map.containsKey(predicate)) return ((Boolean)map.get(predicate)).booleanValue();
+	
+		URI rdftype = new org.openrdf.model.impl.URIImpl("http://www.w3.org/1999/02/22-rdf-syntax-ns#type");
+		String typeuri = "http://www.w3.org/2002/07/owl#" +
+			( forward ? "FunctionalProperty" : "InverseFunctionalProperty");
+		boolean ret = source.hasDefaultStatement(predicate, rdftype, new org.openrdf.model.impl.URIImpl(typeuri));
+		map.put(predicate, new Boolean(ret));
+		return ret;
+	}
+
+	
+    /**
+     * Adds the variables in the constraint into the set.
+     * 
+     * @param variablesKnown a set of variables whose values are known
+     */
+	private void getVariables(TripleConstraint triple, Set variablesKnown) {
+		if (triple.getSubjectExpression() instanceof Variable) variablesKnown.add(triple.getSubjectExpression());
+		if (triple.getPredicateExpression() instanceof Variable) variablesKnown.add(triple.getPredicateExpression());
+		if (triple.getObjectExpression() instanceof Variable) variablesKnown.add(triple.getObjectExpression());
+	}
+	
+   /**
+     * Gets a variable for the filter.  If the filter is a ASTEqualsNode,
+	 * return the variable on the left hand side.  If the filter is a
+	 * ASTOrNode, return the variable if its the same on both sides,
+	 * or else null.
+     */
+	private Variable getFilterPrimaryVariable(BinaryExpressionNode expr) {
+		if (expr instanceof ASTOrNode
+			&& expr.getLeftExpression() instanceof BinaryExpressionNode
+			&& expr.getRightExpression() instanceof BinaryExpressionNode) {
+			Variable left = getFilterPrimaryVariable((BinaryExpressionNode)expr.getLeftExpression());
+			Variable right = getFilterPrimaryVariable((BinaryExpressionNode)expr.getRightExpression());
+			if (left != null && right != null && left.equals(right)) return left;
+		} else if (expr instanceof ASTEqualsNode
+			&& expr.getLeftExpression() instanceof Variable && (expr.getRightExpression() instanceof URI || expr.getRightExpression() instanceof BNode || expr.getRightExpression() instanceof Literal)) {
+			return (Variable)expr.getLeftExpression(); 
+		}
+		return null;
+	}
+	
+   /**
+     * Gets the values for a filter.  For an ASTEqualsNode, returns
+	 * the right hand side.  For an ASTOrNode, returns the values of its parts.
+     */
+	private void getFilterValues(BinaryExpressionNode expr, Set set) {
+		if (expr instanceof ASTOrNode) {
+			getFilterValues((BinaryExpressionNode)expr.getLeftExpression(), set);
+			getFilterValues((BinaryExpressionNode)expr.getRightExpression(), set);
+		} else if (expr instanceof ASTEqualsNode && (expr.getRightExpression() instanceof URI || expr.getRightExpression() instanceof BNode || expr.getRightExpression() instanceof Literal)) {
+			set.add(expr.getRightExpression());
+		}
+	}
+
+	private Set getFilterVariables(SimpleNode filter) {
+		final HashSet ret = new HashSet();
+		filter.jjtAccept(
+			new EmptyVisitor() {
+				public void visit(ASTVar node) {
+					ret.add(node);
+				}
+			}
+			);
+		return ret;
+	}
+}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/streamed/IndexedSetIntersectLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/streamed/IndexedSetIntersectLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/streamed/IndexedSetIntersectLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/streamed/IndexedSetIntersectLogic.java	2006-12-02 11:01:18.000000000 -0500
@@ -64,7 +64,7 @@
         final List variables;
 
         final List commonVariables;
-
+		
         RdfBindingIntersect(RdfBindingSet set1, RdfBindingSet set2) {
             this.set1 = set1;
             this.set2 = set2;
@@ -259,10 +259,11 @@
             }
 
             public Value getValue(Variable variable) {
-                Value returnValue = this.row1.getValue(variable);
-                if (returnValue == null) {
+				Value returnValue = null;
+				if (set1.getVariables().contains(variable))
+					returnValue = this.row1.getValue(variable);
+                if (returnValue == null && set2.getVariables().contains(variable))
                     returnValue = this.row2.getValue(variable);
-                }
                 return returnValue;
             }
 
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/streamed/IndexedSetJoinLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/streamed/IndexedSetJoinLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/streamed/IndexedSetJoinLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/streamed/IndexedSetJoinLogic.java	2006-12-02 11:01:18.000000000 -0500
@@ -81,7 +81,7 @@
 		final List variables;
 
 		final List commonVariables;
-
+		
 		RdfBindingJoin(RdfBindingSet set1, RdfBindingSet set2, Collection filters) {
 			this.set1 = set1;
 			this.set2 = set2;
@@ -293,14 +293,11 @@
 			}
 
 			public Value getValue(Variable variable) {
-				Value returnValue = this.row1.getValue(variable);
-				if (returnValue == null) {
-					if (this.row2 == null) {
-						returnValue = null;
-					} else {
-						returnValue = this.row2.getValue(variable);
-					}
-				}
+				Value returnValue = null;
+				if (set1.getVariables().contains(variable))
+					returnValue = this.row1.getValue(variable);
+				if (returnValue == null && this.row2 != null && set2.getVariables().contains(variable))
+					returnValue = this.row2.getValue(variable);
 				return returnValue;
 			}
 
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/streamed/StreamedFilterConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/streamed/StreamedFilterConstraintLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/streamed/StreamedFilterConstraintLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/streamed/StreamedFilterConstraintLogic.java	2007-02-21 07:33:50.000000000 -0500
@@ -10,6 +10,7 @@
 import java.util.Iterator;
 import java.util.LinkedList;
 import java.util.List;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingRow;
 import name.levering.ryan.sparql.common.RdfBindingSet;
@@ -76,9 +77,8 @@
 	 *            this constraint
 	 * @return a binding set with values that pass through the filter expression
 	 */
-	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
-		return new FilterBindingSet(bindings, this.data.getExpression());
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+		return new FilterBindingSet(p.bindings, this.data.getExpression());
 	}
 
 	private class FilterBindingSet extends AbstractRdfBindingSet implements StackedRdfBindingSet {
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/streamed/StreamedGraphConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/streamed/StreamedGraphConstraintLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/streamed/StreamedGraphConstraintLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/streamed/StreamedGraphConstraintLogic.java	2007-02-21 07:42:47.000000000 -0500
@@ -10,6 +10,7 @@
 import java.util.Collection;
 import java.util.Iterator;
 import java.util.List;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingRow;
 import name.levering.ryan.sparql.common.RdfBindingSet;
@@ -85,21 +86,21 @@
      * @return a binding set of values bound in the named graphs, potentially
      *         with a bound graph variable
      */
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source,
-            Collection defaultDatasets, Collection namedDatasets) {
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
 
         RdfBindingSet fullSet = new RdfBindingSetImpl();
-        if (bindings != null && bindings.iterator().hasNext()) {
-            for (Iterator i = bindings.iterator(); i.hasNext();) {
+        if (p.bindings != null && p.bindings.iterator().hasNext()) {
+            for (Iterator i = p.bindings.iterator(); i.hasNext();) {
                 RdfBindingRow row = (RdfBindingRow) i.next();
                 Object evaluation = this.data.getGraph().evaluate(row);
                 // If this evaluates to an un-bound variable, assume we want to
                 // apply the group to any named dataset
                 if (evaluation instanceof Variable) {
-                    if (namedDatasets.isEmpty()) {
+                    if (p.namedDatasets.isEmpty()) {
                         // Here we want to use any named dataset in the data
-                        RdfBindingSet namedResults = this.data.getConstraint().constrain(
-                                bindings, source, null, namedDatasets);
+								 ConstraintLogic.CallParams p2 = p.clone();
+								 p2.defaultDatasets = null;
+                        RdfBindingSet namedResults = this.data.getConstraint().constrain(p2);
 
                         RdfBindingSet sourcedSet = changeSource(
                                 (Variable) evaluation, namedResults);
@@ -107,12 +108,13 @@
                         fullSet = this.unionLogic.union(fullSet, sourcedSet);
                     } else {
                         // If there are named datasets, only use those
-                        for (Iterator j = namedDatasets.iterator(); j.hasNext();) {
+                        for (Iterator j = p.namedDatasets.iterator(); j.hasNext();) {
                             URI namedSet = (URI) j.next();
-                            Collection datasets = Arrays.asList(new Object[] { namedSet });
 
-                            RdfBindingSet namedResults = this.data.getConstraint().constrain(
-                                    bindings, source, datasets, namedDatasets);
+									  ConstraintLogic.CallParams p2 = p.clone();
+									  p2.defaultDatasets = Arrays.asList(new Object[] { namedSet });
+									  
+                            RdfBindingSet namedResults = this.data.getConstraint().constrain(p2);
 
                             RdfBindingSet sourcedSet = addSource(
                                     (Variable) evaluation, namedSet,
@@ -122,25 +124,27 @@
                         }
                     }
                 } else if (this.data.getGraph() instanceof Variable) {
-                    Collection datasets = Arrays.asList(new Object[] { evaluation });
-                    RdfBindingSet namedResults = this.data.getConstraint().constrain(
-                            bindings, source, datasets, namedDatasets);
+						   ConstraintLogic.CallParams p2 = p.clone();
+						   p2.defaultDatasets = Arrays.asList(new Object[] { evaluation });
+                    RdfBindingSet namedResults = this.data.getConstraint().constrain(p2);
                     fullSet = this.unionLogic.union(fullSet, addSource(
                             (Variable) this.data.getGraph(), (URI) evaluation,
                             namedResults));
                 } else {
-                    Collection datasets = Arrays.asList(new Object[] { evaluation });
+						   ConstraintLogic.CallParams p2 = p.clone();
+						   p2.defaultDatasets = Arrays.asList(new Object[] { evaluation });
                     fullSet = this.unionLogic.union(fullSet,
-                            this.data.getConstraint().constrain(bindings,
-                                    source, datasets, namedDatasets));
+                            this.data.getConstraint().constrain(p2));
                 }
             }
         } else {
             if (this.data.getGraph() instanceof Variable) {
-                if (namedDatasets.isEmpty()) {
+                if (p.namedDatasets.isEmpty()) {
                     // Here we want to use any named dataset in the data
-                    RdfBindingSet namedResults = this.data.getConstraint().constrain(
-                            bindings, source, null, namedDatasets);
+							ConstraintLogic.CallParams p2 = p.clone();
+							p2.defaultDatasets = null;
+
+							RdfBindingSet namedResults = this.data.getConstraint().constrain(p2);
 
                     RdfBindingSet sourcedSet = changeSource(
                             (Variable) this.data.getGraph(), namedResults);
@@ -148,12 +152,13 @@
                     fullSet = this.unionLogic.union(fullSet, sourcedSet);
                 } else {
                     // If there are named datasets, only use those
-                    for (Iterator j = namedDatasets.iterator(); j.hasNext();) {
+                    for (Iterator j = p.namedDatasets.iterator(); j.hasNext();) {
                         URI namedSet = (URI) j.next();
-                        Collection datasets = Arrays.asList(new Object[] { namedSet });
+							
+								 ConstraintLogic.CallParams p2 = p.clone();
+								 p2.defaultDatasets = Arrays.asList(new Object[] { namedSet });
 
-                        RdfBindingSet namedResults = this.data.getConstraint().constrain(
-                                bindings, source, datasets, namedDatasets);
+                        RdfBindingSet namedResults = this.data.getConstraint().constrain(p2);
 
                         RdfBindingSet sourcedSet = addSource(
                                 (Variable) this.data.getGraph(), namedSet,
@@ -163,10 +168,10 @@
                     }
                 }
             } else {
-                Collection datasets = Arrays.asList(new Object[] { this.data.getGraph() });
+					  ConstraintLogic.CallParams p2 = p.clone();
+					  p2.defaultDatasets = Arrays.asList(new Object[] { this.data.getGraph() });
                 fullSet = this.unionLogic.union(fullSet,
-                        this.data.getConstraint().constrain(bindings, source,
-                                datasets, namedDatasets));
+                        this.data.getConstraint().constrain(p2));
             }
         }
         return fullSet;
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/streamed/StreamedSetProjectionLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/streamed/StreamedSetProjectionLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/streamed/StreamedSetProjectionLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/streamed/StreamedSetProjectionLogic.java	2007-02-09 07:54:16.000000000 -0500
@@ -130,8 +130,10 @@
 			}
 
 			public Value getValue(Variable variable) {
-				return ((ExpressionLogic) RdfBindingProjection.this.variableExpressions.get(variable))
-						.evaluate(this.row);
+				ExpressionLogic expr = (ExpressionLogic) RdfBindingProjection.this.variableExpressions.get(variable);
+				if (expr == null)
+					throw new IllegalArgumentException("Variable " + variable + " is not bound in this row.");
+				return expr.evaluate(this.row);
 			}
 
 			public List getVariables() {
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/streamed/StreamedTripleConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/streamed/StreamedTripleConstraintLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/streamed/StreamedTripleConstraintLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/streamed/StreamedTripleConstraintLogic.java	2007-02-21 07:42:10.000000000 -0500
@@ -10,11 +10,14 @@
 import java.util.Iterator;
 import java.util.List;
 import java.util.NoSuchElementException;
+import java.util.Map;
+import java.util.Set;
 
 import name.levering.ryan.sparql.common.GraphStatement;
 import name.levering.ryan.sparql.common.RdfBindingRow;
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
+import name.levering.ryan.sparql.common.AdvancedRdfSource;
 import name.levering.ryan.sparql.common.Variable;
 import name.levering.ryan.sparql.common.impl.AbstractRdfBindingRow;
 import name.levering.ryan.sparql.common.impl.AbstractRdfBindingSet;
@@ -63,8 +66,7 @@
 	 * @param namedDatasets the named datasets to use in graph constraints, not
 	 *            used in this constraint
 	 */
-	public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets,
-			Collection namedDatasets) {
+	public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
 
 		ExpressionLogic subExpr = this.data.getSubjectExpression();
 		ExpressionLogic predExpr = this.data.getPredicateExpression();
@@ -75,12 +77,12 @@
 		Value subject = null;
 		if (subExpr instanceof Variable) {
 			variables.add(subExpr);
-			flags[0] = 1;
+			flags[0] = variables.size();
 			if (subExpr.equals(predExpr)) {
-				flags[1] = 1;
+				flags[1] = flags[0];
 			}
 			if (subExpr.equals(objExpr)) {
-				flags[2] = 1;
+				flags[2] = flags[0];
 			}
 		} else {
 			subject = (Value) subExpr;
@@ -89,10 +91,10 @@
 		URI verb = null;
 		if (predExpr instanceof Variable && flags[1] == 0) {
 			variables.add(predExpr);
-			flags[1] = 2;
+			flags[1] = variables.size();
 			if (predExpr.equals(objExpr)) {
-				flags[2] = 2;
-			}
+				flags[2] = flags[2];
+			}                               
 		} else {
 			verb = (URI) predExpr;
 		}
@@ -100,46 +102,57 @@
 		Value object = null;
 		if (objExpr instanceof Variable && flags[2] == 0) {
 			variables.add(objExpr);
-			flags[2] = 3;
+			flags[2] = variables.size();
 		} else if (flags[2] == 0) {
 			object = (Value) objExpr;
 		}
+		
+		TripleQueryOptions query = new TripleQueryOptions();
+		query.source = p.source;
+		query.variables = variables;
+		query.flags = flags;
+		query.knownValues = p.knownValues;
+		query.knownFilters = p.knownFilters;
+
+		if (p.defaultDatasets == null) {
+			query.includeSource = true;
 
-		if (defaultDatasets == null) {
 			// This adds an extra column to the returned set for the GRAPH
 			// constraint to process
-			if (source != null) {
-				StatementBindingSet bindingSet = new StatementBindingSet(source, variables, flags, true);
+			if (p.source != null) {
+				StatementBindingSet bindingSet = new StatementBindingSet(query);
 				bindingSet.addIterator(new StatementImpl(subject, verb, object));
 				return bindingSet;
 			} else {
-				StreamedTripleBindingSet bindingSet = new StreamedTripleBindingSet(variables, flags, true);
+				StreamedTripleBindingSet bindingSet = new StreamedTripleBindingSet(query);
 				bindingSet.addIterator(new StatementImpl(subject, verb, object));
 				return bindingSet;
 			}
 		} else {
-			if (source != null) {
-				StatementBindingSet bindingSet = new StatementBindingSet(source, variables, flags, false);
-				if (defaultDatasets.isEmpty()) {
+			query.includeSource = false;
+			
+			if (p.source != null) {
+				StatementBindingSet bindingSet = new StatementBindingSet(query);
+				if (p.defaultDatasets.isEmpty()) {
 					// This is if no FROM graphs are specified
 					bindingSet.addIterator(new StatementImpl(subject, verb, object));
 				} else {
 					// This is if FROM graphs are specified or FROM NAMED and
 					// we're in a GRAPH constraint
-					for (Iterator i = defaultDatasets.iterator(); i.hasNext();) {
+					for (Iterator i = p.defaultDatasets.iterator(); i.hasNext();) {
 						bindingSet.addIterator(new StatementImpl(subject, verb, object, (URI) i.next()));
 					}
 				}
 				return bindingSet;
 			} else {
-				StreamedTripleBindingSet bindingSet = new StreamedTripleBindingSet(variables, flags, false);
-				if (defaultDatasets.isEmpty()) {
+				StreamedTripleBindingSet bindingSet = new StreamedTripleBindingSet(query);
+				if (p.defaultDatasets.isEmpty()) {
 					// This is if no FROM graphs are specified
 					bindingSet.addIterator(new StatementImpl(subject, verb, object));
 				} else {
 					// This is if FROM graphs are specified or FROM NAMED and
 					// we're in a GRAPH constraint
-					for (Iterator i = defaultDatasets.iterator(); i.hasNext();) {
+					for (Iterator i = p.defaultDatasets.iterator(); i.hasNext();) {
 						bindingSet.addIterator(new StatementImpl(subject, verb, object, (URI) i.next()));
 					}
 				}
@@ -147,43 +160,67 @@
 			}
 		}
 	}
-
-	/**
-	 * This set is the lowest level binding set that wraps a request to an
-	 * RdfSource. It returns an iterator that uses the row iterators from the
-	 * RdfSource getStatement call to check if returned rows match the equality
-	 * criteria in the passed in flags.
-	 * 
-	 * @author Ryan Levering
-	 * @version 1.1
-	 */
-	private class StatementBindingSet extends AbstractRdfBindingSet {
-
+	
+	private class TripleQueryOptions implements Cloneable {
 		/**
 		 * The RDF source that's being queried.
 		 */
-		final RdfSource source;
+		RdfSource source;
 
 		/**
 		 * The variables that are being bound to values in the RDF source.
 		 */
-		final List variables;
+		List variables;
 
 		/**
 		 * Flags that allow a shortcut to checking for the equality of two
 		 * equivalent variables.
 		 */
-		final int[] flags;
+		int[] flags;
+		
+		/**
+		 * Whether or not to include the graph name in the returned bindings.
+		 */
+		boolean includeSource;
 
 		/**
-		 * The statements that are matched against the RDF source.
+		 * A mapping from variables to Lists of Values that the bindings
+		 * must be drawn from.  (Possibly null if not applicable.)
 		 */
-		final List statementIterators = new ArrayList();
+		Map knownValues;
 
 		/**
-		 * Whether or not to include the graph name in the returned bindings.
+		 * A mapping from variables to Lists of filters (objects) that the bindings
+		 * must satisfy.  (Possibly null if not applicable.)
 		 */
-		final boolean includeSource;
+		Map knownFilters;
+		
+		public TripleQueryOptions clone() {
+			try {
+				return (TripleQueryOptions)super.clone();
+			} catch (CloneNotSupportedException e) {
+				// lame
+				throw new RuntimeException(e);
+			}
+		}
+	}
+
+	/**
+	 * This set is the lowest level binding set that wraps a request to an
+	 * RdfSource. It returns an iterator that uses the row iterators from the
+	 * RdfSource getStatement call to check if returned rows match the equality
+	 * criteria in the passed in flags.
+	 * 
+	 * @author Ryan Levering
+	 * @version 1.1
+	 */
+	private class StatementBindingSet extends AbstractRdfBindingSet {
+		final TripleQueryOptions query;
+		
+		/**
+		 * The statements that are matched against the RDF source.
+		 */
+		final List statementIterators = new ArrayList();
 
 		/**
 		 * Creates a new binding set that queries a particular RdfSource,
@@ -195,11 +232,8 @@
 		 * @param flags indicates the presence of variable equivalency
 		 * @param includeSource whether to bind the graph name as well
 		 */
-		private StatementBindingSet(RdfSource source, List variables, int[] flags, boolean includeSource) {
-			this.source = source;
-			this.variables = variables;
-			this.flags = flags;
-			this.includeSource = includeSource;
+		private StatementBindingSet(TripleQueryOptions query) {
+			this.query = query;
 		}
 
 		void addIterator(GraphStatement statementIterator) {
@@ -211,8 +245,8 @@
 		}
 
 		public List getVariables() {
-			List extVariables = new ArrayList(this.variables);
-			if (this.includeSource) {
+			List extVariables = new ArrayList(this.query.variables);
+			if (this.query.includeSource) {
 				extVariables.add(StreamedGraphConstraintLogic.CONTEXT_VARIABLE);
 			}
 			return extVariables;
@@ -273,24 +307,70 @@
 				// We should only get here if there was never a chance
 				return null;
 			}
-
+			
 			private Iterator getStatements(GraphStatement statement) {
+				if (StatementBindingSet.this.query.source instanceof AdvancedRdfSource)
+					return getStatementsAdvanced(statement);
+				else
+					return getStatementsSimple(statement);
+			}
+			
+			private Iterator getStatementsSimple(GraphStatement statement) {
+				Value s = statement.getSubject();
+				URI p = statement.getPredicate();
+				Value o = statement.getObject();
+				
+				if (statement.getGraphName() == null) {
+					if (StatementBindingSet.this.query.includeSource) {
+						return StatementBindingSet.this.query.source.getStatements(s, p, o);
+					} else {
+						return StatementBindingSet.this.query.source.getDefaultStatements(s, p, o);
+					}
+				} else {
+					return StatementBindingSet.this.query.source.getStatements(s, p, o, statement.getGraphName());
+				}
+			}
+			
+			private Iterator getStatementsAdvanced(GraphStatement statement) {
+				AdvancedRdfSource source = (AdvancedRdfSource)StatementBindingSet.this.query.source;
+				
+				Value[] s = getValues(statement.getSubject(), 0);
+				Value[] p = getValues(statement.getPredicate(), 1);
+				Value[] o = getValues(statement.getObject(), 2);
+				Object[] litFilters = getFilters(statement.getObject());
+				
 				if (statement.getGraphName() == null) {
-					if (StatementBindingSet.this.includeSource) {
-						return StatementBindingSet.this.source.getStatements(statement.getSubject(), statement
-								.getPredicate(), statement.getObject());
+					if (StatementBindingSet.this.query.includeSource) {
+						return source.getStatements(s, p, o, litFilters);
 					} else {
-						return StatementBindingSet.this.source.getDefaultStatements(statement.getSubject(), statement
-								.getPredicate(), statement.getObject());
+						return source.getDefaultStatements(s, p, o, litFilters);
 					}
 				} else {
-					return StatementBindingSet.this.source.getStatements(statement.getSubject(), statement
-							.getPredicate(), statement.getObject(), statement.getGraphName());
+					return source.getStatements(s, p, o, new URI[] { statement.getGraphName() }, litFilters);
 				}
 			}
+			
+			private Value[] getValues(Value value, int index) {
+				if (value != null) return new Value[] { value };
+				if (StatementBindingSet.this.query.knownValues == null) return null;
+				int varIndex = StatementBindingSet.this.query.flags[index]-1;
+				Variable variable = (Variable)StatementBindingSet.this.query.variables.get(varIndex); 
+				Set values = (Set)StatementBindingSet.this.query.knownValues.get(variable);
+				if (values == null) return null;
+				return (Value[])values.toArray(new Value[0]);
+			}
+			private Object[] getFilters(Value value) {
+				if (value != null) return null;
+				if (StatementBindingSet.this.query.knownFilters == null) return null;
+				int varIndex = StatementBindingSet.this.query.flags[2]-1;
+				Variable variable = (Variable)StatementBindingSet.this.query.variables.get(varIndex);
+				List filters = (List)StatementBindingSet.this.query.knownFilters.get(variable);
+				if (filters == null) return null;
+				return filters.toArray();
+			}
 
 			private boolean checkStatement(GraphStatement statement) {
-				int[] localFlags = StatementBindingSet.this.flags;
+				int[] localFlags = StatementBindingSet.this.query.flags;
 
 				if (localFlags[0] != 0 && localFlags[0] == localFlags[2]) {
 					if (!statement.getSubject().equals(statement.getObject())) {
@@ -338,14 +418,14 @@
 
 				public Value getValue(Variable variable) {
 					// Special case for the source
-					if (StatementBindingSet.this.includeSource
+					if (StatementBindingSet.this.query.includeSource
 							&& variable.equals(StreamedGraphConstraintLogic.CONTEXT_VARIABLE)) {
 						return this.statement.getGraphName();
 					}
 					// First get the index
 					int index = getIndex(variable);
 
-					int[] localFlags = StatementBindingSet.this.flags;
+					int[] localFlags = StatementBindingSet.this.query.flags;
 					if (index == 2) {
 						// If the variable is in the last spot, it's got to be
 						// the object
@@ -375,7 +455,7 @@
 
 				private int getIndex(Variable variable) {
 					int index = 0;
-					for (Iterator vars = StatementBindingSet.this.variables.iterator(); vars.hasNext(); index++) {
+					for (Iterator vars = StatementBindingSet.this.query.variables.iterator(); vars.hasNext(); index++) {
 						Variable var = (Variable) vars.next();
 						if (variable.equals(var)) {
 							return index;
@@ -405,22 +485,18 @@
 
 	private class StreamedTripleBindingSet extends VirtualRdfBindingSet {
 
-		private final List variables;
-
-		private final int[] flags;
-
-		private final boolean includeSource;
-
+		private final TripleQueryOptions query;
+		
 		private final List statementIterators = new ArrayList();
 
-		public StreamedTripleBindingSet(List variables, int[] flags, boolean includeSource) {
-			this.variables = variables;
-			this.flags = flags;
-			this.includeSource = includeSource;
+		public StreamedTripleBindingSet(TripleQueryOptions query) {
+			this.query = query;
 		}
 
 		public void setSource(RdfSource source) {
-			StatementBindingSet set = new StatementBindingSet(source, this.variables, this.flags, this.includeSource);
+			TripleQueryOptions q = query.clone();
+			q.source = source;
+			StatementBindingSet set = new StatementBindingSet(q);
 			for (Iterator statementIt = statementIterators.iterator(); statementIt.hasNext();) {
 				set.addIterator((GraphStatement) statementIt.next());
 			}
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/StreamedLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/StreamedLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/StreamedLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/StreamedLogic.java	2006-12-02 11:28:06.000000000 -0500
@@ -378,8 +378,8 @@
 	 *            direction
 	 * @return the logic handling the ordering of an expression
 	 */
-	public OrderExpressionLogic getOrderExpressionLogic(OrderExpressionData data) {
-		return new DefaultOrderExpressionLogic(data, getValueOrderingLogic());
+	public OrderExpressionLogic getOrderExpressionLogic(OrderExpressionData data, SPARQLValueFactory valueFactory) {
+		return new DefaultOrderExpressionLogic(data, getValueOrderingLogic(valueFactory));
 	}
 
 	/**
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/logic/StreamedStrictLogic.java work-copy/src/main/name/levering/ryan/sparql/logic/StreamedStrictLogic.java
--- upstream/src/main/name/levering/ryan/sparql/logic/StreamedStrictLogic.java	2006-08-20 20:01:01.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/logic/StreamedStrictLogic.java	2006-12-02 11:17:59.000000000 -0500
@@ -270,8 +270,8 @@
 	 *            direction
 	 * @return the logic handling the ordering of an expression
 	 */
-	public OrderExpressionLogic getOrderExpressionLogic(OrderExpressionData data) {
-		return new DefaultOrderExpressionLogic(data, getValueOrderingLogic());
+	public OrderExpressionLogic getOrderExpressionLogic(OrderExpressionData data, SPARQLValueFactory valueFactory) {
+		return new DefaultOrderExpressionLogic(data, getValueOrderingLogic(valueFactory));
 	}
 
 	/**
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/model/logic/ConstraintLogic.java work-copy/src/main/name/levering/ryan/sparql/model/logic/ConstraintLogic.java
--- upstream/src/main/name/levering/ryan/sparql/model/logic/ConstraintLogic.java	2006-08-20 20:00:59.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/model/logic/ConstraintLogic.java	2007-02-21 07:49:30.000000000 -0500
@@ -6,6 +6,7 @@
 package name.levering.ryan.sparql.model.logic;
 
 import java.util.Collection;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
 import name.levering.ryan.sparql.common.RdfSource;
@@ -27,16 +28,51 @@
      * Constrains the value bindings by either constraining the current value
      * bindings or returning a set that will be constrained via intersection
      * with the current set.
-     * 
-     * @param bindings the set of current bindings to evaluate against
-     * @param source the RDF source, which is dealt with by the triple
-     *            constraint
-     * @param defaultDatasets the datasets that are currently being used for
-     *            binding
-     * @param namedDatasets the datasets that are used in the GRAPH constraint
-     *            for unbound variables
      */
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source,
-            Collection defaultDatasets, Collection namedDatasets);
+    public RdfBindingSet constrain(CallParams p);
 
+	 public static class CallParams {
+		 /**
+		  * The set of current bindings to evaluate against, for
+		  * ConstraintLogics where it is used (like filters).
+		  */
+		 public RdfBindingSet bindings;
+		 
+		 /**
+		  * The RDF data source, which is dealt with by the triple constraint
+		  */
+		 public RdfSource source;
+       
+		 /**
+		  * The datasets that are currently being used for binding
+		  */
+		 public Collection defaultDatasets;
+		 
+		 /**
+		  * The datasets that are used in the GRAPH constraint for unbound variables
+		  */
+		 public Collection namedDatasets;
+		
+		 /**
+		  * A mapping from variables to Sets of values that the variable must be drawn from
+		  */
+		 public Map knownValues;
+		 
+		 /**
+		  * A mapping from variables to Lists of filters that the variable must satisfy.
+		  * A filter's type is determined by API implementors.
+		  */
+		 public Map knownFilters;
+		 
+		 public CallParams clone() {
+			 CallParams p = new CallParams();
+			 p.bindings = bindings;
+			 p.source = source;
+			 p.defaultDatasets = defaultDatasets == null ? null : new java.util.ArrayList(defaultDatasets);
+			 p.namedDatasets = namedDatasets == null ? null : new java.util.ArrayList(namedDatasets);
+			 p.knownValues = knownValues == null ? null : new java.util.HashMap(knownValues);
+			 p.knownFilters = knownFilters == null ? null : new java.util.HashMap(knownFilters);
+			 return p;
+		 }
+	 }
 }
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/model/logic/LogicFactory.java work-copy/src/main/name/levering/ryan/sparql/model/logic/LogicFactory.java
--- upstream/src/main/name/levering/ryan/sparql/model/logic/LogicFactory.java	2006-08-20 20:00:59.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/model/logic/LogicFactory.java	2006-12-02 11:00:47.000000000 -0500
@@ -63,7 +63,7 @@
 
 	public ConstraintLogic getOptionalConstraintLogic(OptionalConstraintData data, SPARQLValueFactory valueFactory);
 
-	public OrderExpressionLogic getOrderExpressionLogic(OrderExpressionData data);
+	public OrderExpressionLogic getOrderExpressionLogic(OrderExpressionData data, SPARQLValueFactory valueFactory);
 
 	public ExpressionLogic getAdditionLogic(BinaryExpressionData data, SPARQLValueFactory valueFactory);
 
@@ -119,7 +119,7 @@
 
 	public ValueConversionLogic getValueConversionLogic(SPARQLValueFactory valueFactory);
 
-	public ValueOrderingLogic getValueOrderingLogic();
+	public ValueOrderingLogic getValueOrderingLogic(SPARQLValueFactory valueFactory);
 
 	public void registerExternalFunction(URI functionIRI, ExternalFunctionFactory functionFactory);
 
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/parser/model/ASTFilterConstraint.java work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTFilterConstraint.java
--- upstream/src/main/name/levering/ryan/sparql/parser/model/ASTFilterConstraint.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTFilterConstraint.java	2007-02-21 07:40:03.000000000 -0500
@@ -4,6 +4,7 @@
 
 import java.util.Collection;
 import java.util.Collections;
+import java.util.Map;
 import java.util.Set;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
@@ -24,8 +25,8 @@
         return (ExpressionLogic) this.jjtGetChild(0);
     }
 
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets, Collection namedDatasets) {
-        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+        return this.logic.constrain(p);
     }
 
     public Set getVariables() {
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/parser/model/ASTGraphConstraint.java work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTGraphConstraint.java
--- upstream/src/main/name/levering/ryan/sparql/parser/model/ASTGraphConstraint.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTGraphConstraint.java	2007-02-21 07:40:07.000000000 -0500
@@ -3,6 +3,7 @@
 package name.levering.ryan.sparql.parser.model;
 
 import java.util.Collection;
+import java.util.Map;
 import java.util.Set;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
@@ -40,8 +41,8 @@
         return null;
     }
 
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets, Collection namedDatasets) {
-        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+        return this.logic.constrain(p);
     }
 
     public Set getVariables() {
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/parser/model/ASTGroupConstraint.java work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTGroupConstraint.java
--- upstream/src/main/name/levering/ryan/sparql/parser/model/ASTGroupConstraint.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTGroupConstraint.java	2007-02-21 07:40:11.000000000 -0500
@@ -6,6 +6,7 @@
 import java.util.Collection;
 import java.util.HashSet;
 import java.util.Iterator;
+import java.util.Map;
 import java.util.Set;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
@@ -39,9 +40,8 @@
         return constraints;
     }
 
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source,
-            Collection defaultDatasets, Collection namedDatasets) {
-        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+        return this.logic.constrain(p);
     }
 
     public Set getVariables() {
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/parser/model/ASTLiteral.java work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTLiteral.java
--- upstream/src/main/name/levering/ryan/sparql/parser/model/ASTLiteral.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTLiteral.java	2006-12-02 11:00:47.000000000 -0500
@@ -61,4 +61,15 @@
         }
     }
     
+	public int hashCode() {
+		return label.hashCode();
+	}
+	
+	public boolean equals(Object other) {
+		if (!(other instanceof Literal)) return false;
+		Literal lit = (Literal)other;
+		return label.equals(lit.getLabel())
+			&& ((language == null && lit.getLanguage() == null) || (language != null && lit.getLanguage() != null && language.equals(lit.getLanguage())))
+			&& ((datatype == null && lit.getDatatype() == null) || (datatype != null && lit.getDatatype() != null && datatype.equals(lit.getDatatype()))); 
+	}
 }
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/parser/model/ASTOptionalConstraint.java work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTOptionalConstraint.java
--- upstream/src/main/name/levering/ryan/sparql/parser/model/ASTOptionalConstraint.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTOptionalConstraint.java	2007-02-21 07:40:17.000000000 -0500
@@ -3,6 +3,7 @@
 package name.levering.ryan.sparql.parser.model;
 
 import java.util.Collection;
+import java.util.Map;
 import java.util.Set;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
@@ -24,8 +25,8 @@
         return (GroupConstraint) this.jjtGetChild(0);
     }
 
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets, Collection namedDatasets) {
-        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+        return this.logic.constrain(p);
     }
 
     public Set getVariables() {
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/parser/model/ASTUnionConstraint.java work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTUnionConstraint.java
--- upstream/src/main/name/levering/ryan/sparql/parser/model/ASTUnionConstraint.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTUnionConstraint.java	2007-02-21 07:40:21.000000000 -0500
@@ -6,6 +6,7 @@
 import java.util.Collection;
 import java.util.HashSet;
 import java.util.Iterator;
+import java.util.Map;
 import java.util.Set;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
@@ -31,8 +32,8 @@
         return constraints;
     }
 
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets, Collection namedDatasets) {
-        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+        return this.logic.constrain(p);
     }
 
     public Set getVariables() {
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/parser/model/ASTWithExtension.java work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTWithExtension.java
--- upstream/src/main/name/levering/ryan/sparql/parser/model/ASTWithExtension.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/ASTWithExtension.java	2007-02-21 07:40:25.000000000 -0500
@@ -6,6 +6,7 @@
 import java.util.Collections;
 import java.util.List;
 import java.util.Set;
+import java.util.Map;
 
 import name.levering.ryan.sparql.common.QueryException;
 import name.levering.ryan.sparql.common.RdfBindingSet;
@@ -25,8 +26,8 @@
         super(id);
     }
     
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets, Collection namedDatasets) {
-        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+        return this.logic.constrain(p);
     }
 
     public URI getName() {
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/parser/model/DelegatingTripleConstraint.java work-copy/src/main/name/levering/ryan/sparql/parser/model/DelegatingTripleConstraint.java
--- upstream/src/main/name/levering/ryan/sparql/parser/model/DelegatingTripleConstraint.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/DelegatingTripleConstraint.java	2007-02-21 07:40:30.000000000 -0500
@@ -7,6 +7,7 @@
 
 import java.util.Collection;
 import java.util.HashSet;
+import java.util.Map;
 import java.util.Set;
 
 import name.levering.ryan.sparql.common.RdfBindingSet;
@@ -39,8 +40,8 @@
         return this.statement.getObjectExpression();
     }
 
-    public RdfBindingSet constrain(RdfBindingSet bindings, RdfSource source, Collection defaultDatasets, Collection namedDatasets) {
-        return this.logic.constrain(bindings, source, defaultDatasets, namedDatasets);
+    public RdfBindingSet constrain(ConstraintLogic.CallParams p) {
+        return this.logic.constrain(p);
     }
 
     public Set getVariables() {
@@ -64,5 +65,5 @@
     public void setLogic(ConstraintLogic logic) {
         this.logic = logic;
     }
-
+	
 }
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/parser/model/OrderExpressionNode.java work-copy/src/main/name/levering/ryan/sparql/parser/model/OrderExpressionNode.java
--- upstream/src/main/name/levering/ryan/sparql/parser/model/OrderExpressionNode.java	2006-08-20 20:01:00.000000000 -0400
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/OrderExpressionNode.java	2006-12-02 11:00:47.000000000 -0500
@@ -31,6 +31,6 @@
     }
 
     public void applyLogic(LogicBinder binder) {
-        this.logic = binder.getLogicFactory().getOrderExpressionLogic(this);
+        this.logic = binder.getLogicFactory().getOrderExpressionLogic(this, binder.getValueFactory());
     }
 }
diff -urN --exclude=.svn --exclude=.settings --exclude=META-INF upstream/src/main/name/levering/ryan/sparql/parser/model/SPARQLParserTreeConstants.java work-copy/src/main/name/levering/ryan/sparql/parser/model/SPARQLParserTreeConstants.java
--- upstream/src/main/name/levering/ryan/sparql/parser/model/SPARQLParserTreeConstants.java	2006-12-02 11:30:46.000000000 -0500
+++ work-copy/src/main/name/levering/ryan/sparql/parser/model/SPARQLParserTreeConstants.java	2006-12-02 10:52:04.000000000 -0500
@@ -1,4 +1,4 @@
-/* Generated By:JJTree: Do not edit this line. /home/tauberer/dev/semweb/sparql/upstream/src/main/name/levering/ryan/sparql/parser/model/SPARQLParserTreeConstants.java */
+/* Generated By:JJTree: Do not edit this line. /home/tauberer/dev/semweb/sparql/src/src/main/name/levering/ryan/sparql/parser/model/SPARQLParserTreeConstants.java */
 
 package name.levering.ryan.sparql.parser.model;
 
